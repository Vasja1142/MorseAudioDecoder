{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 1: Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 1: Импорты и Базовая Настройка ---\n",
      "\n",
      "--- Статус ключевых библиотек ---\n",
      "PyTorch Версия: 2.5.1+cu121\n",
      "LibROSA Версия: 0.11.0\n",
      "Torchaudio доступен: True\n",
      "NumPy Версия: 2.0.2\n",
      "Pandas Версия: 2.2.3\n",
      "Levenshtein доступен: True\n",
      "MLflow доступен: True\n",
      "IPyWidgets доступен: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 1: Импорты и Базовая Настройка\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 1: Импорты и Базовая Настройка ---\")\n",
    "\n",
    "# --- Базовые библиотеки ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE' # Для избежания конфликтов на некоторых системах\n",
    "import zipfile\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import random\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple, List, Dict, Optional\n",
    "\n",
    "# --- Аудио и Сигналы ---\n",
    "import librosa\n",
    "import librosa.display\n",
    "try:\n",
    "    import torchaudio # Нужен для compute_deltas\n",
    "    TORCHAUDIO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TORCHAUDIO_AVAILABLE = False\n",
    "    print(\"!!! КРИТИЧЕСКАЯ ОШИБКА: torchaudio не найден, но необходим для вычисления дельт! Установите torchaudio. !!!\")\n",
    "    raise SystemExit(\"Остановка: Отсутствует torchaudio.\")\n",
    "\n",
    "# --- Визуализация и Интерактивность (IPython/Jupyter) ---\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, Audio, clear_output\n",
    "    IPYWIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    IPYWIDGETS_AVAILABLE = False\n",
    "    print(\"Предупреждение: ipywidgets не найден. Интерактивные ячейки будут недоступны.\")\n",
    "    def display(*args, **kwargs): pass\n",
    "    def Audio(*args, **kwargs): pass\n",
    "    def clear_output(*args, **kwargs): pass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- PyTorch ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# --- Метрики и Утилиты ---\n",
    "try:\n",
    "    import Levenshtein\n",
    "    LEVENSHTEIN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LEVENSHTEIN_AVAILABLE = False\n",
    "    print(\"!!! ПРЕДУПРЕЖДЕНИЕ: Библиотека Levenshtein не найдена. Метрика качества будет недоступна. Установите python-Levenshtein !!!\")\n",
    "    # Простая заглушка, если библиотека не найдена\n",
    "    class Levenshtein:\n",
    "        @staticmethod\n",
    "        def distance(s1, s2): return max(len(s1), len(s2)) # Возвращает максимальную длину как штраф\n",
    "\n",
    "from tqdm.notebook import tqdm # Используем версию для Jupyter\n",
    "import itertools\n",
    "\n",
    "# --- Логирование Экспериментов (MLflow) ---\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"Предупреждение: mlflow не найден. Логирование экспериментов будет отключено.\")\n",
    "    # Заглушка для MLflow будет определена в Ячейке 12\n",
    "\n",
    "# --- Настройка окружения и предупреждений ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "print(\"\\n--- Статус ключевых библиотек ---\")\n",
    "print(f\"PyTorch Версия: {torch.__version__}\")\n",
    "print(f\"LibROSA Версия: {librosa.__version__}\")\n",
    "print(f\"Torchaudio доступен: {TORCHAUDIO_AVAILABLE}\")\n",
    "print(f\"NumPy Версия: {np.__version__}\")\n",
    "print(f\"Pandas Версия: {pd.__version__}\")\n",
    "print(f\"Levenshtein доступен: {LEVENSHTEIN_AVAILABLE}\")\n",
    "print(f\"MLflow доступен: {MLFLOW_AVAILABLE}\")\n",
    "print(f\"IPyWidgets доступен: {IPYWIDGETS_AVAILABLE}\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 2: Конфигурация и Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 2: Конфигурация и Параметры (ФИНАЛ: Grouped Conv g=2, Delta win=3) ---\n",
      "Базовая директория: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_mel\\MorseAudioDecoder\n",
      "Ожидаемая директория аудио: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_mel\\MorseAudioDecoder\\morse_dataset\\morse_dataset\n",
      "Директория для вывода: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_mel\\MorseAudioDecoder\\output_final_model\n",
      "\n",
      "Аудио параметры (ФИНАЛ):\n",
      "{\n",
      "  \"feature_type\": \"melspec_delta_win3_grouped2\",\n",
      "  \"sample_rate\": 8000,\n",
      "  \"n_fft\": 128,\n",
      "  \"hop_length\": 64,\n",
      "  \"n_mels\": 12,\n",
      "  \"fmin\": 0.0,\n",
      "  \"fmax\": 4200.0,\n",
      "  \"power\": 2.0,\n",
      "  \"apply_trimming\": false,\n",
      "  \"trim_top_db\": 30,\n",
      "  \"delta_win_length\": 3\n",
      "}\n",
      "\n",
      "Параметры модели (ФИНАЛ):\n",
      "{\n",
      "  \"input_feature_dim\": 24,\n",
      "  \"cnn_out_channels\": [\n",
      "    128,\n",
      "    128,\n",
      "    128\n",
      "  ],\n",
      "  \"cnn_kernel_size\": 9,\n",
      "  \"cnn_stride\": 1,\n",
      "  \"cnn_padding\": \"same\",\n",
      "  \"cnn_pool_kernel\": 2,\n",
      "  \"rnn_hidden_size\": 512,\n",
      "  \"rnn_num_layers\": 3,\n",
      "  \"dropout_rate\": 0.2,\n",
      "  \"activation_fn\": \"GELU\",\n",
      "  \"classifier_type\": \"single\",\n",
      "  \"num_feature_groups\": 2\n",
      "}\n",
      "\n",
      "Параметры обучения (ФИНАЛ):\n",
      "{\n",
      "  \"batch_size\": 8,\n",
      "  \"num_workers\": 0,\n",
      "  \"num_epochs\": 80,\n",
      "  \"learning_rate\": 0.0001,\n",
      "  \"div_factor\": 10.0,\n",
      "  \"final_div_factor\": 10000,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"optimizer\": \"AdamW\",\n",
      "  \"early_stopping_patience\": 12,\n",
      "  \"gradient_clip_norm\": 2.0,\n",
      "  \"validation_split_ratio\": 0.1,\n",
      "  \"base_seed\": 42,\n",
      "  \"batches_per_epoch\": 0\n",
      "}\n",
      "\n",
      "Шаблон базового суффикса (ФИНАЛ): SR8k_Mel12x2win3_fft128h64_f0-4k2_CNN128-128g2_RNN3x512_BiGRU_GELU_Clssingle_LR1e-04_WD1e-04\n",
      "\n",
      "Используемое устройство: cuda\n",
      "  GPU: NVIDIA GeForce GTX 1050 Ti\n",
      "Установлен SEED = 42\n",
      "\n",
      "--- Ячейка 2: Финальная конфигурация готова ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 2: Конфигурация и Параметры (ФИНАЛ: Grouped Conv g=2, Delta win=3)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 2: Конфигурация и Параметры (ФИНАЛ: Grouped Conv g=2, Delta win=3) ---\")\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# --- Пути ---\n",
    "BASE_DIR = Path('.').resolve()\n",
    "DATA_DIR = BASE_DIR\n",
    "ZIP_PATH = DATA_DIR / 'morse_dataset.zip'\n",
    "AUDIO_DIR_NAME = 'morse_dataset'\n",
    "EXTRACTED_AUDIO_DIR = DATA_DIR / AUDIO_DIR_NAME / AUDIO_DIR_NAME\n",
    "TRAIN_CSV_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_CSV_PATH = DATA_DIR / 'test.csv'\n",
    "SAMPLE_SUB_PATH = DATA_DIR / 'sample_submission.csv'\n",
    "OUTPUT_DIR = BASE_DIR / 'output_final_model' # Отдельная папка для финальной модели\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Базовая директория: {BASE_DIR}\")\n",
    "print(f\"Ожидаемая директория аудио: {EXTRACTED_AUDIO_DIR}\")\n",
    "print(f\"Директория для вывода: {OUTPUT_DIR}\")\n",
    "\n",
    "# --- Параметры обработки аудио (ФИНАЛ) ---\n",
    "SR_FOR_CONFIG = 8000; HOP_LENGTH_CONST = 64; N_MELS_CONST = 12; N_FFT_CONST = 128; DELTA_WIN_CONST = 3\n",
    "AUDIO_CONFIG = {\n",
    "    \"feature_type\": \"melspec_delta_win3_grouped2\", # Тип признаков финальной модели\n",
    "    \"sample_rate\": SR_FOR_CONFIG,\n",
    "    \"n_fft\": N_FFT_CONST,\n",
    "    \"hop_length\": HOP_LENGTH_CONST,\n",
    "    \"n_mels\": N_MELS_CONST,\n",
    "    \"fmin\": 0.0,\n",
    "    \"fmax\": 4200.0,\n",
    "    \"power\": 2.0,\n",
    "    \"apply_trimming\": False, # Оставляем False\n",
    "    \"trim_top_db\": 30,\n",
    "    \"delta_win_length\": DELTA_WIN_CONST # Оптимальное окно для дельты\n",
    "}\n",
    "print(f\"\\nАудио параметры (ФИНАЛ):\")\n",
    "print(json.dumps(AUDIO_CONFIG, indent=2))\n",
    "\n",
    "# --- Параметры Модели (ФИНАЛ: Grouped Conv g=2, CNN1=128, RNN2) ---\n",
    "MODEL_CONFIG_FINAL = {\n",
    "    \"input_feature_dim\": N_MELS_CONST * 2, # Вход = 2 * n_mels\n",
    "    \"cnn_out_channels\": [128, 128, 128], # Первый слой 128 (64 для M, 64 для D1)\n",
    "    \"cnn_kernel_size\": 9,\n",
    "    \"cnn_stride\": 1,\n",
    "    \"cnn_padding\": 'same',\n",
    "    \"cnn_pool_kernel\": 2,\n",
    "    \"rnn_hidden_size\": 512, # Полный размер\n",
    "    \"rnn_num_layers\": 3,    # 2 слоя RNN\n",
    "    \"dropout_rate\": 0.2,\n",
    "    \"activation_fn\": \"GELU\",\n",
    "    \"classifier_type\": \"single\",\n",
    "    \"num_feature_groups\": 2 # Указываем 2 группы\n",
    "}\n",
    "# Проверка кратности первого канала\n",
    "if MODEL_CONFIG_FINAL[\"cnn_out_channels\"][0] % MODEL_CONFIG_FINAL[\"num_feature_groups\"] != 0:\n",
    "    raise ValueError(f\"Первый cnn_out_channel ({MODEL_CONFIG_FINAL['cnn_out_channels'][0]}) должен быть кратен num_feature_groups ({MODEL_CONFIG_FINAL['num_feature_groups']})!\")\n",
    "\n",
    "print(f\"\\nПараметры модели (ФИНАЛ):\")\n",
    "print(json.dumps(MODEL_CONFIG_FINAL, indent=2))\n",
    "\n",
    "# --- Параметры Обучения (ФИНАЛ) ---\n",
    "TRAIN_CONFIG_FINAL = {\n",
    "    \"batch_size\": 8, # Оставляем 8 для GTX 1050 Ti\n",
    "    \"num_workers\": 0,\n",
    "    \"num_epochs\": 80, # Увеличиваем для полного обучения (можно и больше, если время позволяет)\n",
    "    \"learning_rate\": 1e-4, # Стандартный LR\n",
    "    \"div_factor\": 10.0,\n",
    "    \"final_div_factor\": 10000,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"early_stopping_patience\": 12, # Увеличиваем терпимость\n",
    "    \"gradient_clip_norm\": 2.0,\n",
    "    \"validation_split_ratio\": 0.1,\n",
    "    \"base_seed\": SEED,\n",
    "    \"batches_per_epoch\": 0 # Полные эпохи\n",
    "}\n",
    "print(f\"\\nПараметры обучения (ФИНАЛ):\")\n",
    "print(json.dumps(TRAIN_CONFIG_FINAL, indent=2))\n",
    "\n",
    "# --- Специальные Токены и Глобальные Переменные ---\n",
    "PAD_TOKEN = '<pad>'; BLANK_TOKEN = '_'\n",
    "PAD_IDX = -1; BLANK_IDX = -1; NUM_CLASSES_CTC = -1\n",
    "char_to_index: Dict[str, int] = {}; index_to_char: Dict[int, str] = {}\n",
    "\n",
    "# --- Шаблон Базового Суффикса Имени Файла (ФИНАЛ) ---\n",
    "BASE_FILENAME_SUFFIX_FINAL = (\n",
    "    f\"SR{AUDIO_CONFIG['sample_rate'] // 1000}k_\"\n",
    "    f\"Mel{N_MELS_CONST}x2win{DELTA_WIN_CONST}_fft{AUDIO_CONFIG['n_fft']}h{HOP_LENGTH_CONST}_f0-4k2_\" # MelNx2win3\n",
    "    f\"CNN{MODEL_CONFIG_FINAL['cnn_out_channels'][0]}-{MODEL_CONFIG_FINAL['cnn_out_channels'][-1]}g{MODEL_CONFIG_FINAL['num_feature_groups']}_\" # CNN128-128g2\n",
    "    f\"RNN{MODEL_CONFIG_FINAL['rnn_num_layers']}x{MODEL_CONFIG_FINAL['rnn_hidden_size']}_BiGRU_\" # RNN2x512\n",
    "    f\"{MODEL_CONFIG_FINAL['activation_fn']}_Cls{MODEL_CONFIG_FINAL['classifier_type']}_\"\n",
    "    f\"LR{TRAIN_CONFIG_FINAL['learning_rate']:.0e}_WD{TRAIN_CONFIG_FINAL['weight_decay']:.0e}\"\n",
    ")\n",
    "print(f\"\\nШаблон базового суффикса (ФИНАЛ): {BASE_FILENAME_SUFFIX_FINAL}\")\n",
    "\n",
    "# --- Выбор устройства и Установка SEED ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nИспользуемое устройство: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def set_seed(seed_value: int):\n",
    "    \"\"\"Устанавливает seed для воспроизводимости.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "    print(f\"Установлен SEED = {seed_value}\")\n",
    "\n",
    "set_seed(TRAIN_CONFIG_FINAL['base_seed'])\n",
    "\n",
    "print(\"\\n--- Ячейка 2: Финальная конфигурация готова ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 3: Загрузка данных и распаковка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 3: Загрузка метаданных и распаковка аудио ---\n",
      "Папка с аудио (C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_mel\\MorseAudioDecoder\\morse_dataset\\morse_dataset) уже существует. Распаковка пропускается.\n",
      "\n",
      "Загрузка CSV файлов...\n",
      "  Train DataFrame загружен: 30000 записей, Колонки: ['id', 'message']\n",
      "  Test DataFrame загружен: 5000 записей, Колонки: ['id']\n",
      "  Sample Submission загружен: 5000 записей.\n",
      "\n",
      "Проверка данных...\n",
      "\n",
      "Выборочная проверка наличия аудиофайлов...\n",
      "  Проверено 5 файлов - все найдены (например, C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_mel\\MorseAudioDecoder\\morse_dataset\\morse_dataset\\2309.opus).\n",
      "\n",
      "--- Ячейка 3: Загрузка данных завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 3: Загрузка Метаданных и Распаковка Аудио\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 3: Загрузка метаданных и распаковка аудио ---\")\n",
    "\n",
    "# --- Проверка и Распаковка Архива ---\n",
    "if not EXTRACTED_AUDIO_DIR.exists():\n",
    "    print(f\"Папка для аудио ({EXTRACTED_AUDIO_DIR}) не найдена.\")\n",
    "    if ZIP_PATH.is_file():\n",
    "        print(f\"Найден архив: {ZIP_PATH}. Распаковка...\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "                zip_ref.extractall(DATA_DIR)\n",
    "            print(f\"Архив распакован в: {DATA_DIR}\")\n",
    "            # Проверяем, появилась ли ожидаемая папка после распаковки\n",
    "            if not EXTRACTED_AUDIO_DIR.is_dir():\n",
    "                 # Возможно, архив содержит папку с другим именем или без корневой папки\n",
    "                 # Попробуем найти папку, начинающуюся с AUDIO_DIR_NAME\n",
    "                 found_dirs = [d for d in DATA_DIR.iterdir() if d.is_dir() and d.name.startswith(AUDIO_DIR_NAME)]\n",
    "                 if len(found_dirs) == 1:\n",
    "                     EXTRACTED_AUDIO_DIR = found_dirs[0] # Обновляем путь\n",
    "                     print(f\"Обнаружена папка с аудио: {EXTRACTED_AUDIO_DIR}\")\n",
    "                 elif len(found_dirs) > 1:\n",
    "                     print(f\"!!! ПРЕДУПРЕЖДЕНИЕ: Найдено несколько папок, похожих на '{AUDIO_DIR_NAME}': {found_dirs}. Используется первая: {found_dirs[0]}\")\n",
    "                     EXTRACTED_AUDIO_DIR = found_dirs[0]\n",
    "                 else:\n",
    "                     raise FileNotFoundError(f\"Не удалось найти папку '{AUDIO_DIR_NAME}' или похожую после распаковки в {DATA_DIR}.\")\n",
    "            else:\n",
    "                 print(f\"Папка с аудио найдена: {EXTRACTED_AUDIO_DIR}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Критическая ошибка при распаковке: {e}\")\n",
    "            traceback.print_exc()\n",
    "            raise SystemExit(\"Остановка.\")\n",
    "    else:\n",
    "        print(f\"Критическая ошибка: Архив {ZIP_PATH} не найден.\")\n",
    "        raise SystemExit(\"Остановка.\")\n",
    "else:\n",
    "    print(f\"Папка с аудио ({EXTRACTED_AUDIO_DIR}) уже существует. Распаковка пропускается.\")\n",
    "\n",
    "# --- Загрузка CSV файлов метаданных ---\n",
    "print(\"\\nЗагрузка CSV файлов...\")\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    print(f\"  Train DataFrame загружен: {len(train_df)} записей, Колонки: {train_df.columns.tolist()}\")\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "    print(f\"  Test DataFrame загружен: {len(test_df)} записей, Колонки: {test_df.columns.tolist()}\")\n",
    "    try:\n",
    "        sample_sub_df = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "        print(f\"  Sample Submission загружен: {len(sample_sub_df)} записей.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  Предупреждение: Файл Sample Submission ({SAMPLE_SUB_PATH}) не найден.\")\n",
    "        sample_sub_df = None\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Критическая ошибка: Не найден CSV файл: {e}.\")\n",
    "    raise SystemExit(\"Остановка.\")\n",
    "except Exception as e:\n",
    "    print(f\"Критическая ошибка при чтении CSV: {e}\")\n",
    "    traceback.print_exc()\n",
    "    raise SystemExit(\"Остановка.\")\n",
    "\n",
    "# --- Проверка наличия файлов и колонок ---\n",
    "print(\"\\nПроверка данных...\")\n",
    "if 'id' not in train_df.columns or 'message' not in train_df.columns:\n",
    "    raise ValueError(\"В train_df отсутствуют необходимые колонки 'id' или 'message'.\")\n",
    "if 'id' not in test_df.columns:\n",
    "    raise ValueError(\"В test_df отсутствует необходимая колонка 'id'.\")\n",
    "\n",
    "# --- Выборочная проверка существования аудиофайлов ---\n",
    "print(\"\\nВыборочная проверка наличия аудиофайлов...\")\n",
    "if EXTRACTED_AUDIO_DIR.is_dir():\n",
    "    num_check = 5\n",
    "    if len(train_df) >= num_check:\n",
    "        example_ids = train_df['id'].sample(num_check, random_state=SEED).tolist()\n",
    "    else:\n",
    "        example_ids = train_df['id'].tolist() # Проверяем все, если их мало\n",
    "\n",
    "    missing_files = []\n",
    "    for file_id in example_ids:\n",
    "        expected_path = EXTRACTED_AUDIO_DIR / file_id\n",
    "        if not expected_path.is_file():\n",
    "            missing_files.append(file_id)\n",
    "\n",
    "    if not missing_files:\n",
    "        print(f\"  Проверено {len(example_ids)} файлов - все найдены (например, {EXTRACTED_AUDIO_DIR / example_ids[0]}).\")\n",
    "    else:\n",
    "        print(f\"  !!! ПРЕДУПРЕЖДЕНИЕ: Не найдены файлы для ID: {missing_files} !!!\")\n",
    "        print(f\"  Ожидаемый путь: {EXTRACTED_AUDIO_DIR}/<id>\")\n",
    "else:\n",
    "    print(f\"  Проверка невозможна: Папка {EXTRACTED_AUDIO_DIR} не существует или не является директорией.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 3: Загрузка данных завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 4: Создание словаря символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 4: Создание словаря символов ---\n",
      "Найдено уникальных символов: 44\n",
      "Символы:  #0123456789АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ\n",
      "Размер словаря (включая BLANK и PAD): 46\n",
      "Индекс BLANK ('_'): 44\n",
      "Индекс PAD ('<pad>'): 45\n",
      "Количество классов для CTC Loss: 45\n",
      "\n",
      "--- Ячейка 4: Создание словаря завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 4: Создание Словаря Символов\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 4: Создание словаря символов ---\")\n",
    "\n",
    "# Проверка наличия train_df\n",
    "if 'train_df' not in globals() or train_df is None:\n",
    "    raise SystemExit(\"Остановка: train_df не найден. Выполните Ячейку 3.\")\n",
    "if 'message' not in train_df.columns:\n",
    "    raise SystemExit(\"Остановка: В train_df отсутствует колонка 'message'.\")\n",
    "\n",
    "try:\n",
    "    # Собираем все уникальные символы из обучающей выборки\n",
    "    # Обрабатываем возможные NaN значения в 'message'\n",
    "    all_texts = train_df['message'].fillna('').astype(str)\n",
    "    unique_chars = sorted(list(set(char for text in all_texts for char in text)))\n",
    "\n",
    "    # Создаем словари для преобразования\n",
    "    char_to_index = {char: i for i, char in enumerate(unique_chars)}\n",
    "    index_to_char = {i: char for char, i in char_to_index.items()}\n",
    "\n",
    "    # Добавляем специальные токены BLANK (для CTC) и PAD (для выравнивания)\n",
    "    # Убедимся, что они еще не существуют в словаре (маловероятно)\n",
    "    if BLANK_TOKEN in char_to_index: print(f\"Предупреждение: BLANK_TOKEN '{BLANK_TOKEN}' уже есть в данных!\")\n",
    "    if PAD_TOKEN in char_to_index: print(f\"Предупреждение: PAD_TOKEN '{PAD_TOKEN}' уже есть в данных!\")\n",
    "\n",
    "    BLANK_IDX = len(char_to_index)\n",
    "    PAD_IDX = len(char_to_index) + 1\n",
    "    char_to_index[BLANK_TOKEN] = BLANK_IDX\n",
    "    char_to_index[PAD_TOKEN] = PAD_IDX\n",
    "    index_to_char[BLANK_IDX] = BLANK_TOKEN\n",
    "    index_to_char[PAD_IDX] = PAD_TOKEN\n",
    "\n",
    "    # Общее количество классов для выходного слоя модели (включая BLANK)\n",
    "    NUM_CLASSES_CTC = BLANK_IDX + 1 # Количество классов = индекс BLANK + 1\n",
    "\n",
    "    print(f\"Найдено уникальных символов: {len(unique_chars)}\")\n",
    "    print(f\"Символы: {''.join(unique_chars)}\")\n",
    "    print(f\"Размер словаря (включая BLANK и PAD): {len(char_to_index)}\")\n",
    "    print(f\"Индекс BLANK ('{BLANK_TOKEN}'): {BLANK_IDX}\")\n",
    "    print(f\"Индекс PAD ('{PAD_TOKEN}'): {PAD_IDX}\")\n",
    "    print(f\"Количество классов для CTC Loss: {NUM_CLASSES_CTC}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Критическая ошибка при создании словаря: {e}\")\n",
    "    traceback.print_exc()\n",
    "    raise SystemExit(\"Остановка.\")\n",
    "\n",
    "# Финальная проверка\n",
    "if not char_to_index or not index_to_char or BLANK_IDX == -1 or PAD_IDX == -1 or NUM_CLASSES_CTC <= 0:\n",
    "    raise SystemExit(\"Остановка: Ошибка инициализации словаря или специальных токенов.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 4: Создание словаря завершено ---\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 5: Класс MorseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 5: Определение класса MorseDataset (ФИНАЛ: MelSpec + Delta win=3 + Grouped g=2) ---\n",
      "\n",
      "--- Ячейка 5: Определение MorseDataset (ФИНАЛ) завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 5: Класс MorseDataset (ФИНАЛ: MelSpec + Delta win=3 + Grouped g=2)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 5: Определение класса MorseDataset (ФИНАЛ: MelSpec + Delta win=3 + Grouped g=2) ---\")\n",
    "\n",
    "# Импорты и проверки зависимостей\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import traceback\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple, List, Dict, Optional\n",
    "\n",
    "# Проверка torchaudio (уже сделана в Ячейке 1)\n",
    "if not TORCHAUDIO_AVAILABLE:\n",
    "     raise SystemExit(\"Остановка: Отсутствует torchaudio, необходимый для этого датасета.\")\n",
    "\n",
    "# Проверка наличия глобальных переменных\n",
    "if 'BLANK_IDX' not in globals() or 'PAD_IDX' not in globals(): raise ValueError(\"Индексы BLANK/PAD не инициализированы.\")\n",
    "if 'AUDIO_CONFIG' not in globals(): raise ValueError(\"AUDIO_CONFIG не определен.\") # Используем финальный конфиг\n",
    "\n",
    "class MorseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет для Морзе (Мел-Спектрограммы + Дельта win=3 для Grouped Conv g=2).\n",
    "    Выполняет: Загрузка -> Ресэмплинг -> [Trimming] -> Мел-Спектрограмма -> Дельта (win=3) ->\n",
    "               -> Независимая Z-Score Нормализация -> Стек (M+D1).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dataframe: pd.DataFrame,\n",
    "                 audio_dir: Path,\n",
    "                 char_to_index: Dict[str, int],\n",
    "                 audio_config: Dict, # Принимает актуальный audio_config\n",
    "                 model_input_feature_dim: int, # Ожидаемый размер = 2 * n_mels\n",
    "                 is_train: bool = True):\n",
    "        super().__init__()\n",
    "        # Проверки типов аргументов\n",
    "        if not isinstance(dataframe, pd.DataFrame): raise TypeError(\"dataframe должен быть pandas DataFrame\")\n",
    "        if not isinstance(audio_dir, Path): raise TypeError(\"audio_dir должен быть pathlib.Path\")\n",
    "        if not isinstance(char_to_index, dict): raise TypeError(\"char_to_index должен быть словарем\")\n",
    "        if not isinstance(audio_config, dict): raise TypeError(\"audio_config должен быть словарем\")\n",
    "\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.char_to_index = char_to_index\n",
    "        self.is_train = is_train\n",
    "        self.audio_config = audio_config\n",
    "        self.expected_feature_dim = model_input_feature_dim # Ожидаем 2 * n_mels\n",
    "\n",
    "        # --- Извлечение параметров из audio_config ---\n",
    "        try:\n",
    "            self.feature_type = self.audio_config.get('feature_type', 'melspec_delta_win3_grouped2')\n",
    "            if self.feature_type != 'melspec_delta_win3_grouped2':\n",
    "                 raise ValueError(f\"Этот датасет поддерживает только feature_type='melspec_delta_win3_grouped2'\")\n",
    "\n",
    "            self.sample_rate = int(self.audio_config['sample_rate'])\n",
    "            self.n_fft = int(self.audio_config['n_fft'])\n",
    "            self.hop_length = int(self.audio_config['hop_length'])\n",
    "            self.n_mels = int(self.audio_config['n_mels'])\n",
    "            self.power = float(self.audio_config.get('power', 2.0))\n",
    "            self.fmin = float(self.audio_config.get('fmin', 0.0))\n",
    "            self.fmax = float(self.audio_config.get('fmax', self.sample_rate / 2.0))\n",
    "            self.apply_trimming = bool(self.audio_config.get('apply_trimming', False))\n",
    "            self.trim_top_db = float(self.audio_config.get('trim_top_db', 30))\n",
    "            self.delta_win_length = int(self.audio_config.get('delta_win_length', 3)) # Используем значение из конфига\n",
    "\n",
    "            nyquist = self.sample_rate / 2.0\n",
    "            if self.fmax > nyquist + 1:\n",
    "                print(f\"  Предупреждение Dataset: fmax ({self.fmax:.0f} Hz) > Найквиста ({nyquist:.0f} Hz).\")\n",
    "\n",
    "        except KeyError as e: raise ValueError(f\"Отсутствует ключ в audio_config: {e}\")\n",
    "        except (TypeError, ValueError) as e: raise ValueError(f\"Ошибка типа/значения в audio_config: {e}\")\n",
    "\n",
    "        # --- Валидация параметров ---\n",
    "        if self.sample_rate <= 0: raise ValueError(\"sample_rate > 0\")\n",
    "        if self.n_fft <= 0: raise ValueError(\"n_fft > 0\")\n",
    "        if self.hop_length <= 0: raise ValueError(\"hop_length > 0\")\n",
    "        if self.n_mels <= 0: raise ValueError(\"n_mels > 0\")\n",
    "        if self.apply_trimming and self.trim_top_db <= 0: raise ValueError(\"trim_top_db > 0 при apply_trimming=True\")\n",
    "        if self.delta_win_length <= 0 or self.delta_win_length % 2 == 0:\n",
    "             raise ValueError(f\"delta_win_length ({self.delta_win_length}) должен быть положительным нечетным числом.\")\n",
    "        if self.n_mels * 2 != self.expected_feature_dim:\n",
    "             raise ValueError(f\"Размерность входа модели ({self.expected_feature_dim}) не равна 2 * n_mels ({self.n_mels})!\")\n",
    "\n",
    "        # --- Информационное сообщение (однократно) ---\n",
    "        trim_status = f\"Trimming ON (top_db={self.trim_top_db})\" if self.apply_trimming else \"Trimming OFF\"\n",
    "        print(f\"MorseDataset (Final - GroupedInput g=2, Delta win={self.delta_win_length}): is_train={self.is_train}, SR={self.sample_rate}Hz, {trim_status}\")\n",
    "        print(f\"  Признаки: MelSpec(n_fft={self.n_fft}, hop={self.hop_length}, n_mels={self.n_mels}) + Delta (win={self.delta_win_length})\")\n",
    "        print(f\"  Нормализация: Z-Score (независимая для M, D1)\")\n",
    "        print(f\"  Итоговый вход: ({2 * self.n_mels}, T)\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Возвращает количество примеров в датасете.\"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def _normalize_feature(self, feature_matrix: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Стандартная Z-score нормализация для матрицы признаков (F, T).\"\"\"\n",
    "        if not isinstance(feature_matrix, np.ndarray) or feature_matrix.size == 0:\n",
    "            return np.array([[]], dtype=np.float32).reshape(feature_matrix.shape[0], 0) if feature_matrix.ndim == 2 else np.array([], dtype=np.float32)\n",
    "        epsilon = 1e-8\n",
    "        mean = np.mean(feature_matrix)\n",
    "        std = np.std(feature_matrix)\n",
    "        if std < epsilon:\n",
    "            return np.zeros_like(feature_matrix, dtype=np.float32)\n",
    "        return ((feature_matrix - mean) / (std + epsilon)).astype(np.float32)\n",
    "\n",
    "    def _calculate_features(self, waveform_np: np.ndarray, file_id_for_log: str = \"N/A\") -> Optional[torch.Tensor]:\n",
    "        \"\"\"Вычисляет признаки: MelSpec -> Delta (win=3) -> Независимая Нормализация -> Стек (M+D1).\"\"\"\n",
    "        empty_tensor = torch.empty((self.expected_feature_dim, 0), dtype=torch.float32)\n",
    "        if not isinstance(waveform_np, np.ndarray) or waveform_np.size == 0:\n",
    "            return empty_tensor\n",
    "        try:\n",
    "            processed_waveform = waveform_np.astype(np.float32)\n",
    "\n",
    "            # 1. Вычисление Мел-спектрограммы\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(\n",
    "                y=processed_waveform, sr=self.sample_rate, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, power=self.power\n",
    "            ) # Shape: (n_mels, T)\n",
    "\n",
    "            # Проверка на слишком короткий сигнал для вычисления дельт\n",
    "            if mel_spectrogram.shape[1] < self.delta_win_length:\n",
    "                 # print(f\"Warning ({file_id_for_log}): Слишком короткий сигнал ({mel_spectrogram.shape[1]} < {self.delta_win_length}) для вычисления дельт. Пропуск.\")\n",
    "                 return empty_tensor\n",
    "\n",
    "            # 2. Конвертация в децибелы\n",
    "            mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max, top_db=None)\n",
    "\n",
    "            # 3. Вычисление Дельты (используем torchaudio с заданным win_length)\n",
    "            mel_spec_tensor = torch.from_numpy(mel_spectrogram_db) # (n_mels, T)\n",
    "            # compute_deltas ожидает (..., time, freq), поэтому пермутируем\n",
    "            mel_spec_permuted = mel_spec_tensor.permute(1, 0) # (T, n_mels)\n",
    "            deltas = torchaudio.functional.compute_deltas(mel_spec_permuted, win_length=self.delta_win_length) # (T, n_mels)\n",
    "            # Возвращаем к (n_mels, T) и конвертируем в NumPy для нормализации\n",
    "            deltas = deltas.permute(1, 0).numpy() # (n_mels, T)\n",
    "\n",
    "            # 4. Независимая Нормализация Z-Score\n",
    "            norm_melspec = self._normalize_feature(mel_spectrogram_db)\n",
    "            norm_deltas = self._normalize_feature(deltas)\n",
    "\n",
    "            # Проверка размерностей после нормализации\n",
    "            if not (norm_melspec.shape == norm_deltas.shape):\n",
    "                 print(f\"ERROR ({file_id_for_log}): Несовпадение форм после нормализации! M:{norm_melspec.shape}, D1:{norm_deltas.shape}\")\n",
    "                 return None\n",
    "            if norm_melspec.shape[1] == 0: # Проверка на пустые признаки\n",
    "                 # print(f\"Debug ({file_id_for_log}): Пустой тензор признаков после обработки.\")\n",
    "                 return empty_tensor\n",
    "\n",
    "            # 5. Сборка итогового тензора (M+D1)\n",
    "            features_np = np.vstack([norm_melspec, norm_deltas]).astype(np.float32) # (2 * n_mels, T)\n",
    "            features_tensor = torch.from_numpy(features_np)\n",
    "\n",
    "            # Финальная проверка на NaN/Inf\n",
    "            if not torch.isfinite(features_tensor).all():\n",
    "                print(f\"WARNING ({file_id_for_log}): NaN/Inf в финальном тензоре признаков! Замена на 0.\")\n",
    "                features_tensor = torch.nan_to_num(features_tensor, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "            # Проверка итоговой размерности\n",
    "            if features_tensor.shape[0] != self.expected_feature_dim:\n",
    "                 print(f\"ERROR ({file_id_for_log}): Неожиданная итоговая размерность признаков! Ожидалось {self.expected_feature_dim}, получено {features_tensor.shape[0]}\")\n",
    "                 return None\n",
    "\n",
    "            return features_tensor # (2 * n_mels, T)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL ERROR в _calculate_features (Final - GroupedInput g=2, Delta win={self.delta_win_length}) ({file_id_for_log}): {e}\")\n",
    "            traceback.print_exc(limit=1)\n",
    "            return None\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor, str], Tuple[None, Optional[str]]]:\n",
    "        \"\"\"Загрузка, обработка (Мел-Спектрограмма + Дельта win=3) и возврат примера.\"\"\"\n",
    "        if not (0 <= index < len(self.dataframe)):\n",
    "            return None, (f\"InvalidIndex_{index}\" if not self.is_train else None)\n",
    "        try:\n",
    "            row = self.dataframe.iloc[index]\n",
    "            file_id = row['id']\n",
    "            audio_path = self.audio_dir / file_id\n",
    "        except Exception as e:\n",
    "            print(f\"Error get item data index {index}: {e}\")\n",
    "            return None, (f\"DataAccessError_{index}\" if not self.is_train else None)\n",
    "\n",
    "        # 1. Загрузка и Ресэмплинг\n",
    "        waveform_np: Optional[np.ndarray] = None\n",
    "        try:\n",
    "            waveform_np, _ = librosa.load(audio_path, sr=self.sample_rate, mono=True)\n",
    "            if waveform_np is None or waveform_np.size == 0:\n",
    "                # print(f\"Warning ({file_id}): Файл пуст или не удалось загрузить.\")\n",
    "                return None, (file_id if not self.is_train else None)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR ({file_id}): Файл не найден {audio_path}\")\n",
    "            return None, (file_id if not self.is_train else None)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR ({file_id}): Ошибка загрузки librosa: {e}\")\n",
    "            traceback.print_exc(limit=1)\n",
    "            return None, (file_id if not self.is_train else None)\n",
    "\n",
    "        # 2. Обрезка тишины (Trimming) - если включено\n",
    "        if self.apply_trimming:\n",
    "            try:\n",
    "                waveform_trimmed, _ = librosa.effects.trim(waveform_np, top_db=self.trim_top_db, frame_length=512, hop_length=128)\n",
    "                if waveform_trimmed is not None and waveform_trimmed.size > 0:\n",
    "                    waveform_np = waveform_trimmed\n",
    "                # else: Оставляем исходный, если trim удалил всё\n",
    "            except Exception as e_trim:\n",
    "                print(f\"ERROR ({file_id}): Ошибка librosa.effects.trim: {e_trim}. Используется исходный сигнал.\")\n",
    "\n",
    "        # 3. Вычисление признаков (Мел-Спектрограмма + Дельта -> Нормализация -> Стек)\n",
    "        features: Optional[torch.Tensor] = self._calculate_features(waveform_np, file_id)\n",
    "\n",
    "        # Проверка на None или пустой тензор (0 временных шагов)\n",
    "        if features is None or features.shape[1] == 0:\n",
    "            # print(f\"Warning ({file_id}): Пустой тензор признаков после обработки.\")\n",
    "            return None, (file_id if not self.is_train else None)\n",
    "\n",
    "        # 4. Подготовка цели (для train) или возврат ID (для test)\n",
    "        if self.is_train:\n",
    "            message_text = str(row.get('message', ''))\n",
    "            target_indices = [self.char_to_index.get(c) for c in message_text if c in self.char_to_index]\n",
    "            if not target_indices:\n",
    "                # print(f\"Warning ({file_id}): Пустой или невалидный таргет: '{message_text}'\")\n",
    "                return None, None # Возвращаем None, None чтобы collate_fn его отфильтровал\n",
    "            target_tensor = torch.tensor(target_indices, dtype=torch.long)\n",
    "            return features, target_tensor # (F, T), (Target_Len)\n",
    "        else:\n",
    "            # Для тестового режима возвращаем признаки и ID файла\n",
    "            return features, file_id # (F, T), str\n",
    "\n",
    "print(\"\\n--- Ячейка 5: Определение MorseDataset (ФИНАЛ) завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 6: Функция collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 6: Определение функции collate_fn ---\n",
      "Функция collate_fn определена.\n",
      "\n",
      "--- Ячейка 6: Определение collate_fn завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 6: Функция collate_fn (Сборка Батчей)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 6: Определение функции collate_fn ---\")\n",
    "\n",
    "# Импорты и проверки зависимостей\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "if 'PAD_IDX' not in globals(): raise ValueError(\"PAD_IDX не инициализирован!\")\n",
    "\n",
    "def collate_fn(batch: List[Tuple[Optional[torch.Tensor], Optional[Union[torch.Tensor, str]]]]) \\\n",
    "    -> Optional[Tuple[torch.Tensor, Union[torch.Tensor, List[str]], torch.Tensor, Optional[torch.Tensor]]]:\n",
    "    \"\"\"\n",
    "    Собирает батч данных из списка кортежей, возвращаемых MorseDataset.\n",
    "    Фильтрует некорректные примеры (где признаки или таргет/ID равны None).\n",
    "    Выполняет паддинг признаков и таргетов (для train/val).\n",
    "    Возвращает батч признаков, батч таргетов (или ID), длины признаков и длины таргетов.\n",
    "    \"\"\"\n",
    "    # 1. Фильтрация некорректных/пустых примеров\n",
    "    valid_batch = [item for item in batch if\n",
    "                   item[0] is not None and item[1] is not None and item[0].shape[1] > 0]\n",
    "\n",
    "    if not valid_batch:\n",
    "        # print(\"Warning: collate_fn получил пустой валидный батч.\")\n",
    "        return None # Если после фильтрации батч пуст\n",
    "\n",
    "    # Определяем, содержит ли батч таргеты (тензоры) или ID (строки)\n",
    "    is_train_or_val_batch = isinstance(valid_batch[0][1], torch.Tensor)\n",
    "\n",
    "    # 2. Разделение признаков и таргетов/ID\n",
    "    # Признаки имеют форму (F, T), пермутируем в (T, F) для pad_sequence\n",
    "    features_list = [item[0].permute(1, 0) for item in valid_batch] # Список тензоров (Ti, F)\n",
    "    targets_or_ids_list = [item[1] for item in valid_batch] # Список тензоров таргетов или строк ID\n",
    "\n",
    "    # 3. Паддинг признаков\n",
    "    # batch_first=True -> (B, T_max, F)\n",
    "    features_padded_time_first = pad_sequence(features_list, batch_first=True, padding_value=0.0)\n",
    "    # Возвращаем к формату (B, F, T_max), ожидаемому моделью (Conv1d)\n",
    "    features_padded = features_padded_time_first.permute(0, 2, 1)\n",
    "\n",
    "    # 4. Расчет длин признаков (до паддинга)\n",
    "    # Длина по временной оси (исходная T)\n",
    "    feature_lengths = torch.tensor([f.shape[0] for f in features_list], dtype=torch.long)\n",
    "\n",
    "    # 5. Обработка таргетов (для train/val) или ID (для test)\n",
    "    if is_train_or_val_batch:\n",
    "        # Батч содержит таргеты (тензоры)\n",
    "        targets_list: List[torch.Tensor] = targets_or_ids_list\n",
    "        # Паддинг таргетов\n",
    "        targets_padded: torch.Tensor = pad_sequence(targets_list, batch_first=True, padding_value=PAD_IDX)\n",
    "        # Расчет длин таргетов (до паддинга)\n",
    "        target_lengths: torch.Tensor = torch.tensor([len(t) for t in targets_list], dtype=torch.long)\n",
    "        # Возвращаем данные для обучения/валидации\n",
    "        return features_padded, targets_padded, feature_lengths, target_lengths\n",
    "    else:\n",
    "        # Батч содержит ID файлов (строки)\n",
    "        file_ids: List[str] = targets_or_ids_list\n",
    "        # Возвращаем данные для инференса (таргетов и их длин нет)\n",
    "        return features_padded, file_ids, feature_lengths, None\n",
    "\n",
    "print(\"Функция collate_fn определена.\")\n",
    "print(\"\\n--- Ячейка 6: Определение collate_fn завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 7: Модель MorseRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 7: Определение модели MorseRecognizer (ФИНАЛ: Grouped Conv g=2 для M+D1) ---\n",
      "\n",
      "Создание экземпляра модели для проверки (ФИНАЛ)...\n",
      "Модель 'MorseRecognizer' создана (11,777,709 параметров) на cuda.\n",
      "\n",
      "Проверка forward pass...\n",
      "  Вход: torch.Size([2, 24, 500]), Выход: torch.Size([62, 2, 45])\n",
      "  Размерности выхода (T_red, B, C) корректны.\n",
      "\n",
      "--- Ячейка 7: Определение и проверка модели (ФИНАЛ) завершены ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 7: Модель MorseRecognizer (ФИНАЛ: Grouped Conv g=2 для M+D1)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 7: Определение модели MorseRecognizer (ФИНАЛ: Grouped Conv g=2 для M+D1) ---\")\n",
    "\n",
    "# Импорты и проверки зависимостей\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Tuple, List, Dict, Optional\n",
    "\n",
    "# Проверка наличия глобальных переменных\n",
    "if 'MODEL_CONFIG_FINAL' not in globals(): raise ValueError(\"MODEL_CONFIG_FINAL не определен!\")\n",
    "if 'NUM_CLASSES_CTC' not in globals() or NUM_CLASSES_CTC <= 0: raise ValueError(\"NUM_CLASSES_CTC не корректен!\")\n",
    "\n",
    "class MorseRecognizer(nn.Module):\n",
    "    \"\"\"\n",
    "    Модель для распознавания Морзе (CNN + BiGRU). ФИНАЛЬНАЯ ВЕРСИЯ.\n",
    "    Использует Grouped Convolution (groups=2) в первом слое для раздельной обработки\n",
    "    Mel-спектрограммы и ее первой дельты (win=3), поданных как стек каналов.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes_ctc: int, input_feature_dim: int, # Ожидается 2 * n_mels\n",
    "                 cnn_out_channels: List[int], cnn_kernel_size: int, cnn_stride: int,\n",
    "                 cnn_padding: Union[int, str], cnn_pool_kernel: int,\n",
    "                 rnn_hidden_size: int, rnn_num_layers: int, dropout_rate: float,\n",
    "                 activation_fn: str = \"GELU\", classifier_type: str = \"single\",\n",
    "                 num_feature_groups: int = 2): # <-- Устанавливаем groups=2 по умолчанию\n",
    "        super().__init__()\n",
    "        # Проверка, что размерность входа кратна количеству групп\n",
    "        if input_feature_dim % num_feature_groups != 0:\n",
    "             raise ValueError(f\"input_feature_dim ({input_feature_dim}) должен быть кратен num_feature_groups ({num_feature_groups})\")\n",
    "        # Проверка, что num_feature_groups соответствует ожиданиям (2)\n",
    "        if num_feature_groups != 2:\n",
    "             print(f\"Warning: num_feature_groups={num_feature_groups}, но ожидалось 2 для M+D1.\")\n",
    "\n",
    "        self.input_feature_dim = input_feature_dim\n",
    "        self.num_feature_groups = num_feature_groups # Должно быть 2\n",
    "        self._time_reduction_factor = 1.0\n",
    "        cnn_layers = []\n",
    "        in_channels = input_feature_dim\n",
    "\n",
    "        try:\n",
    "            ActivationLayer = getattr(nn, activation_fn)\n",
    "        except AttributeError:\n",
    "            print(f\"Warning: Activation '{activation_fn}' не найдена. Используется GELU.\")\n",
    "            ActivationLayer = nn.GELU\n",
    "\n",
    "        # CNN Extractor\n",
    "        for i, out_channels in enumerate(cnn_out_channels):\n",
    "            # Устанавливаем группы только для первого слоя\n",
    "            current_groups = self.num_feature_groups if i == 0 else 1\n",
    "            # Убедимся, что out_channels кратно группам (для первого слоя)\n",
    "            if i == 0 and out_channels % self.num_feature_groups != 0:\n",
    "                 raise ValueError(f\"cnn_out_channels[0] ({out_channels}) должен быть кратен num_feature_groups ({self.num_feature_groups}) для Grouped Conv\")\n",
    "\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv1d(\n",
    "                    in_channels, out_channels, cnn_kernel_size, cnn_stride,\n",
    "                    padding=cnn_padding,\n",
    "                    groups=current_groups # <-- Устанавливаем группы (2 для первого слоя)\n",
    "                ),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                ActivationLayer(),\n",
    "                nn.MaxPool1d(cnn_pool_kernel),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "            cnn_layers.append(layer)\n",
    "            in_channels = out_channels # Для следующего слоя in_channels = out_channels предыдущего\n",
    "            self._time_reduction_factor *= cnn_pool_kernel\n",
    "        self.cnn_extractor = nn.Sequential(*cnn_layers)\n",
    "        self.cnn_output_dim = in_channels\n",
    "\n",
    "        # RNN (BiGRU)\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.cnn_output_dim, # Вход RNN = выход CNN\n",
    "            hidden_size=rnn_hidden_size,\n",
    "            num_layers=rnn_num_layers, # Используем значение из конфига (2)\n",
    "            batch_first=True, # Ожидает (B, T, F_cnn)\n",
    "            bidirectional=True, # Используем BiGRU\n",
    "            dropout=dropout_rate if rnn_num_layers > 1 else 0.0\n",
    "        )\n",
    "        rnn_output_dim = rnn_hidden_size * 2 # Учитываем двунаправленность\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier_type = classifier_type\n",
    "        if self.classifier_type == \"double\":\n",
    "            intermediate_dim = rnn_output_dim\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(rnn_output_dim, intermediate_dim),\n",
    "                ActivationLayer(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(intermediate_dim, num_classes_ctc)\n",
    "            )\n",
    "            classifier_str = f\"DoubleLinear({rnn_output_dim}->{intermediate_dim}->{num_classes_ctc})\"\n",
    "        elif self.classifier_type == \"single\":\n",
    "            self.classifier = nn.Linear(rnn_output_dim, num_classes_ctc)\n",
    "            classifier_str = f\"SingleLinear({rnn_output_dim}->{num_classes_ctc})\"\n",
    "        else:\n",
    "            raise ValueError(f\"Неизвестный classifier_type: {self.classifier_type}. Допустимы 'single', 'double'.\")\n",
    "\n",
    "        # Вывод архитектуры при инициализации (можно раскомментировать для отладки)\n",
    "        # print(f\"Архитектура MorseRecognizer (Final - Grouped Conv g={self.num_feature_groups}):\")\n",
    "        # print(f\"  Input Feature Dim: {self.input_feature_dim} ({self.input_feature_dim // self.num_feature_groups} per group)\")\n",
    "        # print(f\"  CNN (1D): {len(cnn_out_channels)} layers, OutChannels={cnn_out_channels}, Kernel={cnn_kernel_size}, Pool={cnn_pool_kernel}\")\n",
    "        # print(f\"       Grouped Conv (Layer 0): groups={self.num_feature_groups}\")\n",
    "        # print(f\"       CNN Output Dim={self.cnn_output_dim}, Time Reduction Factor={self._time_reduction_factor:.1f}x\")\n",
    "        # print(f\"  RNN: BiGRU, Layers={rnn_num_layers}, Hidden Size={rnn_hidden_size}\")\n",
    "        # print(f\"       RNN Output Dim={rnn_output_dim}\")\n",
    "        # print(f\"  Activation: {activation_fn}\")\n",
    "        # print(f\"  Classifier: {classifier_str}\")\n",
    "        # print(f\"  Dropout: {dropout_rate}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input: (B, F, T_in) - где F = 2 * n_mels\n",
    "        -> CNN (Layer 0: Grouped Conv g=2) -> (B, C_cnn, T_red)\n",
    "        -> Permute -> (B, T_red, C_cnn)\n",
    "        -> RNN -> (B, T_red, H*2)\n",
    "        -> Classifier -> (B, T_red, N_classes)\n",
    "        -> Permute -> Output: (T_red, B, N_classes) - для CTC Loss\n",
    "        \"\"\"\n",
    "        # Проверка размерности входа\n",
    "        if x.shape[1] != self.input_feature_dim:\n",
    "            raise ValueError(f\"Input feature dim mismatch! Expected {self.input_feature_dim}, got {x.shape[1]}. Shape: {x.shape}\")\n",
    "\n",
    "        x = self.cnn_extractor(x)        # (B, C_cnn, T_reduced)\n",
    "        x = x.permute(0, 2, 1)           # (B, T_reduced, C_cnn) - готовим для RNN (batch_first=True)\n",
    "        x_rnn, _ = self.rnn(x)           # (B, T_reduced, Hidden*2)\n",
    "        logits = self.classifier(x_rnn)  # (B, T_reduced, NumClasses)\n",
    "        # Готовим для CTC Loss: (Time, Batch, Classes)\n",
    "        logits = logits.permute(1, 0, 2) # (T_reduced, B, NumClasses)\n",
    "        return logits\n",
    "\n",
    "    def get_time_reduction_factor(self) -> float:\n",
    "        \"\"\"Возвращает фактор уменьшения временной размерности после CNN.\"\"\"\n",
    "        return self._time_reduction_factor\n",
    "\n",
    "# --- Создание и Проверка Экземпляра Модели ---\n",
    "model_created_successfully = False\n",
    "model_check = None; dummy_input = None; dummy_output = None\n",
    "try:\n",
    "    print(\"\\nСоздание экземпляра модели для проверки (ФИНАЛ)...\")\n",
    "    # Используем финальный конфиг из Ячейки 2\n",
    "    temp_model_config_check = MODEL_CONFIG_FINAL.copy()\n",
    "\n",
    "    model_check = MorseRecognizer(\n",
    "        num_classes_ctc=NUM_CLASSES_CTC,\n",
    "        **temp_model_config_check # Передаем финальный конфиг\n",
    "    ).to(device)\n",
    "    total_params = sum(p.numel() for p in model_check.parameters() if p.requires_grad)\n",
    "    print(f\"Модель '{type(model_check).__name__}' создана ({total_params:,} параметров) на {device}.\")\n",
    "\n",
    "    print(\"\\nПроверка forward pass...\"); model_check.eval()\n",
    "    dummy_batch_size = 2; dummy_time_steps = 500\n",
    "    # Используем правильную размерность входа\n",
    "    dummy_input = torch.randn(dummy_batch_size, temp_model_config_check['input_feature_dim'], dummy_time_steps).to(device)\n",
    "    with torch.no_grad(): dummy_output = model_check(dummy_input)\n",
    "    print(f\"  Вход: {dummy_input.shape}, Выход: {dummy_output.shape}\")\n",
    "    expected_time_dim = int(dummy_time_steps / model_check.get_time_reduction_factor())\n",
    "    if abs(dummy_output.shape[0] - expected_time_dim) > 2: print(f\"  ПРЕДУПРЕЖДЕНИЕ: Неожиданная длина выхода! Ожидалось ~{expected_time_dim}, получено {dummy_output.shape[0]}.\")\n",
    "    assert dummy_output.shape[1] == dummy_batch_size, \"Batch size mismatch!\"\n",
    "    assert dummy_output.shape[2] == NUM_CLASSES_CTC, \"Num classes mismatch!\"\n",
    "    print(\"  Размерности выхода (T_red, B, C) корректны.\"); model_created_successfully = True\n",
    "except Exception as e: print(f\"\\n!!! КРИТИЧЕСКАЯ ОШИБКА при создании/проверке модели: {e} !!!\"); traceback.print_exc()\n",
    "finally: # Очистка\n",
    "    if 'model_check' in locals(): del model_check\n",
    "    if 'dummy_input' in locals(): del dummy_input\n",
    "    if 'dummy_output' in locals(): del dummy_output\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "if not model_created_successfully: raise SystemExit(\"Остановка: Не удалось создать/проверить модель.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 7: Определение и проверка модели (ФИНАЛ) завершены ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 8: Loss, Optimizer, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 8: Настройка Loss, Optimizer, Scheduler ---\n",
      "Функция потерь: CTCLoss (blank=44, reduction='mean', zero_infinity=True)\n",
      "\n",
      "Оптимизатор: ADAMW (LR=1.0e-04, WD=1.0e-04) - будет создан в пайплайне\n",
      "Планировщик: OneCycleLR (div=10.0, final_div=10000) - будет создан в пайплайне\n",
      "\n",
      "--- Ячейка 8: Настройка Loss, Optimizer, Scheduler завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 8: Настройка Loss, Optimizer, Scheduler\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 8: Настройка Loss, Optimizer, Scheduler ---\")\n",
    "\n",
    "# Проверка зависимостей\n",
    "if 'BLANK_IDX' not in globals(): raise ValueError(\"BLANK_IDX не инициализирован!\")\n",
    "if 'TRAIN_CONFIG_FINAL' not in globals(): raise ValueError(\"TRAIN_CONFIG_FINAL не определен! Убедитесь, что Ячейка 2 выполнена.\")\n",
    "if 'optim' not in globals(): import torch.optim as optim\n",
    "if 'nn' not in globals(): import torch.nn as nn\n",
    "if 'OneCycleLR' not in globals(): from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# --- Функция Потерь ---\n",
    "# Используем CTCLoss, стандарт для задач sequence-to-sequence без выравнивания\n",
    "criterion = nn.CTCLoss(blank=BLANK_IDX, reduction='mean', zero_infinity=True)\n",
    "print(f\"Функция потерь: CTCLoss (blank={BLANK_IDX}, reduction='mean', zero_infinity=True)\")\n",
    "\n",
    "# --- Оптимизатор и Планировщик (параметры из TRAIN_CONFIG_FINAL) ---\n",
    "# Сами объекты optimizer и scheduler будут создаваться внутри run_training_pipeline\n",
    "optimizer_name = TRAIN_CONFIG_FINAL.get('optimizer', 'AdamW').lower()\n",
    "lr = TRAIN_CONFIG_FINAL['learning_rate']\n",
    "wd = TRAIN_CONFIG_FINAL['weight_decay']\n",
    "print(f\"\\nОптимизатор: {optimizer_name.upper()} (LR={lr:.1e}, WD={wd:.1e}) - будет создан в пайплайне\")\n",
    "\n",
    "div_f = TRAIN_CONFIG_FINAL.get('div_factor', 25.0)\n",
    "final_div_f = TRAIN_CONFIG_FINAL.get('final_div_factor', 1e4)\n",
    "print(f\"Планировщик: OneCycleLR (div={div_f}, final_div={final_div_f}) - будет создан в пайплайне\")\n",
    "\n",
    "print(\"\\n--- Ячейка 8: Настройка Loss, Optimizer, Scheduler завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 9: Функции Декодирования и Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 9: Определение функций декодирования и метрики ---\n",
      "Функции ctc_greedy_decode и calculate_levenshtein определены.\n",
      "\n",
      "--- Ячейка 9: Определение функций декодирования и метрики завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 9: Функции Декодирования (Greedy) и Метрики (Levenshtein)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 9: Определение функций декодирования и метрики ---\")\n",
    "\n",
    "# Импорты и проверки зависимостей\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "if 'index_to_char' not in globals(): raise ValueError(\"index_to_char не определен!\")\n",
    "if 'BLANK_IDX' not in globals(): raise ValueError(\"BLANK_IDX не определен!\")\n",
    "if 'PAD_IDX' not in globals(): raise ValueError(\"PAD_IDX не определен!\")\n",
    "if not LEVENSHTEIN_AVAILABLE: print(\"Предупреждение: Levenshtein не найден, используется заглушка.\")\n",
    "else: import Levenshtein # Импортируем, если доступен\n",
    "\n",
    "# --- Greedy CTC Decoding ---\n",
    "def ctc_greedy_decode(logits: torch.Tensor, index_to_char_map: Dict[int, str], blank_idx: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Жадное CTC декодирование батча логитов.\n",
    "    Input: logits (Time, Batch, Classes) - выход модели после log_softmax не нужен.\n",
    "    Output: List[str] - список декодированных строк для батча.\n",
    "    \"\"\"\n",
    "    decoded_batch = []\n",
    "    # Находим наиболее вероятный индекс для каждого временного шага в каждом примере батча\n",
    "    # Используем .detach() для экономии памяти, так как градиенты здесь не нужны\n",
    "    best_path = torch.argmax(logits.detach(), dim=2) # (Time, Batch)\n",
    "    best_path_np = best_path.cpu().numpy()\n",
    "\n",
    "    # Итерируем по каждому примеру в батче\n",
    "    for i in range(best_path_np.shape[1]):\n",
    "        sequence_indices = best_path_np[:, i]\n",
    "        # 1. Схлопываем повторяющиеся символы\n",
    "        collapsed_indices = [idx for j, idx in enumerate(sequence_indices) if j == 0 or idx != sequence_indices[j-1]]\n",
    "        # 2. Удаляем BLANK символы\n",
    "        final_indices = [idx for idx in collapsed_indices if idx != blank_idx]\n",
    "        # 3. Преобразуем индексы в символы\n",
    "        decoded_string = \"\".join([index_to_char_map.get(idx, '?') for idx in final_indices]) # '?' для неизвестных индексов\n",
    "        decoded_batch.append(decoded_string)\n",
    "    return decoded_batch\n",
    "\n",
    "# --- Levenshtein Distance ---\n",
    "def calculate_levenshtein(predictions: List[str], targets_padded: torch.Tensor, target_lengths: torch.Tensor,\n",
    "                          index_to_char_map: Dict[int, str], pad_idx: int) -> Tuple[float, List[Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Вычисляет среднее расстояние Левенштейна для батча и возвращает пары (предсказание, реальность).\n",
    "    Input:\n",
    "        predictions: List[str] - список предсказанных строк.\n",
    "        targets_padded: torch.Tensor (Batch, MaxTargetLen) - тензор реальных таргетов с паддингом.\n",
    "        target_lengths: torch.Tensor (Batch) - тензор реальных длин таргетов.\n",
    "        index_to_char_map: Dict[int, str] - словарь для преобразования индексов в символы.\n",
    "        pad_idx: int - индекс PAD токена.\n",
    "    Output:\n",
    "        Tuple[float, List[Tuple[str, str]]] - среднее расстояние Левенштейна, список пар (предсказание, реальность).\n",
    "    \"\"\"\n",
    "    total_distance = 0.0\n",
    "    num_valid_pairs = 0\n",
    "    decoded_pairs = [] # Список для хранения пар (предсказание, реальность)\n",
    "    targets_np = targets_padded.cpu().numpy()\n",
    "    target_lengths_np = target_lengths.cpu().numpy()\n",
    "    batch_size = targets_padded.shape[0]\n",
    "\n",
    "    # Проверка соответствия размеров предсказаний и таргетов\n",
    "    if len(predictions) != batch_size:\n",
    "        print(f\"Warning: Levenshtein size mismatch! Preds:{len(predictions)}, Targets:{batch_size}\")\n",
    "        return float('inf'), [] # Возвращаем бесконечность и пустой список\n",
    "\n",
    "    # Итерируем по каждому примеру в батче\n",
    "    for i in range(batch_size):\n",
    "        real_target_len = target_lengths_np[i]\n",
    "        pred_str = predictions[i]\n",
    "\n",
    "        # Получаем реальную строку таргета, удаляя паддинг\n",
    "        if real_target_len <= 0:\n",
    "            target_str = \"\"\n",
    "        else:\n",
    "            target_indices = targets_np[i, :real_target_len]\n",
    "            target_str = \"\".join([index_to_char_map.get(idx, '?') for idx in target_indices if idx != pad_idx])\n",
    "\n",
    "        try:\n",
    "            # Вычисляем расстояние Левенштейна\n",
    "            dist = Levenshtein.distance(pred_str, target_str)\n",
    "        except Exception as e:\n",
    "            # Обработка возможных ошибок в Levenshtein\n",
    "            print(f\"Levenshtein Error: ('{pred_str}', '{target_str}'). {e}\")\n",
    "            dist = max(len(pred_str), len(target_str)) # Используем максимальную длину как штраф\n",
    "\n",
    "        total_distance += dist\n",
    "        num_valid_pairs += 1\n",
    "        decoded_pairs.append((pred_str, target_str)) # Добавляем пару\n",
    "\n",
    "    # Вычисляем среднее расстояние\n",
    "    mean_levenshtein = total_distance / num_valid_pairs if num_valid_pairs > 0 else float('inf')\n",
    "    return mean_levenshtein, decoded_pairs\n",
    "\n",
    "print(\"Функции ctc_greedy_decode и calculate_levenshtein определены.\")\n",
    "print(\"\\n--- Ячейка 9: Определение функций декодирования и метрики завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 10: Функции Обучения и Валидации Эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 10: Определение функций обучения и валидации эпохи ---\n",
      "Функции train_epoch и validate_epoch определены.\n",
      "\n",
      "--- Ячейка 10: Определение функций обучения и валидации завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 10: Функции Обучения и Валидации Эпохи\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 10: Определение функций обучения и валидации эпохи ---\")\n",
    "\n",
    "# Импорты и проверки зависимостей\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import traceback\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "\n",
    "# Проверка наличия функций из Ячейки 9\n",
    "if 'ctc_greedy_decode' not in globals() or 'calculate_levenshtein' not in globals():\n",
    "    raise NameError(\"Функции ctc_greedy_decode или calculate_levenshtein не определены!\")\n",
    "\n",
    "# --- Функция Обучения Одной Эпохи ---\n",
    "def train_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.CTCLoss, optimizer: optim.Optimizer,\n",
    "                scheduler: Optional[optim.lr_scheduler._LRScheduler], device: torch.device, epoch_num: int, total_epochs: int,\n",
    "                index_to_char_map: Dict[int, str], blank_idx: int, pad_idx: int, grad_clip_norm: float,\n",
    "                batches_per_epoch: int = 0) -> Tuple[float, float, float]:\n",
    "    \"\"\" Выполняет одну эпоху обучения модели. \"\"\"\n",
    "    model.train() # Переключаем модель в режим обучения\n",
    "    running_loss = 0.0\n",
    "    total_lev_dist = 0.0\n",
    "    total_lr = 0.0\n",
    "    num_batches_processed = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Получаем фактор сжатия времени из модели (для расчета длин для CTC)\n",
    "    try:\n",
    "        time_factor = max(model.get_time_reduction_factor(), 1.0)\n",
    "    except AttributeError:\n",
    "        print(\"Warning: Метод get_time_reduction_factor() не найден в модели. Используется time_factor=1.0\")\n",
    "        time_factor = 1.0\n",
    "\n",
    "    # Определяем итератор и количество батчей для обработки\n",
    "    total_batches_in_loader = len(dataloader)\n",
    "    iterator = dataloader\n",
    "    num_batches_to_process = total_batches_in_loader\n",
    "    if batches_per_epoch > 0 and batches_per_epoch < total_batches_in_loader:\n",
    "         iterator = itertools.islice(dataloader, batches_per_epoch)\n",
    "         num_batches_to_process = batches_per_epoch\n",
    "    if num_batches_to_process == 0:\n",
    "        print(\"Warning: Нет батчей для обработки в train_epoch.\")\n",
    "        return 0.0, float('inf'), 0.0\n",
    "\n",
    "    # Создаем прогресс-бар\n",
    "    pbar = tqdm(iterator, total=num_batches_to_process, desc=f\"Эпоха {epoch_num}/{total_epochs} [Тренировка]\", leave=False, ncols=1000)\n",
    "\n",
    "    # Итерация по батчам\n",
    "    for batch_idx, batch_data in enumerate(pbar):\n",
    "        if batch_data is None: continue # Пропускаем батч, если collate_fn вернул None\n",
    "        features, targets, feature_lengths, target_lengths = batch_data\n",
    "        if features is None or targets is None or feature_lengths is None or target_lengths is None: continue\n",
    "\n",
    "        batch_size = features.size(0)\n",
    "        if batch_size == 0: continue\n",
    "\n",
    "        # Перемещаем данные на устройство\n",
    "        features = features.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        feature_lengths_cpu = feature_lengths.cpu() # Оставляем на CPU для CTC Loss\n",
    "        target_lengths_cpu = target_lengths.cpu()   # Оставляем на CPU для CTC Loss\n",
    "\n",
    "        # Рассчитываем длины выхода модели для CTC Loss\n",
    "        input_lengths_ctc = torch.floor(feature_lengths_cpu.float() / time_factor + 1e-9).long().clamp(min=1)\n",
    "\n",
    "        loss_value = float('inf')\n",
    "        lev_dist_batch = float('inf')\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        try:\n",
    "            optimizer.zero_grad() # Обнуляем градиенты\n",
    "\n",
    "            # Прямой проход через модель\n",
    "            logits = model(features) # Ожидаемый выход: (T_red, B, C)\n",
    "\n",
    "            if logits.shape[1] != batch_size:\n",
    "                print(f\"\\n!!! ERROR (Train): Batch size mismatch! Out:{logits.shape[1]} != In:{batch_size}. Skip batch.\")\n",
    "                continue\n",
    "\n",
    "            # Применяем log_softmax для CTC Loss\n",
    "            log_probs = F.log_softmax(logits, dim=2) # (T_red, B, C)\n",
    "\n",
    "            # Убеждаемся, что длины входа для CTC не превышают реальную длину выхода модели\n",
    "            output_length = log_probs.shape[0]\n",
    "            input_lengths_ctc_clamped = input_lengths_ctc.clamp(max=output_length)\n",
    "\n",
    "            # Убеждаемся, что длины таргетов не превышают размерность тензора таргетов\n",
    "            target_lengths_clamped = target_lengths_cpu.clamp(max=targets.shape[1])\n",
    "\n",
    "            # Вычисляем CTC Loss, обрабатывая случай нулевых длин таргетов\n",
    "            valid_target_mask = target_lengths_clamped > 0\n",
    "            if not torch.all(valid_target_mask):\n",
    "                 log_probs_valid = log_probs[:, valid_target_mask, :]\n",
    "                 targets_valid = targets[valid_target_mask, :]\n",
    "                 input_lengths_valid = input_lengths_ctc_clamped[valid_target_mask]\n",
    "                 target_lengths_valid = target_lengths_clamped[valid_target_mask]\n",
    "                 # Считаем loss только если есть валидные примеры\n",
    "                 loss = criterion(log_probs_valid, targets_valid, input_lengths_valid, target_lengths_valid) if log_probs_valid.shape[1] > 0 else torch.tensor(0.0, device=device)\n",
    "            else:\n",
    "                 loss = criterion(log_probs, targets, input_lengths_ctc_clamped, target_lengths_clamped)\n",
    "\n",
    "            # Проверка на NaN/Inf в loss\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"\\n!!! WARNING (Train): NaN/Inf loss на батче {batch_idx}! Пропуск шага оптимизатора.\")\n",
    "                optimizer.zero_grad()\n",
    "                loss_value = 30.0 # Штраф для логгирования\n",
    "                lev_dist_batch = 30.0\n",
    "                continue # Переходим к следующему батчу\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "            # Обратный проход и шаг оптимизатора\n",
    "            if loss.requires_grad:\n",
    "                loss.backward()\n",
    "                if grad_clip_norm > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_norm)\n",
    "                optimizer.step()\n",
    "                if scheduler:\n",
    "                    scheduler.step() # OneCycleLR обновляется после каждого батча\n",
    "\n",
    "            # Вычисление метрики Levenshtein (без градиентов)\n",
    "            # Делаем это после шага оптимизатора, чтобы не замедлять цикл\n",
    "            decoded_preds = ctc_greedy_decode(logits, index_to_char_map, blank_idx) # logits уже посчитаны\n",
    "            lev_dist_batch, _ = calculate_levenshtein(decoded_preds, targets.cpu(), target_lengths_cpu, index_to_char_map, pad_idx)\n",
    "            if not np.isfinite(lev_dist_batch): lev_dist_batch = 20.0 # Ограничиваем для логгирования\n",
    "\n",
    "        except RuntimeError as e:\n",
    "             if \"CUDA out of memory\" in str(e):\n",
    "                 print(\"\\n!!! CUDA Out of Memory (Train) !!! Попробуйте уменьшить batch_size.\")\n",
    "                 raise e # Перевыбрасываем ошибку\n",
    "             else:\n",
    "                 print(f\"\\n!!! RuntimeError (Train) на батче {batch_idx}: {e} !!!\")\n",
    "                 traceback.print_exc(limit=1)\n",
    "                 loss_value = 30.0; lev_dist_batch = 30.0\n",
    "        except Exception as e:\n",
    "             print(f\"\\n!!! Error (Train) на батче {batch_idx}: {e} !!!\")\n",
    "             traceback.print_exc(limit=1)\n",
    "             loss_value = 30.0; lev_dist_batch = 30.0\n",
    "\n",
    "        # Обновление статистики эпохи\n",
    "        running_loss += loss_value * batch_size\n",
    "        total_lev_dist += lev_dist_batch * batch_size\n",
    "        total_samples += batch_size\n",
    "        total_lr += current_lr\n",
    "        num_batches_processed += 1\n",
    "\n",
    "        # Обновление прогресс-бара\n",
    "        pbar.set_postfix(loss=f'{loss_value:.3f}', lev=f'{lev_dist_batch:.3f}', lr=f'{current_lr:.2e}')\n",
    "\n",
    "    pbar.close() # Закрываем прогресс-бар\n",
    "\n",
    "    # Вычисляем средние значения за эпоху\n",
    "    avg_loss = running_loss / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lev = total_lev_dist / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lr = total_lr / num_batches_processed if num_batches_processed > 0 else 0.0\n",
    "\n",
    "    return avg_loss, avg_lev, avg_lr\n",
    "\n",
    "# --- Функция Валидации Одной Эпохи ---\n",
    "def validate_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.CTCLoss, device: torch.device,\n",
    "                   index_to_char_map: Dict[int, str], blank_idx: int, pad_idx: int\n",
    "                  ) -> Tuple[float, float, List[Tuple[str, str]]]:\n",
    "    \"\"\" Выполняет одну эпоху валидации модели. \"\"\"\n",
    "    model.eval() # Переключаем модель в режим оценки\n",
    "    running_loss = 0.0\n",
    "    total_lev_dist = 0.0\n",
    "    total_samples = 0\n",
    "    all_decoded_pairs = [] # Список для примеров декодирования\n",
    "\n",
    "    # Получаем фактор сжатия времени\n",
    "    try: time_factor = max(model.get_time_reduction_factor(), 1.0)\n",
    "    except AttributeError: time_factor = 1.0\n",
    "\n",
    "    # Создаем прогресс-бар\n",
    "    pbar = tqdm(dataloader, desc=\"   [Валидация]\", leave=False, ncols=1000)\n",
    "\n",
    "    # Отключаем расчет градиентов\n",
    "    with torch.no_grad():\n",
    "        # Итерация по батчам\n",
    "        for batch_data in pbar:\n",
    "            if batch_data is None: continue\n",
    "            features, targets, feature_lengths, target_lengths = batch_data\n",
    "            if features is None or targets is None or feature_lengths is None or target_lengths is None: continue\n",
    "\n",
    "            batch_size = features.size(0)\n",
    "            if batch_size == 0: continue\n",
    "\n",
    "            # Перемещаем данные на устройство\n",
    "            features = features.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            feature_lengths_cpu = feature_lengths.cpu()\n",
    "            target_lengths_cpu = target_lengths.cpu()\n",
    "\n",
    "            # Рассчитываем длины для CTC\n",
    "            input_lengths_ctc = torch.floor(feature_lengths_cpu.float() / time_factor + 1e-9).long().clamp(min=1)\n",
    "\n",
    "            loss_value = float('inf')\n",
    "            lev_dist_batch = float('inf')\n",
    "            decoded_pairs_batch = []\n",
    "\n",
    "            try:\n",
    "                # Прямой проход\n",
    "                logits = model(features) # (T_red, B, C)\n",
    "                output_length = logits.shape[0]\n",
    "\n",
    "                if logits.shape[1] != batch_size:\n",
    "                    print(f\"\\n!!! ERROR (Val): Batch size mismatch! Out:{logits.shape[1]} != In:{batch_size}. Skip batch.\")\n",
    "                    continue\n",
    "\n",
    "                # Log_softmax для CTC\n",
    "                log_probs = F.log_softmax(logits, dim=2)\n",
    "\n",
    "                # Клампинг длин\n",
    "                input_lengths_ctc_clamped = input_lengths_ctc.clamp(max=output_length)\n",
    "                target_lengths_clamped = target_lengths_cpu.clamp(max=targets.shape[1])\n",
    "\n",
    "                # Расчет Loss\n",
    "                valid_target_mask = target_lengths_clamped > 0\n",
    "                if not torch.all(valid_target_mask):\n",
    "                    log_probs_valid = log_probs[:, valid_target_mask, :]\n",
    "                    targets_valid = targets[valid_target_mask, :]\n",
    "                    input_lengths_valid = input_lengths_ctc_clamped[valid_target_mask]\n",
    "                    target_lengths_valid = target_lengths_clamped[valid_target_mask]\n",
    "                    loss = criterion(log_probs_valid, targets_valid, input_lengths_valid, target_lengths_valid) if log_probs_valid.shape[1] > 0 else torch.tensor(0.0, device=device)\n",
    "                else:\n",
    "                    loss = criterion(log_probs, targets, input_lengths_ctc_clamped, target_lengths_clamped)\n",
    "\n",
    "                if torch.isfinite(loss): loss_value = loss.item()\n",
    "                else: print(\"\\nWarning (Val): NaN/Inf loss.\")\n",
    "\n",
    "                # Декодирование и расчет Levenshtein\n",
    "                decoded_preds = ctc_greedy_decode(logits, index_to_char_map, blank_idx)\n",
    "                lev_dist_batch, decoded_pairs_batch = calculate_levenshtein(decoded_preds, targets.cpu(), target_lengths_cpu, index_to_char_map, pad_idx)\n",
    "                if not np.isfinite(lev_dist_batch): lev_dist_batch = 20.0\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n!!! Error (Val): {e} !!!\")\n",
    "                traceback.print_exc(limit=1)\n",
    "                loss_value=float('inf'); lev_dist_batch=float('inf')\n",
    "                decoded_pairs_batch = [(\"ERROR\",\"ERROR\")] * batch_size # Заполняем ошибками\n",
    "\n",
    "            # Обновление статистики эпохи\n",
    "            if np.isfinite(loss_value): # Учитываем только конечные значения loss\n",
    "                running_loss += loss_value * batch_size\n",
    "            total_lev_dist += lev_dist_batch * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # Сохраняем несколько примеров декодирования для вывода\n",
    "            if len(all_decoded_pairs) < 10: # Сохраняем первые 10 пар\n",
    "                all_decoded_pairs.extend(decoded_pairs_batch[:max(0, 10 - len(all_decoded_pairs))])\n",
    "\n",
    "            # Обновление прогресс-бара\n",
    "            pbar.set_postfix(loss=f'{loss_value:.3f}', lev=f'{lev_dist_batch:.3f}')\n",
    "\n",
    "    pbar.close() # Закрываем прогресс-бар\n",
    "\n",
    "    # Вычисляем средние значения за эпоху\n",
    "    avg_loss = running_loss / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lev = total_lev_dist / total_samples if total_samples > 0 else float('inf')\n",
    "\n",
    "    return avg_loss, avg_lev, all_decoded_pairs\n",
    "\n",
    "print(\"Функции train_epoch и validate_epoch определены.\")\n",
    "print(\"\\n--- Ячейка 10: Определение функций обучения и валидации завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 11 Интерактивная настройка RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 11: Интерактивная Настройка Мел-Спектрограмм (SR=8000 Гц) ---\n",
      "Выберите файл и настройте параметры для визуализации:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfc8c0f9e2d40a2a01d50ed65a5cd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Файл:', options=('2309.opus', '22405.opus', '23398.opus', '25059.opus', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ячейка 11: Завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 11: Интерактивная Настройка Мел-Спектрограмм (Опционально)\n",
    "# =============================================================================\n",
    "print(f\"--- Ячейка 11: Интерактивная Настройка Мел-Спектрограмм (SR={AUDIO_CONFIG['sample_rate']} Гц) ---\")\n",
    "\n",
    "if not IPYWIDGETS_AVAILABLE:\n",
    "    print(\"Виджеты недоступны. Пропустите эту ячейку или установите ipywidgets.\")\n",
    "else:\n",
    "    # --- Функции для Визуализации ---\n",
    "    def plot_mel_spectrogram_interactive(y, sr, n_fft, hop_length, n_mels, fmin, fmax, file_id=\"\"):\n",
    "        \"\"\"Строит Мел-спектрограмму.\"\"\"\n",
    "        try:\n",
    "            S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "            S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            librosa.display.specshow(S_dB, sr=sr, hop_length=hop_length, x_axis='time', y_axis='mel', fmin=fmin, fmax=fmax)\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.title(f'Мел-Спектрограмма ({file_id})\\nn_fft={n_fft}, hop={hop_length}, n_mels={n_mels}, fmax={fmax:.0f}Hz')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при построении спектрограммы: {e}\")\n",
    "\n",
    "    def plot_waveform_interactive(y, sr, file_id=\"\"):\n",
    "        \"\"\"Строит волновую форму.\"\"\"\n",
    "        plt.figure(figsize=(12, 2))\n",
    "        librosa.display.waveshow(y, sr=sr, alpha=0.7)\n",
    "        plt.title(f'Волновая форма ({file_id})')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # --- Виджеты ---\n",
    "    # Используем значения из финального AUDIO_CONFIG\n",
    "    default_sr = AUDIO_CONFIG['sample_rate']\n",
    "    default_hop = AUDIO_CONFIG['hop_length']\n",
    "    default_nmels = AUDIO_CONFIG['n_mels']\n",
    "    default_nfft = AUDIO_CONFIG['n_fft']\n",
    "    default_fmin = AUDIO_CONFIG['fmin']\n",
    "    default_fmax = AUDIO_CONFIG['fmax']\n",
    "\n",
    "    # Выбираем несколько файлов для примера\n",
    "    example_files = train_df['id'].sample(min(5, len(train_df)), random_state=SEED).tolist()\n",
    "\n",
    "    file_selector = widgets.Dropdown(options=example_files, description='Файл:')\n",
    "    # Добавим слайдеры для ключевых параметров, чтобы можно было поиграть\n",
    "    n_fft_slider = widgets.SelectionSlider(options=[32, 64, 128, 256, 512], value=default_nfft, description='n_fft:', continuous_update=False)\n",
    "    hop_length_slider = widgets.IntSlider(value=default_hop, min=16, max=256, step=16, description='hop_length:', continuous_update=False)\n",
    "    n_mels_slider = widgets.IntSlider(value=default_nmels, min=8, max=64, step=4, description='n_mels:', continuous_update=False)\n",
    "    fmax_slider = widgets.IntSlider(value=int(default_fmax), min=1000, max=default_sr//2, step=100, description='fmax (Hz):', continuous_update=False)\n",
    "\n",
    "    plot_output = widgets.Output() # Место для вывода графиков\n",
    "\n",
    "    def update_plot_interactive(change):\n",
    "        \"\"\"Обновляет графики при изменении виджетов.\"\"\"\n",
    "        with plot_output:\n",
    "            clear_output(wait=True) # Очищаем предыдущий вывод\n",
    "            file_id = file_selector.value\n",
    "            n_fft_val = n_fft_slider.value\n",
    "            hop_val = hop_length_slider.value\n",
    "            n_mels_val = n_mels_slider.value\n",
    "            fmax_val = float(fmax_slider.value)\n",
    "            fmin_val = default_fmin # Оставляем fmin фиксированным\n",
    "\n",
    "            if not file_id:\n",
    "                print(\"Выберите файл.\")\n",
    "                return\n",
    "\n",
    "            audio_path = EXTRACTED_AUDIO_DIR / file_id\n",
    "            if not audio_path.is_file():\n",
    "                print(f\"Файл не найден: {audio_path}\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                y, sr_loaded = librosa.load(audio_path, sr=default_sr) # Загружаем с нужной SR\n",
    "                if sr_loaded != default_sr:\n",
    "                     print(f\"Предупреждение: SR файла ({sr_loaded}) отличается от целевой ({default_sr}). Выполнено ресэмплирование.\")\n",
    "\n",
    "                # Строим графики\n",
    "                print(f\"Параметры: n_fft={n_fft_val}, hop={hop_val}, n_mels={n_mels_val}, fmax={fmax_val:.0f}Hz\")\n",
    "                plot_waveform_interactive(y, default_sr, file_id)\n",
    "                plot_mel_spectrogram_interactive(y, default_sr, n_fft_val, hop_val, n_mels_val, fmin_val, fmax_val, file_id)\n",
    "                # Отображаем аудио для прослушивания\n",
    "                display(Audio(data=y, rate=default_sr))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при обработке файла {file_id}: {e}\")\n",
    "                traceback.print_exc(limit=1)\n",
    "\n",
    "    # Привязываем обработчик к изменению виджетов\n",
    "    file_selector.observe(update_plot_interactive, names='value')\n",
    "    n_fft_slider.observe(update_plot_interactive, names='value')\n",
    "    hop_length_slider.observe(update_plot_interactive, names='value')\n",
    "    n_mels_slider.observe(update_plot_interactive, names='value')\n",
    "    fmax_slider.observe(update_plot_interactive, names='value')\n",
    "\n",
    "    # Отображаем виджеты и запускаем первое обновление\n",
    "    print(\"Выберите файл и настройте параметры для визуализации:\")\n",
    "    display(widgets.VBox([file_selector, n_fft_slider, hop_length_slider, n_mels_slider, fmax_slider, plot_output]))\n",
    "    update_plot_interactive(None) # Первоначальный вызов для отображения\n",
    "\n",
    "print(\"\\n--- Ячейка 11: Завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 12: Функция Полного Цикла Обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 12: Определение функции run_training_pipeline ---\n",
      "--- Функция run_training_pipeline определена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 12: Функция для Полного Цикла Обучения и Инференса (run_training_pipeline)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 12: Определение функции run_training_pipeline ---\")\n",
    "\n",
    "# Импорты, необходимые внутри функции\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import numpy as np, pandas as pd, time, json, random, traceback\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Union, Tuple, List, Dict, Optional\n",
    "\n",
    "# --- MLflow Заглушка (если MLflow не установлен) ---\n",
    "if not MLFLOW_AVAILABLE:\n",
    "    class DummyRun:\n",
    "        def __enter__(self): return self\n",
    "        def __exit__(self, *args): pass\n",
    "        class DummyRunInfo: info = type('obj', (object,), {'run_id': 'mlflow_disabled'})()\n",
    "        info = DummyRunInfo()\n",
    "    class DummyMLflow:\n",
    "        def set_experiment(self, *args, **kwargs): pass\n",
    "        def start_run(self, *args, **kwargs): return DummyRun()\n",
    "        def log_param(self, *args, **kwargs): pass\n",
    "        def log_params(self, *args, **kwargs): pass\n",
    "        def log_metric(self, *args, **kwargs): pass\n",
    "        def log_metrics(self, *args, **kwargs): pass\n",
    "        def log_artifact(self, *args, **kwargs): pass\n",
    "        def log_dict(self, *args, **kwargs): pass\n",
    "        def set_tag(self, *args, **kwargs): pass\n",
    "        def active_run(self): return None\n",
    "        def end_run(self, status='FINISHED'): pass\n",
    "    mlflow = DummyMLflow()\n",
    "    print(\"Используется заглушка для MLflow.\")\n",
    "# --- Конец MLflow Заглушки ---\n",
    "\n",
    "# --- Проверка глобальных зависимостей пайплайна ---\n",
    "def check_global_dependencies():\n",
    "    \"\"\"Проверяет наличие необходимых классов и функций в глобальной области видимости.\"\"\"\n",
    "    required = ['MorseDataset', 'MorseRecognizer', 'collate_fn', 'train_epoch', 'validate_epoch',\n",
    "                'ctc_greedy_decode', 'calculate_levenshtein', 'set_seed']\n",
    "    missing = [r for r in required if not callable(globals().get(r))]\n",
    "    if missing: raise NameError(f\"Отсутствуют зависимости: {missing}. Убедитесь, что все ячейки выше выполнены.\")\n",
    "\n",
    "# --- Основная функция пайплайна ---\n",
    "def run_training_pipeline(\n",
    "    # Конфигурации\n",
    "    audio_config: Dict, model_config: Dict, train_config: Dict,\n",
    "    # Данные и пути\n",
    "    full_train_df: pd.DataFrame, test_df: pd.DataFrame, audio_dir: Path, base_output_dir: Path,\n",
    "    # Словари и константы\n",
    "    char_to_index: Dict[str, int], index_to_char: Dict[int, str],\n",
    "    blank_idx: int, pad_idx: int, num_classes_ctc: int,\n",
    "    # Управление\n",
    "    device: torch.device, run_suffix: str, base_filename_suffix: str,\n",
    "    seed: int = 42, mlflow_experiment_name: str = \"Morse_Experiment\"\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Выполняет полный цикл: подготовка данных, обучение модели, валидация,\n",
    "    сохранение лучшей модели и параметров, инференс на тестовых данных,\n",
    "    сохранение submission файла и логирование в MLflow.\n",
    "    \"\"\"\n",
    "    check_global_dependencies() # Проверяем наличие функций и классов\n",
    "\n",
    "    # Словарь для хранения результатов этого запуска\n",
    "    run_results = {\n",
    "        \"run_suffix\": run_suffix, \"status\": \"pending\", \"best_val_lev\": float('inf'),\n",
    "        \"best_epoch\": None, \"final_train_loss\": float('inf'), \"final_val_loss\": float('inf'),\n",
    "        \"train_time_min\": 0.0, \"infer_time_sec\": 0.0, \"model_path\": None,\n",
    "        \"params_path\": None, \"submission_path\": None, \"error\": None, \"mlflow_run_id\": None\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{'='*20} Запуск: {run_suffix} {'='*20}\")\n",
    "    print(f\"Audio Config: {json.dumps(audio_config)}\")\n",
    "    print(f\"Model Config: {json.dumps(model_config)}\")\n",
    "    print(f\"Train Config: {json.dumps(train_config)}\")\n",
    "\n",
    "    # Формирование путей для сохранения артефактов\n",
    "    output_filename_base = f\"{base_filename_suffix}{run_suffix}\"\n",
    "    current_model_path = base_output_dir / f\"model_{output_filename_base}.pth\"\n",
    "    current_params_path = base_output_dir / f\"params_{output_filename_base}.json\"\n",
    "    current_submission_path = base_output_dir / f\"submission_greedy_{output_filename_base}.csv\"\n",
    "    run_results.update({\n",
    "        \"model_path\": str(current_model_path),\n",
    "        \"params_path\": str(current_params_path),\n",
    "        \"submission_path\": str(current_submission_path)\n",
    "    })\n",
    "    print(f\"  Пути вывода: Model={current_model_path.name}, Params={current_params_path.name}, Sub={current_submission_path.name}\")\n",
    "\n",
    "    # Объявление переменных для блока finally\n",
    "    model = None; criterion = None; optimizer = None; scheduler = None\n",
    "    full_dataset = None; train_subset = None; val_subset = None\n",
    "    train_loader = None; val_loader = None\n",
    "    inference_model_instance = None; infer_test_dataset = None; test_loader_infer = None\n",
    "    logits_infer = None; features_infer = None\n",
    "    best_model_local_path_temp = None # Инициализируем здесь\n",
    "\n",
    "    try:\n",
    "        # Установка SEED для воспроизводимости\n",
    "        set_seed(seed)\n",
    "\n",
    "        # --- 1. Подготовка Данных ---\n",
    "        print(\"\\n1. Подготовка данных...\")\n",
    "        full_dataset = MorseDataset(\n",
    "            dataframe=full_train_df, audio_dir=audio_dir, char_to_index=char_to_index,\n",
    "            audio_config=audio_config,\n",
    "            model_input_feature_dim=model_config['input_feature_dim'],\n",
    "            is_train=True\n",
    "        )\n",
    "        dataset_size = len(full_dataset)\n",
    "        if dataset_size == 0: raise ValueError(\"Обучающий датасет пуст после инициализации!\")\n",
    "\n",
    "        val_split_ratio = train_config['validation_split_ratio']\n",
    "        val_size = int(np.floor(val_split_ratio * dataset_size))\n",
    "        train_size = dataset_size - val_size\n",
    "        if train_size <= 0 or val_size <= 0: raise ValueError(f\"Некорректное разделение: Train={train_size}, Val={val_size}\")\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "        train_subset, val_subset = random_split(full_dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "        bs = train_config['batch_size']; nw = train_config['num_workers']; pm = (device.type == 'cuda')\n",
    "        train_loader = DataLoader(train_subset, batch_size=bs, shuffle=True, collate_fn=collate_fn, num_workers=nw, pin_memory=pm, drop_last=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=bs*2, shuffle=False, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "        print(f\"  Данные готовы: Train={len(train_subset)} ({len(train_loader)} батчей), Val={len(val_subset)} ({len(val_loader)} батчей).\")\n",
    "\n",
    "        # --- 2. Инициализация Модели, Loss, Optimizer, Scheduler ---\n",
    "        print(\"\\n2. Инициализация компонентов...\")\n",
    "        model = MorseRecognizer(num_classes_ctc=num_classes_ctc, **model_config).to(device)\n",
    "        criterion = nn.CTCLoss(blank=blank_idx, reduction='mean', zero_infinity=True).to(device)\n",
    "        optimizer_name = train_config.get('optimizer', 'AdamW').lower(); lr = train_config['learning_rate']; wd = train_config['weight_decay']\n",
    "        if optimizer_name == 'adamw': optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        elif optimizer_name == 'adam': optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        else: print(f\"Warning: Неизвестный optimizer '{optimizer_name}'. Используется AdamW.\"); optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        print(f\"  Model, Loss, Optimizer ({type(optimizer).__name__}) готовы.\")\n",
    "\n",
    "        total_batches_in_loader = len(train_loader); batches_per_epoch_run = train_config.get(\"batches_per_epoch\", 0)\n",
    "        steps_per_epoch = total_batches_in_loader\n",
    "        if batches_per_epoch_run > 0 and batches_per_epoch_run < total_batches_in_loader: steps_per_epoch = batches_per_epoch_run\n",
    "        if steps_per_epoch <= 0: raise ValueError(f\"Steps_per_epoch ({steps_per_epoch}) должен быть > 0!\")\n",
    "        total_steps = train_config['num_epochs'] * steps_per_epoch\n",
    "        div_f = train_config.get('div_factor', 25.0); final_div_f = train_config.get('final_div_factor', 1e4)\n",
    "        scheduler = OneCycleLR(optimizer, max_lr=lr, total_steps=total_steps, pct_start=0.3, anneal_strategy='cos', div_factor=div_f, final_div_factor=final_div_f)\n",
    "        print(f\"  Scheduler OneCycleLR создан (total_steps={total_steps}).\")\n",
    "\n",
    "        # --- 3. Цикл Обучения с MLflow ---\n",
    "        print(\"\\n3. Запуск цикла обучения...\")\n",
    "        mlflow.set_experiment(mlflow_experiment_name)\n",
    "        with mlflow.start_run(run_name=f\"run_{run_suffix}\") as current_run:\n",
    "            mlflow_run_id = current_run.info.run_id\n",
    "            print(f\"  MLflow Run ID: {mlflow_run_id}\")\n",
    "            run_results[\"mlflow_run_id\"] = mlflow_run_id\n",
    "            run_results[\"status\"] = \"training\"\n",
    "            # Логирование параметров запуска\n",
    "            mlflow.log_param(\"run_suffix\", run_suffix)\n",
    "            mlflow.log_param(\"base_filename\", base_filename_suffix)\n",
    "            mlflow.log_params({\"seed\": seed, **train_config})\n",
    "            mlflow.log_dict(audio_config, \"audio_config.json\")\n",
    "            mlflow.log_dict(model_config, \"model_config.json\")\n",
    "            mlflow.set_tag(\"status\", \"training\")\n",
    "\n",
    "            start_time_train = time.time()\n",
    "            best_val_lev = float('inf')\n",
    "            epochs_without_improvement = 0\n",
    "            best_epoch = None\n",
    "            # Путь для временного сохранения лучшей модели локально\n",
    "            best_model_local_path_temp = base_output_dir / f\"temp_best_model_{mlflow_run_id}.pth\"\n",
    "\n",
    "            # Основной цикл по эпохам\n",
    "            for epoch in range(1, train_config['num_epochs'] + 1):\n",
    "                print(f\"\\n--- Эпоха {epoch}/{train_config['num_epochs']} ---\")\n",
    "                avg_train_loss, avg_train_lev, avg_epoch_lr = train_epoch(\n",
    "                    model, train_loader, criterion, optimizer, scheduler, device, epoch,\n",
    "                    train_config['num_epochs'], index_to_char, blank_idx, pad_idx,\n",
    "                    train_config['gradient_clip_norm'], batches_per_epoch=batches_per_epoch_run\n",
    "                )\n",
    "                avg_val_loss, avg_val_lev, decoded_examples = validate_epoch(\n",
    "                    model, val_loader, criterion, device, index_to_char, blank_idx, pad_idx\n",
    "                )\n",
    "\n",
    "                run_results.update({ \"final_train_loss\": avg_train_loss, \"final_val_loss\": avg_val_loss })\n",
    "                mlflow.log_metrics({\n",
    "                    \"train_loss\": avg_train_loss, \"train_levenshtein\": avg_train_lev,\n",
    "                    \"val_loss\": avg_val_loss, \"val_levenshtein\": avg_val_lev,\n",
    "                    \"learning_rate\": avg_epoch_lr\n",
    "                }, step=epoch)\n",
    "                print(f\"  Итоги Эпохи {epoch}: Train Loss={avg_train_loss:.4f}, Train Lev={avg_train_lev:.4f}, Val Loss={avg_val_loss:.4f}, Val Lev={avg_val_lev:.4f}\")\n",
    "                print(\"  Примеры декодирования (Предсказание | Реалность):\")\n",
    "                for pred, real in decoded_examples: print(f\"    '{pred}' | '{real}'\")\n",
    "\n",
    "                # Логика сохранения лучшей модели и ранней остановки\n",
    "                if np.isfinite(avg_val_lev) and avg_val_lev < best_val_lev:\n",
    "                    print(f\"  ✨ Val Lev улучшился: {best_val_lev:.4f} -> {avg_val_lev:.4f}. Сохранение лучшей модели...\")\n",
    "                    best_val_lev = avg_val_lev\n",
    "                    best_epoch = epoch\n",
    "                    run_results.update({ \"best_val_lev\": best_val_lev, \"best_epoch\": best_epoch })\n",
    "                    try:\n",
    "                        # Сохраняем модель локально (временно)\n",
    "                        torch.save(model.state_dict(), best_model_local_path_temp)\n",
    "                    except Exception as save_err:\n",
    "                        print(f\"  !!! Ошибка сохранения временной модели: {save_err} !!!\")\n",
    "                    epochs_without_improvement = 0\n",
    "                else:\n",
    "                    epochs_without_improvement += 1\n",
    "                    print(f\"  Val Lev не улучшился ({avg_val_lev:.4f} vs best {best_val_lev:.4f}). Без улучшений: {epochs_without_improvement}/{train_config['early_stopping_patience']}\")\n",
    "\n",
    "                if epochs_without_improvement >= train_config['early_stopping_patience']:\n",
    "                    print(f\"  ❗️ Ранняя остановка на эпохе {epoch}!\")\n",
    "                    mlflow.set_tag(\"status\", \"completed_early_stopping\")\n",
    "                    run_results[\"status\"] = \"completed_early_stopping\"\n",
    "                    break\n",
    "            # --- Конец цикла по эпохам ---\n",
    "\n",
    "            if run_results[\"status\"] == \"training\":\n",
    "                run_results[\"status\"] = \"completed\"\n",
    "                mlflow.set_tag(\"status\", \"completed\")\n",
    "\n",
    "            train_duration_min = (time.time() - start_time_train) / 60\n",
    "            run_results[\"train_time_min\"] = train_duration_min\n",
    "            print(f\"\\n  Обучение завершено ({run_results['status']}) за {train_duration_min:.2f} мин. Лучший Val Lev: {best_val_lev:.4f} (Эпоха {best_epoch})\")\n",
    "\n",
    "            # --- 4. Сохранение Лучшей Модели и Параметров ---\n",
    "            print(\"\\n4. Сохранение артефактов...\")\n",
    "            if np.isfinite(best_val_lev): mlflow.log_metric(\"best_val_levenshtein\", best_val_lev)\n",
    "            if best_epoch is not None: mlflow.log_metric(\"best_epoch\", best_epoch)\n",
    "            mlflow.log_metric(\"training_time_min\", train_duration_min)\n",
    "\n",
    "            model_saved_final = False\n",
    "            if best_model_local_path_temp is not None and best_model_local_path_temp.exists() and np.isfinite(best_val_lev):\n",
    "                try:\n",
    "                    current_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    current_model_path.unlink(missing_ok=True)\n",
    "                    best_model_local_path_temp.rename(current_model_path)\n",
    "                    print(f\"  Лучшая модель сохранена: {current_model_path.name}\")\n",
    "                    mlflow.log_artifact(str(current_model_path), artifact_path=\"model\")\n",
    "                    model_saved_final = True\n",
    "                except Exception as e:\n",
    "                    print(f\"  !!! Ошибка перемещения/логирования модели: {e} !!!\")\n",
    "                    if best_model_local_path_temp.exists(): best_model_local_path_temp.unlink()\n",
    "            else:\n",
    "                print(\"  !!! Лучшая модель не найдена или невалидна. Сохранение пропущено.\")\n",
    "                mlflow.set_tag(\"model_saved\", \"False\")\n",
    "                if best_model_local_path_temp is not None and best_model_local_path_temp.exists(): best_model_local_path_temp.unlink()\n",
    "\n",
    "            # Сохранение финальных параметров запуска в JSON\n",
    "            final_params = {\n",
    "                'audio_config': audio_config, 'model_config': model_config, 'train_config': train_config,\n",
    "                'char_map': { 'char_to_index': char_to_index, 'index_to_char': {str(k): v for k, v in index_to_char.items()},\n",
    "                              'BLANK_IDX': blank_idx, 'PAD_IDX': pad_idx, 'NUM_CLASSES_CTC': num_classes_ctc },\n",
    "                'results': { k: v for k, v in run_results.items() if k not in ['model_path', 'params_path', 'submission_path', 'mlflow_run_id'] and\n",
    "                             (np.isfinite(v) if isinstance(v, (float, int)) else v is not None) }\n",
    "            }\n",
    "            try:\n",
    "                current_params_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                current_params_path.unlink(missing_ok=True)\n",
    "                with open(current_params_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(final_params, f, indent=4, ensure_ascii=False)\n",
    "                print(f\"  Параметры сохранены: {current_params_path.name}\")\n",
    "                mlflow.log_artifact(str(current_params_path), artifact_path=\"config\")\n",
    "            except Exception as e: print(f\"  !!! Ошибка сохранения/логирования параметров: {e} !!!\")\n",
    "        # --- Конец MLflow run ---\n",
    "\n",
    "        # --- 5. Инференс на Тестовых Данных ---\n",
    "        print(\"\\n5. Запуск инференса...\")\n",
    "        infer_duration_sec = 0.0\n",
    "        if model_saved_final:\n",
    "            infer_start_time = time.time()\n",
    "            try:\n",
    "                 print(f\"  Загрузка артефактов для инференса: {current_model_path.name}, {current_params_path.name}\")\n",
    "                 with open(current_params_path, 'r', encoding='utf-8') as f: loaded_params_inf = json.load(f)\n",
    "                 loaded_audio_config_inf = loaded_params_inf['audio_config']\n",
    "                 loaded_model_config_inf = loaded_params_inf['model_config']\n",
    "                 loaded_char_map_inf = loaded_params_inf['char_map']\n",
    "                 loaded_index_to_char_inf = {int(k): v for k, v in loaded_char_map_inf['index_to_char'].items()}\n",
    "                 loaded_blank_idx_inf = loaded_char_map_inf['BLANK_IDX']\n",
    "                 loaded_num_classes_inf = loaded_char_map_inf['NUM_CLASSES_CTC']\n",
    "\n",
    "                 inference_model_instance = MorseRecognizer(num_classes_ctc=loaded_num_classes_inf, **loaded_model_config_inf).to(device)\n",
    "                 try: # Пытаемся загрузить только веса\n",
    "                     inference_model_instance.load_state_dict(torch.load(current_model_path, map_location=device, weights_only=True))\n",
    "                 except (TypeError, AttributeError):\n",
    "                     print(\"   Warning: weights_only=True не поддерживается/вызвал ошибку. Загрузка стандартным способом.\")\n",
    "                     inference_model_instance.load_state_dict(torch.load(current_model_path, map_location=device))\n",
    "                 inference_model_instance.eval()\n",
    "                 print(f\"  Модель для инференса загружена и переведена в режим eval().\")\n",
    "\n",
    "                 print(f\"  Создание тестового DataLoader...\")\n",
    "                 infer_test_dataset = MorseDataset(\n",
    "                     dataframe=test_df, audio_dir=audio_dir, char_to_index=loaded_char_map_inf['char_to_index'],\n",
    "                     audio_config=loaded_audio_config_inf, model_input_feature_dim=loaded_model_config_inf['input_feature_dim'],\n",
    "                     is_train=False\n",
    "                 )\n",
    "                 infer_bs = train_config.get('batch_size', 16) * 4\n",
    "                 test_loader_infer = DataLoader(infer_test_dataset, batch_size=infer_bs, shuffle=False, collate_fn=collate_fn, num_workers=0, pin_memory=(device.type == 'cuda') )\n",
    "\n",
    "                 print(f\"  Предсказание на {len(test_df)} тестовых примерах...\")\n",
    "                 predictions: Dict[str, str] = {}\n",
    "                 pbar_infer = tqdm(test_loader_infer, desc=\"Инференс\", leave=False, ncols=1000)\n",
    "                 with torch.no_grad():\n",
    "                     for batch_data_infer in pbar_infer:\n",
    "                         if batch_data_infer is None: continue\n",
    "                         features_infer, file_ids_infer, _, _ = batch_data_infer\n",
    "                         if features_infer is None or file_ids_infer is None or len(features_infer) == 0: continue\n",
    "\n",
    "                         features_infer = features_infer.to(device, non_blocking=True)\n",
    "                         try:\n",
    "                             logits_infer = inference_model_instance(features_infer)\n",
    "                             decoded_batch_infer = ctc_greedy_decode(logits_infer, loaded_index_to_char_inf, loaded_blank_idx_inf)\n",
    "                             for file_id, pred_text in zip(file_ids_infer, decoded_batch_infer):\n",
    "                                 predictions[file_id] = pred_text\n",
    "                         except Exception as e_inf_batch:\n",
    "                             print(f\"\\nОшибка инференса батча: {e_inf_batch}\")\n",
    "                             for fid in file_ids_infer: predictions[fid] = \"ERROR_INFER\"\n",
    "\n",
    "                 infer_duration_sec = time.time() - infer_start_time\n",
    "                 run_results[\"infer_time_sec\"] = infer_duration_sec\n",
    "                 print(f\"  Инференс завершен за {infer_duration_sec:.2f} сек. Сделано предсказаний: {len(predictions)}/{len(test_df)}\")\n",
    "\n",
    "                 if predictions:\n",
    "                     print(f\"  Формирование submission файла: {current_submission_path.name}\")\n",
    "                     submission_df = pd.DataFrame({'id': test_df['id']})\n",
    "                     submission_df['message'] = submission_df['id'].map(predictions).fillna(\"ERROR_MISSING\")\n",
    "                     current_submission_path.unlink(missing_ok=True)\n",
    "                     submission_df.to_csv(current_submission_path, index=False)\n",
    "                     print(f\"  Submission файл сохранен.\")\n",
    "                     mlflow.log_artifact(str(current_submission_path), artifact_path=\"submission\")\n",
    "                 else:\n",
    "                     print(\"  Предсказания не сгенерированы. Submission файл не создан.\")\n",
    "                     mlflow.set_tag(\"submission_generated\", \"False\")\n",
    "\n",
    "            except Exception as e_infer:\n",
    "                print(f\"  !!! Ошибка на этапе инференса: {e_infer} !!!\")\n",
    "                traceback.print_exc(limit=2)\n",
    "                run_results[\"error\"] = f\"Inference Error: {e_infer}\"\n",
    "                run_results[\"status\"] = \"failed_inference\"\n",
    "                try: mlflow.set_tag(\"status\", \"failed_inference\")\n",
    "                except: pass\n",
    "            finally:\n",
    "                 try: del inference_model_instance\n",
    "                 except NameError: pass\n",
    "                 try: del test_loader_infer\n",
    "                 except NameError: pass\n",
    "                 try: del infer_test_dataset\n",
    "                 except NameError: pass\n",
    "                 if 'logits_infer' in locals(): del logits_infer\n",
    "                 if 'features_infer' in locals(): del features_infer\n",
    "                 if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "        else:\n",
    "            print(\"  Инференс пропущен (лучшая модель не была сохранена).\")\n",
    "            run_results[\"status\"] += \"_no_inference\"\n",
    "            try: mlflow.set_tag(\"inference_skipped\", \"True\")\n",
    "            except: pass\n",
    "\n",
    "    except Exception as e_main:\n",
    "        print(f\"!!! КРИТИЧЕСКАЯ ОШИБКА в пайплайне {run_suffix}: {e_main} !!!\")\n",
    "        traceback.print_exc()\n",
    "        run_results[\"error\"] = str(e_main)\n",
    "        run_results[\"status\"] = \"failed_critical\"\n",
    "        try:\n",
    "            mlflow.set_tag(\"status\", \"failed_critical\")\n",
    "            mlflow.set_tag(\"error\", str(e_main)[:250])\n",
    "            if mlflow.active_run(): mlflow.end_run(status='FAILED')\n",
    "        except: pass\n",
    "\n",
    "    finally:\n",
    "        # Финальная очистка ресурсов\n",
    "        try: del model\n",
    "        except NameError: pass\n",
    "        try: del criterion\n",
    "        except NameError: pass\n",
    "        try: del optimizer\n",
    "        except NameError: pass\n",
    "        try: del scheduler\n",
    "        except NameError: pass\n",
    "        if 'full_dataset' in locals(): del full_dataset\n",
    "        if 'train_subset' in locals(): del train_subset\n",
    "        if 'val_subset' in locals(): del val_subset\n",
    "        if 'train_loader' in locals(): del train_loader\n",
    "        if 'val_loader' in locals(): del val_loader\n",
    "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "        # Удаляем временный файл модели, если он остался\n",
    "        if best_model_local_path_temp is not None and best_model_local_path_temp.exists():\n",
    "             best_model_local_path_temp.unlink()\n",
    "        print(f\"{'='*20} Завершение: {run_suffix} {'='*20}\\n\")\n",
    "\n",
    "    return run_results\n",
    "\n",
    "print(\"--- Функция run_training_pipeline определена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 13: Основной Цикл Обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 13: Финальный Запуск (Grouped Conv g=2, Delta win=3) ---\n",
      "\n",
      "1. Определение конфигурации для финального запуска...\n",
      "  Запускаемая конфигурация: 'Final_MelSpec_DeltaW3_GroupedG2_CNN128_RNN2'\n",
      "  Аудио параметры: {\n",
      "  \"feature_type\": \"melspec_delta_win3_grouped2\",\n",
      "  \"sample_rate\": 8000,\n",
      "  \"n_fft\": 128,\n",
      "  \"hop_length\": 64,\n",
      "  \"n_mels\": 12,\n",
      "  \"fmin\": 0.0,\n",
      "  \"fmax\": 4200.0,\n",
      "  \"power\": 2.0,\n",
      "  \"apply_trimming\": false,\n",
      "  \"trim_top_db\": 30,\n",
      "  \"delta_win_length\": 3\n",
      "}\n",
      "  Параметры модели: {\n",
      "  \"input_feature_dim\": 24,\n",
      "  \"cnn_out_channels\": [\n",
      "    128,\n",
      "    128,\n",
      "    128\n",
      "  ],\n",
      "  \"cnn_kernel_size\": 9,\n",
      "  \"cnn_stride\": 1,\n",
      "  \"cnn_padding\": \"same\",\n",
      "  \"cnn_pool_kernel\": 2,\n",
      "  \"rnn_hidden_size\": 512,\n",
      "  \"rnn_num_layers\": 3,\n",
      "  \"dropout_rate\": 0.2,\n",
      "  \"activation_fn\": \"GELU\",\n",
      "  \"classifier_type\": \"single\",\n",
      "  \"num_feature_groups\": 2\n",
      "}\n",
      "  Параметры обучения: {\n",
      "  \"batch_size\": 8,\n",
      "  \"num_workers\": 0,\n",
      "  \"num_epochs\": 80,\n",
      "  \"learning_rate\": 0.0001,\n",
      "  \"div_factor\": 10.0,\n",
      "  \"final_div_factor\": 10000,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"optimizer\": \"AdamW\",\n",
      "  \"early_stopping_patience\": 12,\n",
      "  \"gradient_clip_norm\": 2.0,\n",
      "  \"validation_split_ratio\": 0.1,\n",
      "  \"base_seed\": 42,\n",
      "  \"batches_per_epoch\": 0\n",
      "}\n",
      "\n",
      "--- Начало финального запуска (Final_MelSpec_DeltaW3_GroupedG2_CNN128_RNN2) ---\n",
      "MLflow эксперимент: 'Morse_FinalModel'\n",
      "\n",
      "--- Попытка завершить ЛЮБОЙ активный MLflow run перед запуском ---\n",
      "--- Активный MLflow run не обнаружен. ---\n",
      "--- Вызов run_training_pipeline для конфигурации 'Final_MelSpec_DeltaW3_GroupedG2_CNN128_RNN2' ---\n",
      "\n",
      "==================== Запуск: _Final_MelSpec_DeltaW3_GroupedG2_CNN128_RNN2 ====================\n",
      "Audio Config: {\"feature_type\": \"melspec_delta_win3_grouped2\", \"sample_rate\": 8000, \"n_fft\": 128, \"hop_length\": 64, \"n_mels\": 12, \"fmin\": 0.0, \"fmax\": 4200.0, \"power\": 2.0, \"apply_trimming\": false, \"trim_top_db\": 30, \"delta_win_length\": 3}\n",
      "Model Config: {\"input_feature_dim\": 24, \"cnn_out_channels\": [128, 128, 128], \"cnn_kernel_size\": 9, \"cnn_stride\": 1, \"cnn_padding\": \"same\", \"cnn_pool_kernel\": 2, \"rnn_hidden_size\": 512, \"rnn_num_layers\": 3, \"dropout_rate\": 0.2, \"activation_fn\": \"GELU\", \"classifier_type\": \"single\", \"num_feature_groups\": 2}\n",
      "Train Config: {\"batch_size\": 8, \"num_workers\": 0, \"num_epochs\": 80, \"learning_rate\": 0.0001, \"div_factor\": 10.0, \"final_div_factor\": 10000, \"weight_decay\": 0.0001, \"optimizer\": \"AdamW\", \"early_stopping_patience\": 12, \"gradient_clip_norm\": 2.0, \"validation_split_ratio\": 0.1, \"base_seed\": 42, \"batches_per_epoch\": 0}\n",
      "  Пути вывода: Model=model_SR8k_Mel12x2win3_fft128h64_f0-4k2_CNN128-128g2_RNN3x512_BiGRU_GELU_Clssingle_LR1e-04_WD1e-04_Final_MelSpec_DeltaW3_GroupedG2_CNN128_RNN2.pth, Params=params_SR8k_Mel12x2win3_fft128h64_f0-4k2_CNN128-128g2_RNN3x512_BiGRU_GELU_Clssingle_LR1e-04_WD1e-04_Final_MelSpec_DeltaW3_GroupedG2_CNN128_RNN2.json, Sub=submission_greedy_SR8k_Mel12x2win3_fft128h64_f0-4k2_CNN128-128g2_RNN3x512_BiGRU_GELU_Clssingle_LR1e-04_WD1e-04_Final_MelSpec_DeltaW3_GroupedG2_CNN128_RNN2.csv\n",
      "Установлен SEED = 42\n",
      "\n",
      "1. Подготовка данных...\n",
      "  Предупреждение Dataset: fmax (4200 Hz) > Найквиста (4000 Hz).\n",
      "MorseDataset (Final - GroupedInput g=2, Delta win=3): is_train=True, SR=8000Hz, Trimming OFF\n",
      "  Признаки: MelSpec(n_fft=128, hop=64, n_mels=12) + Delta (win=3)\n",
      "  Нормализация: Z-Score (независимая для M, D1)\n",
      "  Итоговый вход: (24, T)\n",
      "  Данные готовы: Train=27000 (3375 батчей), Val=3000 (188 батчей).\n",
      "\n",
      "2. Инициализация компонентов...\n",
      "  Model, Loss, Optimizer (AdamW) готовы.\n",
      "  Scheduler OneCycleLR создан (total_steps=270000).\n",
      "\n",
      "3. Запуск цикла обучения...\n",
      "  MLflow Run ID: a690b08caa1342afb384a9ff07f59d9a\n",
      "\n",
      "--- Эпоха 1/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df14620b873044e3833d9defe63b9c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 1/80 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8235675cd1ae41e2913edcc1b5765bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 1: Train Loss=4.5219, Train Lev=8.9589, Val Loss=4.1561, Val Lev=8.8780\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    '' | 'ФААР834ОМП'\n",
      "    '' | 'Т0С ЖЩ0О БМЫ'\n",
      "    '' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    '' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '' | '#6ЧФ8ЮО'\n",
      "    '' | 'ЫЭ# НЬЦЦ'\n",
      "    '' | '8ЖЭК ЛТЕ'\n",
      "    '' | '5О4ГЪЦ'\n",
      "    '' | 'ДФЯЯХЭФ9'\n",
      "    '' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: inf -> 8.8780. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 2/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b116f71d0e414cbb821eaeddf27b4b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 2/80 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e058bb1cef74caba77786df8edb6d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 2: Train Loss=3.9975, Train Lev=8.9211, Val Loss=4.0223, Val Lev=8.8780\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    '' | 'ФААР834ОМП'\n",
      "    '' | 'Т0С ЖЩ0О БМЫ'\n",
      "    '' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    '' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '' | '#6ЧФ8ЮО'\n",
      "    '' | 'ЫЭ# НЬЦЦ'\n",
      "    '' | '8ЖЭК ЛТЕ'\n",
      "    '' | '5О4ГЪЦ'\n",
      "    '' | 'ДФЯЯХЭФ9'\n",
      "    '' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (8.8780 vs best 8.8780). Без улучшений: 1/12\n",
      "\n",
      "--- Эпоха 3/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fe93797cc048e39e3c8355744fe770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 3/80 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4bda62abb44ffa852e8deb91c5d63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 3: Train Loss=3.9840, Train Lev=8.9191, Val Loss=4.0021, Val Lev=8.8647\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    '' | 'ФААР834ОМП'\n",
      "    '' | 'Т0С ЖЩ0О БМЫ'\n",
      "    '  ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    '' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '' | '#6ЧФ8ЮО'\n",
      "    '' | 'ЫЭ# НЬЦЦ'\n",
      "    '' | '8ЖЭК ЛТЕ'\n",
      "    '' | '5О4ГЪЦ'\n",
      "    '' | 'ДФЯЯХЭФ9'\n",
      "    '' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 8.8780 -> 8.8647. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 4/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e167892867442279d7d49104555b6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 4/80 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc0f3346c6343a8ad68f682d34ae1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 4: Train Loss=3.9542, Train Lev=8.8544, Val Loss=3.8455, Val Lev=8.6147\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    '' | 'ФААР834ОМП'\n",
      "    '' | 'Т0С ЖЩ0О БМЫ'\n",
      "    ' ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    '' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '' | '#6ЧФ8ЮО'\n",
      "    ' ' | 'ЫЭ# НЬЦЦ'\n",
      "    ' ' | '8ЖЭК ЛТЕ'\n",
      "    '' | '5О4ГЪЦ'\n",
      "    '' | 'ДФЯЯХЭФ9'\n",
      "    ' ' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 8.8647 -> 8.6147. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 5/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0f1ec436254b56a9ec9dcee796d8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 5/80 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb28f98d2aa74e369982ac213606e88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 5: Train Loss=2.6850, Train Lev=6.2337, Val Loss=1.0793, Val Lev=2.1160\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'РААРЧ3ЯОМП' | 'ФААР834ОМП'\n",
      "    'ТХ 5Щ0З МЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЛН3ЭХЛ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'ФФЩЯАХ Ф9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 8.6147 -> 2.1160. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 6/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1741034ffec54532b04505e86236e4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 6/80 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c503b5a048904f839b1e3c32c63a5c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 6: Train Loss=0.8881, Train Lev=1.8837, Val Loss=0.6123, Val Lev=1.3460\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'РААР83ЙШМП' | 'ФААР834ОМП'\n",
      "    'ТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХЛ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'ЭЩЯЖФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 2.1160 -> 1.3460. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 7/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740f2a0608304db69ee3ca279a875b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 7/80 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733ab63dc32847b284cd6ed648fee24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 7: Train Loss=0.6302, Train Lev=1.4344, Val Loss=0.4889, Val Lev=1.1183\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'РААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХЛ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'ФЯЯХФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 1.3460 -> 1.1183. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 8/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53a3c5ed911489ba1aaa4be5003633a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 8/80 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64c9c335257472d98d0d819922bec28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 8: Train Loss=0.5311, Train Lev=1.2224, Val Loss=0.4360, Val Lev=0.9850\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХЛ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РЯЯХФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 1.1183 -> 0.9850. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 9/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2e54bd656847bdbeba55b0a17e8e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 9/80 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5ca4fcb0924ee699e0f20466c4b434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 9: Train Loss=0.4646, Train Lev=1.0864, Val Loss=0.3769, Val Lev=0.8567\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РЯЯХФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.9850 -> 0.8567. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 10/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c77e5aabfda44ee9cd5113bcc26303e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 10/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde4a99c2dd340b0a7c8c999621be5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 10: Train Loss=0.4211, Train Lev=0.9916, Val Loss=0.3615, Val Lev=0.8897\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМЪ' | 'ФААР834ОМП'\n",
      "    'КОС ЖЩ0Щ БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РФЯЯЖФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.8897 vs best 0.8567). Без улучшений: 1/12\n",
      "\n",
      "--- Эпоха 11/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296fe5a6e90b485e9858eb56d1be4c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 11/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d89e1360ef4cb2a4b75112408bcebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 11: Train Loss=0.3878, Train Lev=0.9231, Val Loss=0.3260, Val Lev=0.7893\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РЯЯЖЛФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.8567 -> 0.7893. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 12/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1005aa0226bb4413b55da666d1e6f628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 12/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e71986eb374ea3bd0e7c3948c9109b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 12: Train Loss=0.3623, Train Lev=0.8690, Val Loss=0.3122, Val Lev=0.7303\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РЯЯЖФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.7893 -> 0.7303. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 13/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bfb7d9bec540ce916a9786b616884b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 13/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f2d69f8a2c4ba3b2f9b3cab9d98cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 13: Train Loss=0.3407, Train Lev=0.8254, Val Loss=0.3024, Val Lev=0.7257\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РПЯЯХБФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.7303 -> 0.7257. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 14/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29cb227c489947f692ffbe9030dbf33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 14/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbb5dbfde0a4882817c92c3b4dcf9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 14: Train Loss=0.3247, Train Lev=0.7887, Val Loss=0.2945, Val Lev=0.6963\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РФЯЯХ6Ф9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.7257 -> 0.6963. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 15/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07ce3c6ec8c4f12882a1851e11f1e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 15/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc481863cbb846e48226bc0104a93bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 15: Train Loss=0.3096, Train Lev=0.7589, Val Loss=0.2897, Val Lev=0.7100\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РГЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.7100 vs best 0.6963). Без улучшений: 1/12\n",
      "\n",
      "--- Эпоха 16/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad045c791e954322a01f8b7eccdf52d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 16/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a68f9a1be84df79a9d2766654bbc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 16: Train Loss=0.2978, Train Lev=0.7309, Val Loss=0.2871, Val Lev=0.6877\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РПЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.6963 -> 0.6877. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 17/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46896b9147444a558da0fba930965564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 17/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39ae1dec51349e0a21128d5e12c794e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 17: Train Loss=0.2855, Train Lev=0.7100, Val Loss=0.2828, Val Lev=0.6693\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РФЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.6877 -> 0.6693. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 18/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bf64235e6e48b4a633ea5a0fdb5eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 18/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea7ee98e1404d99b2f38452cd73000f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 18: Train Loss=0.2742, Train Lev=0.6854, Val Loss=0.2675, Val Lev=0.6527\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КТЙС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РЯЯХ6Ф9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.6693 -> 0.6527. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 19/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332c11d312b143bd8dab34df1ad67af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 19/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d836c65e08ad492fa2445eebe7f1dd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 19: Train Loss=0.2638, Train Lev=0.6620, Val Loss=0.2782, Val Lev=0.6543\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РГЯЯХ6Ф9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6543 vs best 0.6527). Без улучшений: 1/12\n",
      "\n",
      "--- Эпоха 20/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e03f57efeb14d03856e48fb1b5817f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 20/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc616da12af14525b479391015177b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 20: Train Loss=0.2538, Train Lev=0.6472, Val Loss=0.2664, Val Lev=0.6233\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'ФЯЯХЭФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.6527 -> 0.6233. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 21/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba67763bf91647069f2a8d89f72cfada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 21/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fbeb78fa0344ebb5e4d91b55b43228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 21: Train Loss=0.2415, Train Lev=0.6173, Val Loss=0.2630, Val Lev=0.6287\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'КОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РФЯЯХЛФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6287 vs best 0.6233). Без улучшений: 1/12\n",
      "\n",
      "--- Эпоха 22/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bca8aeb926b4e3094bd0234011d54d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 22/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730b4f7259504b54acbecb81b8ec0927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 22: Train Loss=0.2330, Train Lev=0.5953, Val Loss=0.2569, Val Lev=0.6200\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РФЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.6233 -> 0.6200. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 23/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5fb7e892b54a9a98d3e7107e1feb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 23/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fa349a385549659ce8d980583941cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 23: Train Loss=0.2224, Train Lev=0.5766, Val Loss=0.2583, Val Lev=0.6307\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'ФЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6307 vs best 0.6200). Без улучшений: 1/12\n",
      "\n",
      "--- Эпоха 24/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a6dff59ff24d35a476c50226ee0367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 24/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6232cbd0d78c4cb2987d4512ac797380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 24: Train Loss=0.2109, Train Lev=0.5534, Val Loss=0.2716, Val Lev=0.6270\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6270 vs best 0.6200). Без улучшений: 2/12\n",
      "\n",
      "--- Эпоха 25/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6050a764fe4fb0ad92713f5b17a3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 25/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4eb952d27b4568b64412e4d580206f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 25: Train Loss=0.2006, Train Lev=0.5254, Val Loss=0.2672, Val Lev=0.6197\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    'ХО4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'ФЯЯХЭФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.6200 -> 0.6197. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 26/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f036b782ad5e41b3b82b9a783ea33347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 26/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b6d8e788594b4cb3d887443d972ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 26: Train Loss=0.1886, Train Lev=0.5026, Val Loss=0.2745, Val Lev=0.6193\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФАСР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РФЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.6197 -> 0.6193. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 27/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b040e60aea5a4987a547509bc715ed46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 27/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac79a674cca4578a73462344379b712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 27: Train Loss=0.1771, Train Lev=0.4734, Val Loss=0.2684, Val Lev=0.6233\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'ФЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6233 vs best 0.6193). Без улучшений: 1/12\n",
      "\n",
      "--- Эпоха 28/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4589e4ac4777402fb0149ee30bd8eeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 28/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44988fd7948415e9ffdc1271e22f53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 28: Train Loss=0.1664, Train Lev=0.4500, Val Loss=0.2720, Val Lev=0.6220\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РФЯЯХЭФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6220 vs best 0.6193). Без улучшений: 2/12\n",
      "\n",
      "--- Эпоха 29/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa727aae72874af98bb781ad9255cb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 29/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c8fd210c664a8eacc2020c34cbc80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 29: Train Loss=0.1533, Train Lev=0.4170, Val Loss=0.2732, Val Lev=0.6197\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТЙС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РФЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6197 vs best 0.6193). Без улучшений: 3/12\n",
      "\n",
      "--- Эпоха 30/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e24178688104f3fbd0a04723595b269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 30/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6441d2b500584229af009e1bbbab4fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 30: Train Loss=0.1434, Train Lev=0.3930, Val Loss=0.2766, Val Lev=0.6077\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТЙС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РПЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  ✨ Val Lev улучшился: 0.6193 -> 0.6077. Сохранение лучшей модели...\n",
      "\n",
      "--- Эпоха 31/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a238429a904ad5a0d63c88e2740333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 31/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60f5e0d161740af8f0e2a70ad1f0392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 31: Train Loss=0.1326, Train Lev=0.3673, Val Loss=0.2828, Val Lev=0.6323\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РГЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6323 vs best 0.6077). Без улучшений: 1/12\n",
      "\n",
      "--- Эпоха 32/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb72fbea94c42e1b29ac7f86046df8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 32/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad81136e960043c09c18cf5d3afb4fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 32: Train Loss=0.1215, Train Lev=0.3383, Val Loss=0.2889, Val Lev=0.6207\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РГЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6207 vs best 0.6077). Без улучшений: 2/12\n",
      "\n",
      "--- Эпоха 33/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d931f94d36c946c4a4fe7df76e37e762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 33/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23669ddeb64345d0b29ae6dac9ce2527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 33: Train Loss=0.1127, Train Lev=0.3165, Val Loss=0.2971, Val Lev=0.6263\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РГЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6263 vs best 0.6077). Без улучшений: 3/12\n",
      "\n",
      "--- Эпоха 34/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09d195988fc489aa2973c3f1a113283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 34/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ecf19a6c4e4fe4a8dd0d5d220ef2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 34: Train Loss=0.1017, Train Lev=0.2858, Val Loss=0.2968, Val Lev=0.6293\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РФЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6293 vs best 0.6077). Без улучшений: 4/12\n",
      "\n",
      "--- Эпоха 35/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069d792ed3534bfe895997d48e11b57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 35/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5e0480550041d9afb09ff4e9f10621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 35: Train Loss=0.0925, Train Lev=0.2603, Val Loss=0.3094, Val Lev=0.6287\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РФЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6287 vs best 0.6077). Без улучшений: 5/12\n",
      "\n",
      "--- Эпоха 36/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd683aabf5664483830546fe3980dd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 36/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9c034ce4d44f178a3b0bb83edcc907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 36: Train Loss=0.0832, Train Lev=0.2347, Val Loss=0.3215, Val Lev=0.6360\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РЯЯХЗФ9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6360 vs best 0.6077). Без улучшений: 6/12\n",
      "\n",
      "--- Эпоха 37/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d022d7e46144afad816dab9c6fe0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 37/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf15aaaf80d4adcaa37f44380b3425c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 37: Train Loss=0.0769, Train Lev=0.2189, Val Loss=0.3175, Val Lev=0.6273\n",
      "  Примеры декодирования (Предсказание | Реалность):\n",
      "    'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    'ТТОС 5Щ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "    'ЫЭ# НЬЦЦ' | 'ЫЭ# НЬЦЦ'\n",
      "    '8ЖЭК ЛТЕ' | '8ЖЭК ЛТЕ'\n",
      "    '5О4ГЪЦ' | '5О4ГЪЦ'\n",
      "    'РРЯЯХ7Ф9' | 'ДФЯЯХЭФ9'\n",
      "    'ЧШ9А 8П' | 'ЧШ9А 8П'\n",
      "  Val Lev не улучшился (0.6273 vs best 0.6077). Без улучшений: 7/12\n",
      "\n",
      "--- Эпоха 38/80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76212c287c104309be1adbd6c360ae32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 38/80 [Тренировка]:   0%|                                                                               …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 13: Финальный Запуск (Grouped Conv g=2, Delta win=3)\n",
    "# =============================================================================\n",
    "print(f\"--- Ячейка 13: Финальный Запуск (Grouped Conv g=2, Delta win=3) ---\")\n",
    "\n",
    "# Импорты и проверки зависимостей\n",
    "import time, pandas as pd, numpy as np, json, random, copy, traceback\n",
    "from pathlib import Path; import torch\n",
    "from IPython.display import display\n",
    "\n",
    "# Проверка наличия финальных конфигураций и шаблона\n",
    "required_globals_loop = [\n",
    "    'train_df', 'test_df', 'EXTRACTED_AUDIO_DIR',\n",
    "    'char_to_index', 'index_to_char', 'BLANK_IDX', 'PAD_IDX', 'NUM_CLASSES_CTC',\n",
    "    'device', 'OUTPUT_DIR',\n",
    "    'BASE_FILENAME_SUFFIX_FINAL', # <-- Используем финальный шаблон\n",
    "    'SEED', 'run_training_pipeline',\n",
    "    'AUDIO_CONFIG',\n",
    "    'MODEL_CONFIG_FINAL', # <-- Используем финальный конфиг модели\n",
    "    'TRAIN_CONFIG_FINAL',\n",
    "    'mlflow'\n",
    "]\n",
    "missing_globals_loop = [v for v in required_globals_loop if v not in globals() or globals().get(v) is None]\n",
    "if missing_globals_loop: raise NameError(f\"Отсутствуют переменные/функции или они None: {missing_globals_loop}\")\n",
    "\n",
    "# ============================================================================\n",
    "# === БЛОК 1: Определение Конфигурации для Запуска ===\n",
    "# ============================================================================\n",
    "print(\"\\n1. Определение конфигурации для финального запуска...\")\n",
    "\n",
    "config_name = f\"Final_MelSpec_DeltaW3_GroupedG2_CNN128_RNN2\" # Имя для MLflow и логов\n",
    "current_model_config = MODEL_CONFIG_FINAL.copy()\n",
    "current_audio_config = AUDIO_CONFIG.copy()\n",
    "fixed_train_config = TRAIN_CONFIG_FINAL.copy()\n",
    "\n",
    "print(f\"  Запускаемая конфигурация: '{config_name}'\")\n",
    "print(f\"  Аудио параметры: {json.dumps(current_audio_config, indent=2)}\")\n",
    "print(f\"  Параметры модели: {json.dumps(current_model_config, indent=2)}\")\n",
    "print(f\"  Параметры обучения: {json.dumps(fixed_train_config, indent=2)}\")\n",
    "\n",
    "# --- Инициализация Списка для Результатов ---\n",
    "all_run_results_list: List[Dict] = []\n",
    "\n",
    "# ============================================================================\n",
    "# === БЛОК 2: Запуск обучения для одной конфигурации ===\n",
    "# ============================================================================\n",
    "print(f\"\\n--- Начало финального запуска ({config_name}) ---\")\n",
    "overall_start_time = time.time()\n",
    "# === Имя эксперимента MLflow ===\n",
    "MLFLOW_EXPERIMENT_NAME = f\"Morse_FinalModel\" # Имя для финального эксперимента\n",
    "# ==============================\n",
    "print(f\"MLflow эксперимент: '{MLFLOW_EXPERIMENT_NAME}'\")\n",
    "\n",
    "# --- Надежное завершение ЛЮБОГО активного MLflow run ---\n",
    "print(\"\\n--- Попытка завершить ЛЮБОЙ активный MLflow run перед запуском ---\")\n",
    "try:\n",
    "    if mlflow.active_run():\n",
    "        active_run_id = mlflow.active_run().info.run_id\n",
    "        print(f\"!!! Обнаружен активный MLflow run ({active_run_id}). Принудительно завершаем... !!!\")\n",
    "        mlflow.end_run()\n",
    "        time.sleep(1)\n",
    "        print(\"--- Проверка: Активный MLflow run отсутствует.\" if not mlflow.active_run() else \"!!! ПРЕДУПРЕЖДЕНИЕ: MLflow run ВСЕ ЕЩЕ АКТИВЕН! !!!\")\n",
    "    else:\n",
    "        print(\"--- Активный MLflow run не обнаружен. ---\")\n",
    "except Exception as e_check_run:\n",
    "    print(f\"Предупреждение: Ошибка при проверке/завершении активного MLflow run: {e_check_run}\")\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# --- Формируем суффикс для MLflow run ---\n",
    "current_run_suffix = f\"_{config_name}\"\n",
    "\n",
    "# --- Вызов основной функции обучения/инференса ---\n",
    "try:\n",
    "    print(f\"--- Вызов run_training_pipeline для конфигурации '{config_name}' ---\")\n",
    "    run_result_dict = run_training_pipeline(\n",
    "        audio_config=current_audio_config,\n",
    "        model_config=current_model_config,\n",
    "        train_config=fixed_train_config,\n",
    "        full_train_df=train_df,\n",
    "        test_df=test_df,\n",
    "        audio_dir=EXTRACTED_AUDIO_DIR,\n",
    "        base_output_dir=OUTPUT_DIR, # Используем финальную папку вывода\n",
    "        char_to_index=char_to_index,\n",
    "        index_to_char=index_to_char,\n",
    "        blank_idx=BLANK_IDX,\n",
    "        pad_idx=PAD_IDX,\n",
    "        num_classes_ctc=NUM_CLASSES_CTC,\n",
    "        device=device,\n",
    "        run_suffix=current_run_suffix,\n",
    "        base_filename_suffix=BASE_FILENAME_SUFFIX_FINAL, # <-- Используем финальный шаблон\n",
    "        seed=SEED,\n",
    "        mlflow_experiment_name=MLFLOW_EXPERIMENT_NAME\n",
    "    )\n",
    "    print(f\"--- Успешное завершение run_training_pipeline для '{config_name}' ---\")\n",
    "\n",
    "except Exception as e_pipeline:\n",
    "    print(f\"!!! КРИТИЧЕСКАЯ ОШИБКА ПРИ ВЫЗОВЕ ПАЙПЛАЙНА для '{config_name}' !!!\")\n",
    "    print(f\"Ошибка: {e_pipeline}\")\n",
    "    traceback.print_exc()\n",
    "    run_result_dict = {\n",
    "        \"run_suffix\": current_run_suffix,\n",
    "        \"status\": \"failed_launch\",\n",
    "        \"best_val_lev\": float('inf'),\n",
    "        \"error\": f\"Pipeline launch error: {e_pipeline}\",\n",
    "        \"config_name\": config_name\n",
    "    }\n",
    "\n",
    "# Добавляем параметры этого запуска в результаты\n",
    "run_result_dict['config_name'] = config_name\n",
    "run_result_dict['n_mels'] = current_audio_config['n_mels']\n",
    "run_result_dict['n_fft'] = current_audio_config['n_fft']\n",
    "run_result_dict['hop_length'] = current_audio_config['hop_length']\n",
    "run_result_dict['feature_type'] = current_audio_config['feature_type']\n",
    "run_result_dict['delta_win_length'] = current_audio_config.get('delta_win_length', 'N/A')\n",
    "run_result_dict['num_feature_groups'] = current_model_config.get('num_feature_groups', 'N/A')\n",
    "all_run_results_list.append(run_result_dict)\n",
    "\n",
    "# --- Конец запуска ---\n",
    "# ============================================================================\n",
    "# === КОНЕЦ БЛОКА 2 ===\n",
    "# ============================================================================\n",
    "\n",
    "overall_end_time = time.time()\n",
    "total_duration_hours = (overall_end_time - overall_start_time) / 3600\n",
    "print(f\"\\n--- Финальный запуск ({config_name}) завершен за {total_duration_hours:.2f} часов ---\")\n",
    "\n",
    "# ============================================================================\n",
    "# === БЛОК 3: Анализ и вывод итогов ===\n",
    "# ============================================================================\n",
    "print(f\"\\n--- Итоги Финального Запуска ({config_name}) ---\")\n",
    "if not all_run_results_list:\n",
    "    print(\"Нет результатов для анализа.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(all_run_results_list)\n",
    "\n",
    "    # Настройки отображения Pandas\n",
    "    pd.set_option('display.max_rows', 100)\n",
    "    pd.set_option('display.max_columns', 20)\n",
    "    pd.set_option('display.width', 180)\n",
    "    pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "    print(\"\\nСводная таблица результатов:\")\n",
    "    display_cols = ['config_name', 'best_val_lev', 'best_epoch', 'status', 'train_time_min', 'infer_time_sec', 'error', 'mlflow_run_id']\n",
    "    display_cols_present = [col for col in display_cols if col in results_df.columns]\n",
    "    display(results_df[display_cols_present].head(len(results_df)))\n",
    "\n",
    "    if not results_df.empty:\n",
    "        best_run = results_df.iloc[0] # Результат единственного запуска\n",
    "        if pd.notna(best_run['best_val_lev']) and np.isfinite(best_run['best_val_lev']):\n",
    "            print(f\"\\n--- Результат Финального Запуска ---\")\n",
    "            print(f\"  Конфигурация: {best_run.get('config_name', 'N/A')}\")\n",
    "            print(f\"  Best Val Levenshtein: {best_run['best_val_lev']:.4f} (Эпоха {best_run.get('best_epoch', 'N/A')})\")\n",
    "            print(f\"  Статус: {best_run.get('status', 'N/A')}\")\n",
    "            if pd.notna(best_run.get('error')):\n",
    "                 print(f\"  Ошибка: {best_run['error']}\")\n",
    "            # Вывод путей к артефактам\n",
    "            print(f\"  Модель сохранена в: {best_run.get('model_path', 'N/A')}\")\n",
    "            print(f\"  Параметры сохранены в: {best_run.get('params_path', 'N/A')}\")\n",
    "            print(f\"  Submission сохранен в: {best_run.get('submission_path', 'N/A')}\")\n",
    "            print(f\"  MLflow Run ID: {best_run.get('mlflow_run_id', 'N/A')}\")\n",
    "        else:\n",
    "            print(\"\\nНе удалось найти валидный результат (best_val_lev is NaN or Inf).\")\n",
    "            if pd.notna(best_run.get('error')): print(f\"  Ошибка: {best_run['error']}\")\n",
    "    else:\n",
    "        print(\"\\nНе удалось определить результат (DataFrame пуст).\")\n",
    "\n",
    "    # Сохранение полной таблицы результатов (для одного запуска)\n",
    "    results_csv_path = OUTPUT_DIR / f\"final_run_results_{config_name}.csv\"\n",
    "    try:\n",
    "        results_df.to_csv(results_csv_path, index=False)\n",
    "        print(f\"\\nПолные результаты сохранены в CSV: {results_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nНе удалось сохранить результаты в CSV: {e}\")\n",
    "# ============================================================================\n",
    "# === КОНЕЦ БЛОКА 3 ===\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n--- Ячейка 13: Завершена (Финальный Запуск) ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
