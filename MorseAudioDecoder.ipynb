{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 1: Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 1: Импорты и Базовая Настройка ---\n",
      "\n",
      "--- Статус ключевых библиотек ---\n",
      "PyTorch Версия: 2.5.1+cu121\n",
      "LibROSA Версия: 0.11.0\n",
      "NumPy Версия: 2.0.2\n",
      "Pandas Версия: 2.2.3\n",
      "Levenshtein Версия: 0.27.1\n",
      "MLflow доступен: True\n",
      "IPyWidgets доступен: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 1: Импорты и Базовая Настройка\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 1: Импорты и Базовая Настройка ---\")\n",
    "\n",
    "# --- Базовые библиотеки ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE' # Для избежания конфликтов на некоторых системах\n",
    "import zipfile\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import random\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple, List, Dict, Optional\n",
    "\n",
    "# --- Аудио и Сигналы ---\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# --- Визуализация и Интерактивность (IPython/Jupyter) ---\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, Audio, clear_output\n",
    "    IPYWIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    IPYWIDGETS_AVAILABLE = False\n",
    "    print(\"Предупреждение: ipywidgets не найден. Интерактивные ячейки будут недоступны.\")\n",
    "    def display(*args, **kwargs): pass\n",
    "    def Audio(*args, **kwargs): pass\n",
    "    def clear_output(*args, **kwargs): pass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import scipy.signal as signal # Больше не используется\n",
    "\n",
    "# --- PyTorch ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR # Импортируем сразу\n",
    "\n",
    "# --- Метрики и Утилиты ---\n",
    "import Levenshtein\n",
    "from tqdm.notebook import tqdm # Используем версию для Jupyter\n",
    "import itertools\n",
    "\n",
    "# --- Логирование Экспериментов (MLflow) ---\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"Предупреждение: mlflow не найден. Логирование экспериментов будет отключено.\")\n",
    "    # Заглушка для MLflow будет определена в Ячейке 12\n",
    "\n",
    "# --- Настройка окружения и предупреждений ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "print(\"\\n--- Статус ключевых библиотек ---\")\n",
    "print(f\"PyTorch Версия: {torch.__version__}\")\n",
    "print(f\"LibROSA Версия: {librosa.__version__}\")\n",
    "print(f\"NumPy Версия: {np.__version__}\")\n",
    "print(f\"Pandas Версия: {pd.__version__}\")\n",
    "print(f\"Levenshtein Версия: {Levenshtein.__version__}\")\n",
    "print(f\"MLflow доступен: {MLFLOW_AVAILABLE}\")\n",
    "print(f\"IPyWidgets доступен: {IPYWIDGETS_AVAILABLE}\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 2: Конфигурация и Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 2: Конфигурация и Параметры (ОБНОВЛЕНА для Simple Model) ---\n",
      "Базовая директория: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_mel\\MorseAudioDecoder\n",
      "Ожидаемая директория аудио: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_mel\\MorseAudioDecoder\\morse_dataset\\morse_dataset\n",
      "Директория для вывода: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_mel\\MorseAudioDecoder\\output_melspec_experiments\n",
      "\n",
      "Аудио параметры (Базовые для теста n_mels, hop=64):\n",
      "  (n_mels будет [8, 12], f_range=0-4200Hz)\n",
      "{\n",
      "  \"feature_type\": \"melspec\",\n",
      "  \"sample_rate\": 8000,\n",
      "  \"n_fft\": 128,\n",
      "  \"hop_length\": 64,\n",
      "  \"n_mels\": 16,\n",
      "  \"fmin\": 0.0,\n",
      "  \"fmax\": 4200.0,\n",
      "  \"power\": 2.0,\n",
      "  \"apply_trimming\": false,\n",
      "  \"trim_top_db\": 30\n",
      "}\n",
      "\n",
      "Параметры ПОЛНОЙ модели (для справки):\n",
      "{\n",
      "  \"input_feature_dim\": 16,\n",
      "  \"cnn_out_channels\": [\n",
      "    64,\n",
      "    128,\n",
      "    128\n",
      "  ],\n",
      "  \"cnn_kernel_size\": 9,\n",
      "  \"cnn_stride\": 1,\n",
      "  \"cnn_padding\": \"same\",\n",
      "  \"cnn_pool_kernel\": 2,\n",
      "  \"rnn_hidden_size\": 512,\n",
      "  \"rnn_num_layers\": 3,\n",
      "  \"dropout_rate\": 0.2,\n",
      "  \"activation_fn\": \"GELU\",\n",
      "  \"classifier_type\": \"single\",\n",
      "  \"bidirectional\": true\n",
      "}\n",
      "\n",
      "Параметры УПРОЩЕННОЙ модели (для калибровки n_mels):\n",
      "{\n",
      "  \"input_feature_dim\": 16,\n",
      "  \"cnn_out_channels\": [\n",
      "    64,\n",
      "    128,\n",
      "    128\n",
      "  ],\n",
      "  \"cnn_kernel_size\": 9,\n",
      "  \"cnn_stride\": 1,\n",
      "  \"cnn_padding\": \"same\",\n",
      "  \"cnn_pool_kernel\": 2,\n",
      "  \"rnn_hidden_size\": 512,\n",
      "  \"rnn_num_layers\": 2,\n",
      "  \"dropout_rate\": 0.2,\n",
      "  \"activation_fn\": \"GELU\",\n",
      "  \"classifier_type\": \"single\",\n",
      "  \"bidirectional\": true\n",
      "}\n",
      "\n",
      "Параметры обучения (Эпохи/Терпимость уменьшены):\n",
      "{\n",
      "  \"batch_size\": 8,\n",
      "  \"num_workers\": 0,\n",
      "  \"num_epochs\": 10,\n",
      "  \"learning_rate\": 0.0005,\n",
      "  \"div_factor\": 3.0,\n",
      "  \"final_div_factor\": 100,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"optimizer\": \"AdamW\",\n",
      "  \"early_stopping_patience\": 5,\n",
      "  \"gradient_clip_norm\": 2.0,\n",
      "  \"validation_split_ratio\": 0.1,\n",
      "  \"base_seed\": 42,\n",
      "  \"batches_per_epoch\": 1000\n",
      "}\n",
      "\n",
      "Шаблон базового суффикса (УПРОЩЕННАЯ модель): SR8k_MelSpec{n_mels}_fft128h64_f0-4k2_CNN128_RNN2x512_GRU_GELU_Clssingle_LR5e-04_WD1e-04\n",
      "\n",
      "Используемое устройство: cuda\n",
      "  GPU: NVIDIA GeForce GTX 1050 Ti\n",
      "Установлен SEED = 42\n",
      "\n",
      "--- Ячейка 2: Конфигурация для тестов n_mels = [8, 12] (УПРОЩЕННАЯ модель) готова ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 2: Конфигурация и Параметры - ОБНОВЛЕНА (Добавлена Simple Model Config)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 2: Конфигурация и Параметры (ОБНОВЛЕНА для Simple Model) ---\")\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# --- Пути ---\n",
    "BASE_DIR = Path('.').resolve()\n",
    "DATA_DIR = BASE_DIR\n",
    "ZIP_PATH = DATA_DIR / 'morse_dataset.zip'\n",
    "AUDIO_DIR_NAME = 'morse_dataset'\n",
    "EXTRACTED_AUDIO_DIR = DATA_DIR / AUDIO_DIR_NAME / AUDIO_DIR_NAME\n",
    "TRAIN_CSV_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_CSV_PATH = DATA_DIR / 'test.csv'\n",
    "SAMPLE_SUB_PATH = DATA_DIR / 'sample_submission.csv'\n",
    "OUTPUT_DIR = BASE_DIR / 'output_melspec_experiments'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Базовая директория: {BASE_DIR}\")\n",
    "print(f\"Ожидаемая директория аудио: {EXTRACTED_AUDIO_DIR}\")\n",
    "print(f\"Директория для вывода: {OUTPUT_DIR}\")\n",
    "\n",
    "# --- Параметры обработки аудио (Базовые для теста n_mels) ---\n",
    "SR_FOR_CONFIG = 8000\n",
    "HOP_LENGTH_CONST = 64 # Фиксированный hop_length\n",
    "N_MELS_DEFAULT = 16 # Дефолтное значение (будет переопределяться)\n",
    "\n",
    "AUDIO_CONFIG_MELSPEC = {\n",
    "    \"feature_type\": \"melspec\", \"sample_rate\": SR_FOR_CONFIG, \"n_fft\": 128,\n",
    "    \"hop_length\": HOP_LENGTH_CONST, \"n_mels\": N_MELS_DEFAULT, # Будет [8, 12] в цикле\n",
    "    \"fmin\": 0.0, \"fmax\": 4200.0, \"power\": 2.0,\n",
    "    \"apply_trimming\": False, \"trim_top_db\": 30,\n",
    "}\n",
    "print(f\"\\nАудио параметры (Базовые для теста n_mels, hop={HOP_LENGTH_CONST}):\")\n",
    "print(f\"  (n_mels будет [8, 12], f_range={AUDIO_CONFIG_MELSPEC['fmin']:.0f}-{AUDIO_CONFIG_MELSPEC['fmax']:.0f}Hz)\")\n",
    "print(json.dumps(AUDIO_CONFIG_MELSPEC, indent=2))\n",
    "\n",
    "# --- Параметры Модели (Полная версия - для справки) ---\n",
    "MODEL_CONFIG_FULL = {\n",
    "    \"input_feature_dim\": N_MELS_DEFAULT, # Будет [8, 12] в цикле\n",
    "    \"cnn_out_channels\": [64, 128, 128], \"cnn_kernel_size\": 9, \"cnn_stride\": 1, \"cnn_padding\": 'same',\n",
    "    \"cnn_pool_kernel\": 2, \"rnn_hidden_size\": 512, \"rnn_num_layers\": 3, \"dropout_rate\": 0.2,\n",
    "    \"activation_fn\": \"GELU\", \"classifier_type\": \"single\", \"bidirectional\": True # Полная модель - BiGRU\n",
    "}\n",
    "print(f\"\\nПараметры ПОЛНОЙ модели (для справки):\")\n",
    "print(json.dumps(MODEL_CONFIG_FULL, indent=2))\n",
    "\n",
    "# --- Параметры Модели (УПРОЩЕННАЯ версия для калибровки) ---\n",
    "MODEL_CONFIG_SIMPLE = {\n",
    "    \"input_feature_dim\": N_MELS_DEFAULT, # Будет [8, 12] в цикле\n",
    "    \"cnn_out_channels\": [64, 128, 128],       # Уменьшено: 2 слоя CNN, меньше каналов\n",
    "    \"cnn_kernel_size\": 9, \"cnn_stride\": 1, \"cnn_padding\": 'same',\n",
    "    \"cnn_pool_kernel\": 2,\n",
    "    \"rnn_hidden_size\": 512,             # Уменьшено: размер RNN\n",
    "    \"rnn_num_layers\": 2,                # Уменьшено: 1 слой RNN\n",
    "    \"dropout_rate\": 0.2,\n",
    "    \"activation_fn\": \"GELU\", \"classifier_type\": \"single\",\n",
    "    \"bidirectional\": True             # <-- Упрощено: Однонаправленный GRU\n",
    "}\n",
    "print(f\"\\nПараметры УПРОЩЕННОЙ модели (для калибровки n_mels):\")\n",
    "print(json.dumps(MODEL_CONFIG_SIMPLE, indent=2))\n",
    "\n",
    "# --- Параметры Обучения (Оставляем прежними, но можно уменьшить num_epochs) ---\n",
    "TRAIN_CONFIG_MELSPEC = {\n",
    "    \"batch_size\": 8, \"num_workers\": 0, \"num_epochs\": 10, # <-- Уменьшено кол-во эпох для скорости\n",
    "    \"learning_rate\": 5e-4, \"div_factor\": 3.0, \"final_div_factor\": 100,\n",
    "    \"weight_decay\": 1e-4, \"optimizer\": \"AdamW\", \"early_stopping_patience\": 5, # <-- Уменьшена терпимость\n",
    "    \"gradient_clip_norm\": 2.0, \"validation_split_ratio\": 0.1,\n",
    "    \"base_seed\": SEED, \"batches_per_epoch\": 1000 # Полные эпохи\n",
    "}\n",
    "print(f\"\\nПараметры обучения (Эпохи/Терпимость уменьшены):\")\n",
    "print(json.dumps(TRAIN_CONFIG_MELSPEC, indent=2))\n",
    "\n",
    "# --- Специальные Токены и Глобальные Переменные ---\n",
    "PAD_TOKEN = '<pad>'; BLANK_TOKEN = '_'\n",
    "PAD_IDX = -1; BLANK_IDX = -1; NUM_CLASSES_CTC = -1\n",
    "char_to_index: Dict[str, int] = {}; index_to_char: Dict[int, str] = {}\n",
    "\n",
    "# --- Шаблон Базового Суффикса Имени Файла (для УПРОЩЕННОЙ модели) - ОБНОВЛЕН ---\n",
    "BASE_FILENAME_SUFFIX_TEMPLATE_SIMPLE = (\n",
    "    f\"SR{AUDIO_CONFIG_MELSPEC['sample_rate'] // 1000}k_\"\n",
    "    f\"MelSpec{{n_mels}}_fft{AUDIO_CONFIG_MELSPEC['n_fft']}h{HOP_LENGTH_CONST}_f0-4k2_\" # {n_mels} - плейсхолдер\n",
    "    f\"CNN{MODEL_CONFIG_SIMPLE['cnn_out_channels'][-1]}_\" # Каналы из SIMPLE\n",
    "    f\"RNN{MODEL_CONFIG_SIMPLE['rnn_num_layers']}x{MODEL_CONFIG_SIMPLE['rnn_hidden_size']}_GRU_\" # Параметры и тип RNN из SIMPLE\n",
    "    f\"{MODEL_CONFIG_SIMPLE['activation_fn']}_Cls{MODEL_CONFIG_SIMPLE['classifier_type']}_\"\n",
    "    f\"LR{TRAIN_CONFIG_MELSPEC['learning_rate']:.0e}_WD{TRAIN_CONFIG_MELSPEC['weight_decay']:.0e}\"\n",
    ")\n",
    "print(f\"\\nШаблон базового суффикса (УПРОЩЕННАЯ модель): {BASE_FILENAME_SUFFIX_TEMPLATE_SIMPLE}\")\n",
    "\n",
    "# --- Выбор устройства и Установка SEED ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nИспользуемое устройство: {device}\")\n",
    "if device.type == 'cuda': print(f\"  GPU: {torch.cuda.get_device_name(0)}\"); torch.cuda.empty_cache()\n",
    "\n",
    "def set_seed(seed_value: int):\n",
    "    \"\"\"Устанавливает seed для воспроизводимости.\"\"\"\n",
    "    random.seed(seed_value); np.random.seed(seed_value); torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed_value)\n",
    "    print(f\"Установлен SEED = {seed_value}\")\n",
    "set_seed(TRAIN_CONFIG_MELSPEC['base_seed'])\n",
    "\n",
    "print(\"\\n--- Ячейка 2: Конфигурация для тестов n_mels = [8, 12] (УПРОЩЕННАЯ модель) готова ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 3: Загрузка данных и распаковка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 3: Загрузка метаданных и распаковка аудио ---\n",
      "Папка с аудио (C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_mel\\MorseAudioDecoder\\morse_dataset\\morse_dataset) уже существует. Распаковка пропускается.\n",
      "\n",
      "Загрузка CSV файлов...\n",
      "  Train DataFrame загружен: 30000 записей, Колонки: ['id', 'message']\n",
      "  Test DataFrame загружен: 5000 записей, Колонки: ['id']\n",
      "  Sample Submission загружен: 5000 записей.\n",
      "\n",
      "Проверка данных...\n",
      "\n",
      "Выборочная проверка наличия аудиофайлов...\n",
      "  Проверено 5 файлов - все найдены (например, C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_mel\\MorseAudioDecoder\\morse_dataset\\morse_dataset\\2309.opus).\n",
      "\n",
      "--- Ячейка 3: Загрузка данных завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 3: Загрузка Метаданных и Распаковка Аудио\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 3: Загрузка метаданных и распаковка аудио ---\")\n",
    "\n",
    "# --- Проверка и Распаковка Архива ---\n",
    "if not EXTRACTED_AUDIO_DIR.exists():\n",
    "    print(f\"Папка для аудио ({EXTRACTED_AUDIO_DIR}) не найдена.\")\n",
    "    if ZIP_PATH.is_file():\n",
    "        print(f\"Найден архив: {ZIP_PATH}. Распаковка...\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref: zip_ref.extractall(DATA_DIR)\n",
    "            print(f\"Архив распакован в: {DATA_DIR}\")\n",
    "            if not EXTRACTED_AUDIO_DIR.is_dir(): raise FileNotFoundError(f\"Не удалось найти папку '{EXTRACTED_AUDIO_DIR.name}' после распаковки в {DATA_DIR}.\")\n",
    "            else: print(f\"Папка с аудио найдена: {EXTRACTED_AUDIO_DIR}\")\n",
    "        except Exception as e: print(f\"Критическая ошибка при распаковке: {e}\"); traceback.print_exc(); raise SystemExit(\"Остановка.\")\n",
    "    else: print(f\"Критическая ошибка: Архив {ZIP_PATH} не найден.\"); raise SystemExit(\"Остановка.\")\n",
    "else: print(f\"Папка с аудио ({EXTRACTED_AUDIO_DIR}) уже существует. Распаковка пропускается.\")\n",
    "\n",
    "# --- Загрузка CSV файлов метаданных ---\n",
    "print(\"\\nЗагрузка CSV файлов...\")\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    print(f\"  Train DataFrame загружен: {len(train_df)} записей, Колонки: {train_df.columns.tolist()}\")\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "    print(f\"  Test DataFrame загружен: {len(test_df)} записей, Колонки: {test_df.columns.tolist()}\")\n",
    "    try: sample_sub_df = pd.read_csv(SAMPLE_SUB_PATH); print(f\"  Sample Submission загружен: {len(sample_sub_df)} записей.\")\n",
    "    except FileNotFoundError: print(f\"  Предупреждение: Файл Sample Submission ({SAMPLE_SUB_PATH}) не найден.\"); sample_sub_df = None\n",
    "except FileNotFoundError as e: print(f\"Критическая ошибка: Не найден CSV файл: {e}.\"); raise SystemExit(\"Остановка.\")\n",
    "except Exception as e: print(f\"Критическая ошибка при чтении CSV: {e}\"); traceback.print_exc(); raise SystemExit(\"Остановка.\")\n",
    "\n",
    "# --- Проверка наличия файлов и колонок ---\n",
    "print(\"\\nПроверка данных...\")\n",
    "if 'id' not in train_df.columns or 'message' not in train_df.columns: raise ValueError(\"В train_df нет 'id' или 'message'.\")\n",
    "if 'id' not in test_df.columns: raise ValueError(\"В test_df нет 'id'.\")\n",
    "\n",
    "# --- Выборочная проверка существования аудиофайлов ---\n",
    "print(\"\\nВыборочная проверка наличия аудиофайлов...\")\n",
    "if EXTRACTED_AUDIO_DIR.is_dir():\n",
    "    num_check = 5; example_ids = train_df['id'].sample(min(num_check, len(train_df)), random_state=SEED).tolist(); missing_files = []\n",
    "    for file_id in example_ids:\n",
    "        if not (EXTRACTED_AUDIO_DIR / file_id).is_file(): missing_files.append(file_id)\n",
    "    if not missing_files: print(f\"  Проверено {len(example_ids)} файлов - все найдены (например, {EXTRACTED_AUDIO_DIR / example_ids[0]}).\")\n",
    "    else: print(f\"  !!! ПРЕДУПРЕЖДЕНИЕ: Не найдены файлы для ID: {missing_files} !!!\")\n",
    "else: print(f\"  Проверка невозможна: Папка {EXTRACTED_AUDIO_DIR} не существует.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 3: Загрузка данных завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 4: Создание словаря символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 4: Создание словаря символов ---\n",
      "Найдено уникальных символов: 44\n",
      "Размер словаря (включая BLANK и PAD): 46\n",
      "Индекс BLANK ('_'): 44, Индекс PAD ('<pad>'): 45\n",
      "Количество классов для CTC Loss: 45\n",
      "\n",
      "--- Ячейка 4: Создание словаря завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 4: Создание Словаря Символов\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 4: Создание словаря символов ---\")\n",
    "\n",
    "if 'train_df' not in globals() or train_df is None: raise SystemExit(\"Остановка: train_df не найден.\")\n",
    "if 'message' not in train_df.columns: raise SystemExit(\"Остановка: В train_df нет 'message'.\")\n",
    "\n",
    "try:\n",
    "    # Собираем все уникальные символы из обучающей выборки\n",
    "    all_texts = train_df['message'].fillna('').astype(str)\n",
    "    unique_chars = sorted(list(set(char for text in all_texts for char in text)))\n",
    "\n",
    "    # Создаем словари для преобразования\n",
    "    char_to_index = {char: i for i, char in enumerate(unique_chars)}\n",
    "    index_to_char = {i: char for char, i in char_to_index.items()}\n",
    "\n",
    "    # Добавляем специальные токены BLANK (для CTC) и PAD (для выравнивания)\n",
    "    BLANK_IDX = len(char_to_index)\n",
    "    PAD_IDX = len(char_to_index) + 1\n",
    "    char_to_index[BLANK_TOKEN] = BLANK_IDX\n",
    "    char_to_index[PAD_TOKEN] = PAD_IDX\n",
    "    index_to_char[BLANK_IDX] = BLANK_TOKEN\n",
    "    index_to_char[PAD_IDX] = PAD_TOKEN\n",
    "\n",
    "    # Общее количество классов для выходного слоя модели (включая BLANK)\n",
    "    NUM_CLASSES_CTC = BLANK_IDX + 1\n",
    "\n",
    "    print(f\"Найдено уникальных символов: {len(unique_chars)}\")\n",
    "    print(f\"Размер словаря (включая BLANK и PAD): {len(char_to_index)}\")\n",
    "    print(f\"Индекс BLANK ('{BLANK_TOKEN}'): {BLANK_IDX}, Индекс PAD ('{PAD_TOKEN}'): {PAD_IDX}\")\n",
    "    print(f\"Количество классов для CTC Loss: {NUM_CLASSES_CTC}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Критическая ошибка при создании словаря: {e}\")\n",
    "    traceback.print_exc()\n",
    "    raise SystemExit(\"Остановка.\")\n",
    "\n",
    "if not char_to_index or not index_to_char or BLANK_IDX == -1 or PAD_IDX == -1 or NUM_CLASSES_CTC <= 0:\n",
    "    raise SystemExit(\"Остановка: Ошибка инициализации словаря.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 4: Создание словаря завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 5: Класс MorseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 5: Определение класса MorseDataset (Мел-Спектрограммы) ---\n",
      "\n",
      "--- Ячейка 5: Определение MorseDataset (Мел-Спектрограммы) завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 5: Класс MorseDataset (Мел-Спектрограммы)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 5: Определение класса MorseDataset (Мел-Спектрограммы) ---\")\n",
    "\n",
    "# Проверка наличия глобальных переменных из предыдущих ячеек\n",
    "if 'BLANK_IDX' not in globals() or 'PAD_IDX' not in globals(): raise ValueError(\"Индексы BLANK/PAD не инициализированы.\")\n",
    "if 'AUDIO_CONFIG_MELSPEC' not in globals(): raise ValueError(\"AUDIO_CONFIG_MELSPEC не определен.\")\n",
    "# MODEL_CONFIG_MELSPEC проверяется при создании модели\n",
    "\n",
    "class MorseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет для Морзе (Мел-Спектрограммы).\n",
    "    Выполняет: Загрузка -> Ресэмплинг -> [Trimming] -> Мел-Спектрограмма -> dB -> Z-Score.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dataframe: pd.DataFrame,\n",
    "                 audio_dir: Path,\n",
    "                 char_to_index: Dict[str, int],\n",
    "                 audio_config: Dict, # Принимает актуальный audio_config для запуска\n",
    "                 model_input_feature_dim: int, # Принимает актуальный n_mels\n",
    "                 is_train: bool = True):\n",
    "        super().__init__()\n",
    "        if not isinstance(dataframe, pd.DataFrame): raise TypeError(\"dataframe должен быть pandas DataFrame\")\n",
    "        if not isinstance(audio_dir, Path): raise TypeError(\"audio_dir должен быть pathlib.Path\")\n",
    "        if not isinstance(char_to_index, dict): raise TypeError(\"char_to_index должен быть словарем\")\n",
    "        if not isinstance(audio_config, dict): raise TypeError(\"audio_config должен быть словарем\")\n",
    "\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.char_to_index = char_to_index\n",
    "        self.is_train = is_train\n",
    "        self.audio_config = audio_config\n",
    "        self.expected_feature_dim = model_input_feature_dim # Ожидаемый размер = n_mels\n",
    "\n",
    "        # --- Извлечение параметров из audio_config ---\n",
    "        try:\n",
    "            self.feature_type = self.audio_config.get('feature_type', 'melspec')\n",
    "            if self.feature_type != 'melspec': raise ValueError(f\"Поддерживается только feature_type='melspec'\")\n",
    "\n",
    "            self.sample_rate = int(self.audio_config['sample_rate'])\n",
    "            self.n_fft = int(self.audio_config['n_fft'])\n",
    "            self.hop_length = int(self.audio_config['hop_length'])\n",
    "            self.n_mels = int(self.audio_config['n_mels'])\n",
    "            self.power = float(self.audio_config.get('power', 2.0))\n",
    "            self.fmin = float(self.audio_config.get('fmin', 0.0))\n",
    "            self.fmax = float(self.audio_config.get('fmax', self.sample_rate / 2.0))\n",
    "            self.apply_trimming = bool(self.audio_config.get('apply_trimming', False))\n",
    "            self.trim_top_db = float(self.audio_config.get('trim_top_db', 30))\n",
    "\n",
    "            nyquist = self.sample_rate / 2.0\n",
    "            if self.fmax > nyquist + 1:\n",
    "                print(f\"  Предупреждение Dataset: fmax ({self.fmax:.0f} Hz) > Найквиста ({nyquist:.0f} Hz).\")\n",
    "\n",
    "        except KeyError as e: raise ValueError(f\"Отсутствует ключ в audio_config: {e}\")\n",
    "        except (TypeError, ValueError) as e: raise ValueError(f\"Ошибка типа/значения в audio_config: {e}\")\n",
    "\n",
    "        # --- Валидация параметров ---\n",
    "        if self.sample_rate <= 0: raise ValueError(\"sample_rate > 0\")\n",
    "        if self.n_fft <= 0: raise ValueError(\"n_fft > 0\")\n",
    "        if self.hop_length <= 0: raise ValueError(\"hop_length > 0\")\n",
    "        if self.n_mels <= 0: raise ValueError(\"n_mels > 0\")\n",
    "        if self.apply_trimming and self.trim_top_db <= 0: raise ValueError(\"trim_top_db > 0 при apply_trimming=True\")\n",
    "        if self.n_mels != self.expected_feature_dim:\n",
    "             # Эта проверка важна при динамическом изменении n_mels\n",
    "             raise ValueError(f\"n_mels ({self.n_mels}) в audio_config не совпадает с model_input_feature_dim ({self.expected_feature_dim})!\")\n",
    "\n",
    "        # --- Информационное сообщение (однократно при инициализации) ---\n",
    "        # Чтобы не засорять вывод при создании DataLoader, можно вывести это сообщение\n",
    "        # один раз перед циклом обучения или убрать его совсем.\n",
    "        # trim_status = f\"Trimming ON (top_db={self.trim_top_db})\" if self.apply_trimming else \"Trimming OFF\"\n",
    "        # print(f\"MorseDataset (MelSpec): is_train={self.is_train}, SR={self.sample_rate}Hz, {trim_status}\")\n",
    "        # print(f\"  Признаки: MelSpec(n_fft={self.n_fft}, hop={self.hop_length}, n_mels={self.n_mels}, f_range={self.fmin:.0f}-{self.fmax:.0f}Hz) -> dB -> Z-Score\")\n",
    "        # print(f\"  Нормализация: Z-Score (глобальная)\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Возвращает количество примеров в датасете.\"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def _normalize_feature(self, feature_matrix: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Стандартная Z-score нормализация для всей матрицы признаков.\"\"\"\n",
    "        if not isinstance(feature_matrix, np.ndarray) or feature_matrix.size == 0:\n",
    "            # Возвращаем пустой массив правильной формы (F, 0)\n",
    "            return np.array([[]], dtype=np.float32).reshape(self.expected_feature_dim, 0)\n",
    "        epsilon = 1e-8\n",
    "        mean = np.mean(feature_matrix)\n",
    "        std = np.std(feature_matrix)\n",
    "        if std < epsilon:\n",
    "            # Если стандартное отклонение близко к нулю, возвращаем нули\n",
    "            return np.zeros_like(feature_matrix, dtype=np.float32)\n",
    "        return ((feature_matrix - mean) / (std + epsilon)).astype(np.float32)\n",
    "\n",
    "    def _calculate_features(self, waveform_np: np.ndarray, file_id_for_log: str = \"N/A\") -> Optional[torch.Tensor]:\n",
    "        \"\"\"Вычисляет признаки: Мел-Спектрограмма -> dB -> Z-Score.\"\"\"\n",
    "        # Ожидаем пустой тензор формы (n_mels, 0)\n",
    "        empty_tensor = torch.empty((self.expected_feature_dim, 0), dtype=torch.float32)\n",
    "        if not isinstance(waveform_np, np.ndarray) or waveform_np.size == 0:\n",
    "            return empty_tensor\n",
    "        try:\n",
    "            processed_waveform = waveform_np.astype(np.float32)\n",
    "\n",
    "            # 1. Вычисление Мел-спектрограммы\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(\n",
    "                y=processed_waveform,\n",
    "                sr=self.sample_rate,\n",
    "                n_fft=self.n_fft,\n",
    "                hop_length=self.hop_length,\n",
    "                n_mels=self.n_mels,\n",
    "                fmin=self.fmin,\n",
    "                fmax=self.fmax,\n",
    "                power=self.power\n",
    "            )\n",
    "\n",
    "            # 2. Конвертация в децибелы\n",
    "            mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max, top_db=None)\n",
    "\n",
    "            # 3. Нормализация Z-Score (глобальная)\n",
    "            normalized_mel_spec = self._normalize_feature(mel_spectrogram_db)\n",
    "\n",
    "            # 4. Проверка размерности и содержимого\n",
    "            if normalized_mel_spec.shape[0] != self.expected_feature_dim:\n",
    "                 # Эта ошибка не должна возникать, если n_mels == expected_feature_dim\n",
    "                 print(f\"ERROR ({file_id_for_log}): Неожиданное кол-во признаков! Ожидалось {self.expected_feature_dim}, получено {normalized_mel_spec.shape[0]}\")\n",
    "                 return None\n",
    "\n",
    "            features_tensor = torch.from_numpy(normalized_mel_spec) # Уже (F, T)\n",
    "\n",
    "            if not torch.isfinite(features_tensor).all():\n",
    "                # Заменяем NaN/Inf на 0, чтобы не терять пример\n",
    "                print(f\"WARNING ({file_id_for_log}): NaN/Inf в тензоре Мел-спектрограммы! Замена на 0.\")\n",
    "                features_tensor = torch.nan_to_num(features_tensor, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "            # Проверка на пустой тензор после всех операций\n",
    "            if features_tensor.shape[1] == 0:\n",
    "                # print(f\"Debug ({file_id_for_log}): Пустой тензор признаков после обработки.\")\n",
    "                return empty_tensor\n",
    "\n",
    "            return features_tensor # (n_mels, Time)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL ERROR в _calculate_features (MelSpec) ({file_id_for_log}): {e}\")\n",
    "            traceback.print_exc(limit=1)\n",
    "            return None\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor, str], Tuple[None, Optional[str]]]:\n",
    "        \"\"\"Загрузка, обработка (Мел-Спектрограмма) и возврат примера.\"\"\"\n",
    "        if not (0 <= index < len(self.dataframe)):\n",
    "            # Возвращаем None и ID для тестового режима, если индекс невалиден\n",
    "            return None, (f\"InvalidIndex_{index}\" if not self.is_train else None)\n",
    "        try:\n",
    "            # Получаем строку из DataFrame и ID файла\n",
    "            row = self.dataframe.iloc[index]\n",
    "            file_id = row['id']\n",
    "            audio_path = self.audio_dir / file_id\n",
    "        except Exception as e:\n",
    "            print(f\"Error get item data index {index}: {e}\")\n",
    "            return None, (f\"DataAccessError_{index}\" if not self.is_train else None)\n",
    "\n",
    "        # 1. Загрузка и Ресэмплинг\n",
    "        waveform_np: Optional[np.ndarray] = None\n",
    "        try:\n",
    "            waveform_np, _ = librosa.load(audio_path, sr=self.sample_rate, mono=True)\n",
    "            if waveform_np is None or waveform_np.size == 0:\n",
    "                # Файл пуст или не удалось загрузить\n",
    "                return None, (file_id if not self.is_train else None)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR ({file_id}): Файл не найден {audio_path}\")\n",
    "            return None, (file_id if not self.is_train else None)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR ({file_id}): Ошибка загрузки librosa: {e}\")\n",
    "            traceback.print_exc(limit=1)\n",
    "            return None, (file_id if not self.is_train else None)\n",
    "\n",
    "        # 2. Обрезка тишины (Trimming) - если включено\n",
    "        if self.apply_trimming:\n",
    "            try:\n",
    "                waveform_trimmed, _ = librosa.effects.trim(waveform_np, top_db=self.trim_top_db, frame_length=512, hop_length=128)\n",
    "                if waveform_trimmed is not None and waveform_trimmed.size > 0:\n",
    "                    waveform_np = waveform_trimmed\n",
    "                # else: Оставляем исходный, если trim удалил всё\n",
    "            except Exception as e_trim:\n",
    "                print(f\"ERROR ({file_id}): Ошибка librosa.effects.trim: {e_trim}. Используется исходный сигнал.\")\n",
    "\n",
    "        # 3. Вычисление признаков (Мел-Спектрограмма -> dB -> Z-Score)\n",
    "        features: Optional[torch.Tensor] = self._calculate_features(waveform_np, file_id)\n",
    "\n",
    "        # Проверка на None или пустой тензор (0 временных шагов)\n",
    "        if features is None or features.shape[1] == 0:\n",
    "            return None, (file_id if not self.is_train else None)\n",
    "\n",
    "        # 4. Подготовка цели (для train) или возврат ID (для test)\n",
    "        if self.is_train:\n",
    "            message_text = str(row.get('message', ''))\n",
    "            target_indices = [self.char_to_index.get(c) for c in message_text if c in self.char_to_index]\n",
    "            # Пропускаем примеры без валидных символов в таргете\n",
    "            if not target_indices:\n",
    "                return None, None # Возвращаем None, None чтобы collate_fn его отфильтровал\n",
    "            target_tensor = torch.tensor(target_indices, dtype=torch.long)\n",
    "            return features, target_tensor # (F, T), (Target_Len)\n",
    "        else:\n",
    "            # Для тестового режима возвращаем признаки и ID файла\n",
    "            return features, file_id # (F, T), str\n",
    "\n",
    "print(\"\\n--- Ячейка 5: Определение MorseDataset (Мел-Спектрограммы) завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 6: Функция collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 6: Определение функции collate_fn ---\n",
      "Функция collate_fn определена.\n",
      "\n",
      "--- Ячейка 6: Определение collate_fn завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 6: Функция collate_fn (Сборка Батчей)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 6: Определение функции collate_fn ---\")\n",
    "\n",
    "# Проверка зависимостей\n",
    "if 'PAD_IDX' not in globals(): raise ValueError(\"PAD_IDX не инициализирован!\")\n",
    "if 'torch' not in globals(): import torch\n",
    "if 'pad_sequence' not in globals(): from torch.nn.utils.rnn import pad_sequence\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "def collate_fn(batch: List[Tuple[Optional[torch.Tensor], Optional[Union[torch.Tensor, str]]]]) \\\n",
    "    -> Optional[Tuple[torch.Tensor, Union[torch.Tensor, List[str]], torch.Tensor, Optional[torch.Tensor]]]:\n",
    "    \"\"\"\n",
    "    Собирает батч данных из списка кортежей, возвращаемых MorseDataset.\n",
    "    Фильтрует некорректные примеры (где признаки или таргет/ID равны None).\n",
    "    Выполняет паддинг признаков и таргетов (для train/val).\n",
    "    Возвращает батч признаков, батч таргетов (или ID), длины признаков и длины таргетов.\n",
    "    \"\"\"\n",
    "    # 1. Фильтрация некорректных/пустых примеров\n",
    "    # Пример считается валидным, если есть тензор признаков (item[0])\n",
    "    # и он не пустой по временной оси (item[0].shape[1] > 0),\n",
    "    # а также есть таргет или ID (item[1]).\n",
    "    valid_batch = [item for item in batch if\n",
    "                   item[0] is not None and item[1] is not None and item[0].shape[1] > 0]\n",
    "\n",
    "    # Если после фильтрации батч пуст, возвращаем None\n",
    "    if not valid_batch:\n",
    "        return None\n",
    "\n",
    "    # Определяем, содержит ли батч таргеты (тензоры) или ID (строки)\n",
    "    is_train_or_val_batch = isinstance(valid_batch[0][1], torch.Tensor)\n",
    "\n",
    "    # 2. Разделение признаков и таргетов/ID\n",
    "    # Признаки имеют форму (F, T), пермутируем в (T, F) для pad_sequence\n",
    "    features_list = [item[0].permute(1, 0) for item in valid_batch] # Список тензоров (Ti, F)\n",
    "    targets_or_ids_list = [item[1] for item in valid_batch] # Список тензоров таргетов или строк ID\n",
    "\n",
    "    # 3. Паддинг признаков\n",
    "    # batch_first=True -> (B, T_max, F)\n",
    "    features_padded_time_first = pad_sequence(features_list, batch_first=True, padding_value=0.0)\n",
    "    # Возвращаем к формату (B, F, T_max), ожидаемому моделью (Conv1d)\n",
    "    features_padded = features_padded_time_first.permute(0, 2, 1)\n",
    "\n",
    "    # 4. Расчет длин признаков (до паддинга)\n",
    "    # Длина по временной оси (исходная T)\n",
    "    feature_lengths = torch.tensor([f.shape[0] for f in features_list], dtype=torch.long)\n",
    "\n",
    "    # 5. Обработка таргетов (для train/val) или ID (для test)\n",
    "    if is_train_or_val_batch:\n",
    "        # Батч содержит таргеты (тензоры)\n",
    "        targets_list: List[torch.Tensor] = targets_or_ids_list\n",
    "        # Паддинг таргетов\n",
    "        targets_padded: torch.Tensor = pad_sequence(targets_list, batch_first=True, padding_value=PAD_IDX)\n",
    "        # Расчет длин таргетов (до паддинга)\n",
    "        target_lengths: torch.Tensor = torch.tensor([len(t) for t in targets_list], dtype=torch.long)\n",
    "        # Возвращаем данные для обучения/валидации\n",
    "        return features_padded, targets_padded, feature_lengths, target_lengths\n",
    "    else:\n",
    "        # Батч содержит ID файлов (строки)\n",
    "        file_ids: List[str] = targets_or_ids_list\n",
    "        # Возвращаем данные для инференса (таргетов и их длин нет)\n",
    "        return features_padded, file_ids, feature_lengths, None\n",
    "\n",
    "print(\"Функция collate_fn определена.\")\n",
    "print(\"\\n--- Ячейка 6: Определение collate_fn завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 7: Модель MorseRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 7: Определение модели MorseRecognizer (ОБНОВЛЕНА для GRU/BiGRU) ---\n",
      "\n",
      "Создание экземпляра модели для проверки (с базовым конфигом)...\n",
      "Модель 'MorseRecognizer' создана (11,699,181 параметров) на cuda.\n",
      "\n",
      "Проверка forward pass...\n",
      "  Вход: torch.Size([2, 16, 500]), Выход: torch.Size([62, 2, 45])\n",
      "  Размерности выхода (T_red, B, C) корректны.\n",
      "\n",
      "--- Ячейка 7: Определение и проверка модели (ОБНОВЛЕНА для GRU/BiGRU) завершены ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 7: Модель MorseRecognizer (1D CNN + GRU/BiGRU) - ОБНОВЛЕНА\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 7: Определение модели MorseRecognizer (ОБНОВЛЕНА для GRU/BiGRU) ---\")\n",
    "\n",
    "# Проверка зависимостей\n",
    "if 'MODEL_CONFIG_MELSPEC' not in globals(): raise ValueError(\"MODEL_CONFIG_MELSPEC не определен!\") # Используем для проверки\n",
    "if 'NUM_CLASSES_CTC' not in globals() or NUM_CLASSES_CTC <= 0: raise ValueError(\"NUM_CLASSES_CTC не корректен!\")\n",
    "if 'torch' not in globals(): import torch\n",
    "if 'nn' not in globals(): import torch.nn as nn\n",
    "from typing import Union, Tuple, List, Dict, Optional\n",
    "\n",
    "class MorseRecognizer(nn.Module):\n",
    "    \"\"\"\n",
    "    Модель для распознавания Морзе (1D CNN + GRU/BiGRU). - ОБНОВЛЕНА\n",
    "    Принимает на вход признаки (B, F, T), где F - размерность признака (n_mels).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes_ctc: int, input_feature_dim: int,\n",
    "                 cnn_out_channels: List[int], cnn_kernel_size: int, cnn_stride: int,\n",
    "                 cnn_padding: Union[int, str], cnn_pool_kernel: int,\n",
    "                 rnn_hidden_size: int, rnn_num_layers: int, dropout_rate: float,\n",
    "                 activation_fn: str = \"GELU\", classifier_type: str = \"single\",\n",
    "                 bidirectional: bool = True): # <-- Добавлен параметр bidirectional\n",
    "        super().__init__()\n",
    "        self.input_feature_dim = input_feature_dim # Сохраняем для проверки в forward\n",
    "        self._time_reduction_factor = 1.0 # Фактор сжатия времени из-за MaxPool\n",
    "        cnn_layers = []\n",
    "        in_channels = input_feature_dim # Первый слой CNN принимает F каналов\n",
    "\n",
    "        try:\n",
    "            ActivationLayer = getattr(nn, activation_fn)\n",
    "        except AttributeError:\n",
    "            print(f\"Warning: Activation '{activation_fn}' не найдена. Используется GELU.\")\n",
    "            ActivationLayer = nn.GELU\n",
    "\n",
    "        # CNN Extractor (1D свертки по времени)\n",
    "        for i, out_channels in enumerate(cnn_out_channels):\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, cnn_kernel_size, cnn_stride, padding=cnn_padding),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                ActivationLayer(),\n",
    "                nn.MaxPool1d(cnn_pool_kernel), # Пулинг по временной оси\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "            cnn_layers.append(layer)\n",
    "            in_channels = out_channels # Выходные каналы текущего слоя = входные для следующего\n",
    "            self._time_reduction_factor *= cnn_pool_kernel # Считаем общее сжатие времени\n",
    "        self.cnn_extractor = nn.Sequential(*cnn_layers)\n",
    "        self.cnn_output_dim = in_channels # Размерность признаков после CNN\n",
    "\n",
    "        # RNN (GRU или BiGRU) - ОБНОВЛЕНО\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.cnn_output_dim, # Вход RNN = выход CNN\n",
    "            hidden_size=rnn_hidden_size,\n",
    "            num_layers=rnn_num_layers,\n",
    "            batch_first=True, # Ожидает (B, T, F_cnn)\n",
    "            bidirectional=bidirectional, # <-- Используем параметр\n",
    "            dropout=dropout_rate if rnn_num_layers > 1 else 0.0\n",
    "        )\n",
    "        # Корректный расчет выходной размерности RNN - ОБНОВЛЕНО\n",
    "        rnn_output_dim = rnn_hidden_size * 2 if bidirectional else rnn_hidden_size\n",
    "\n",
    "        # Classifier (Single или Double Linear)\n",
    "        self.classifier_type = classifier_type\n",
    "        if self.classifier_type == \"double\":\n",
    "            intermediate_dim = rnn_output_dim # Можно сделать настраиваемым\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(rnn_output_dim, intermediate_dim),\n",
    "                ActivationLayer(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(intermediate_dim, num_classes_ctc)\n",
    "            )\n",
    "            classifier_str = f\"DoubleLinear({rnn_output_dim}->{intermediate_dim}->{num_classes_ctc})\"\n",
    "        elif self.classifier_type == \"single\":\n",
    "            # Используем корректный rnn_output_dim - ОБНОВЛЕНО\n",
    "            self.classifier = nn.Linear(rnn_output_dim, num_classes_ctc)\n",
    "            classifier_str = f\"SingleLinear({rnn_output_dim}->{num_classes_ctc})\"\n",
    "        else:\n",
    "            raise ValueError(f\"Неизвестный classifier_type: {self.classifier_type}. Допустимы 'single', 'double'.\")\n",
    "\n",
    "        # Вывод архитектуры при инициализации (можно закомментировать для чистоты логов)\n",
    "        # rnn_type_str = \"BiGRU\" if bidirectional else \"GRU\" # <-- Обновлено для лога\n",
    "        # print(f\"Архитектура MorseRecognizer:\")\n",
    "        # print(f\"  Input Feature Dim: {self.input_feature_dim}\")\n",
    "        # print(f\"  CNN (1D): {len(cnn_out_channels)} layers, OutChannels={cnn_out_channels}, Kernel={cnn_kernel_size}, Pool={cnn_pool_kernel}\")\n",
    "        # print(f\"       Output Dim={self.cnn_output_dim}, Time Reduction Factor={self._time_reduction_factor:.1f}x\")\n",
    "        # print(f\"  RNN: {rnn_type_str}, Layers={rnn_num_layers}, Hidden Size={rnn_hidden_size}\") # <-- Обновлено для лога\n",
    "        # print(f\"       Output Dim={rnn_output_dim}\")\n",
    "        # print(f\"  Activation: {activation_fn}\")\n",
    "        # print(f\"  Classifier: {classifier_str}\")\n",
    "        # print(f\"  Dropout: {dropout_rate}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input: (B, F, T_in) - где F = input_feature_dim (n_mels)\n",
    "        -> CNN -> (B, C_cnn, T_red)\n",
    "        -> Permute -> (B, T_red, C_cnn)\n",
    "        -> RNN -> (B, T_red, H*2 или H)\n",
    "        -> Classifier -> (B, T_red, N_classes)\n",
    "        -> Permute -> Output: (T_red, B, N_classes) - для CTC Loss\n",
    "        \"\"\"\n",
    "        # Проверка размерности входа\n",
    "        if x.shape[1] != self.input_feature_dim:\n",
    "            raise ValueError(f\"Input feature dim mismatch! Expected {self.input_feature_dim}, got {x.shape[1]}. Shape: {x.shape}\")\n",
    "\n",
    "        x = self.cnn_extractor(x)        # (B, C_cnn, T_reduced)\n",
    "        x = x.permute(0, 2, 1)           # (B, T_reduced, C_cnn) - готовим для RNN (batch_first=True)\n",
    "        x_rnn, _ = self.rnn(x)           # (B, T_reduced, Hidden*2 или Hidden)\n",
    "        logits = self.classifier(x_rnn)  # (B, T_reduced, NumClasses)\n",
    "        # Готовим для CTC Loss: (Time, Batch, Classes)\n",
    "        logits = logits.permute(1, 0, 2) # (T_reduced, B, NumClasses)\n",
    "        return logits\n",
    "\n",
    "    def get_time_reduction_factor(self) -> float:\n",
    "        \"\"\"Возвращает фактор уменьшения временной размерности после CNN.\"\"\"\n",
    "        return self._time_reduction_factor\n",
    "\n",
    "# --- Создание и Проверка Экземпляра Модели (с базовым конфигом) ---\n",
    "# Эта проверка выполняется один раз для базовой конфигурации\n",
    "model_created_successfully = False\n",
    "model_check = None; dummy_input_check = None; dummy_output_check = None\n",
    "try:\n",
    "    print(\"\\nСоздание экземпляра модели для проверки (с базовым конфигом)...\")\n",
    "    # Используем базовый конфиг для проверки размерностей\n",
    "    # Теперь передаем bidirectional=True (как в базовом конфиге)\n",
    "    model_check = MorseRecognizer(\n",
    "        num_classes_ctc=NUM_CLASSES_CTC,\n",
    "        bidirectional=MODEL_CONFIG_MELSPEC.get('bidirectional', True), # Используем значение из конфига или True по умолчанию\n",
    "        **MODEL_CONFIG_MELSPEC # Используем базовый MODEL_CONFIG_MELSPEC\n",
    "    ).to(device)\n",
    "    total_params = sum(p.numel() for p in model_check.parameters() if p.requires_grad)\n",
    "    print(f\"Модель '{type(model_check).__name__}' создана ({total_params:,} параметров) на {device}.\")\n",
    "\n",
    "    print(\"\\nПроверка forward pass...\"); model_check.eval()\n",
    "    dummy_batch_size = 2; dummy_time_steps = 500 # Уменьшим для экономии памяти\n",
    "    dummy_input_check = torch.randn(dummy_batch_size, MODEL_CONFIG_MELSPEC['input_feature_dim'], dummy_time_steps).to(device)\n",
    "    with torch.no_grad(): dummy_output_check = model_check(dummy_input_check)\n",
    "    print(f\"  Вход: {dummy_input_check.shape}, Выход: {dummy_output_check.shape}\")\n",
    "    expected_time_dim = int(dummy_time_steps / model_check.get_time_reduction_factor())\n",
    "    if abs(dummy_output_check.shape[0] - expected_time_dim) > 2: print(f\"  ПРЕДУПРЕЖДЕНИЕ: Неожиданная длина выхода! Ожидалось ~{expected_time_dim}, получено {dummy_output_check.shape[0]}.\")\n",
    "    assert dummy_output_check.shape[1] == dummy_batch_size, \"Batch size mismatch!\"\n",
    "    assert dummy_output_check.shape[2] == NUM_CLASSES_CTC, \"Num classes mismatch!\"\n",
    "    print(\"  Размерности выхода (T_red, B, C) корректны.\"); model_created_successfully = True\n",
    "except Exception as e: print(f\"\\n!!! КРИТИЧЕСКАЯ ОШИБКА при создании/проверке модели: {e} !!!\"); traceback.print_exc()\n",
    "finally:\n",
    "    # Очистка памяти после проверки\n",
    "    if model_check is not None: del model_check\n",
    "    if dummy_input_check is not None: del dummy_input_check\n",
    "    if dummy_output_check is not None: del dummy_output_check\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "if not model_created_successfully: raise SystemExit(\"Остановка: Не удалось создать/проверить модель.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 7: Определение и проверка модели (ОБНОВЛЕНА для GRU/BiGRU) завершены ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 8: Loss, Optimizer, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 8: Настройка Loss, Optimizer, Scheduler ---\n",
      "Функция потерь: CTCLoss (blank=44, reduction='mean', zero_infinity=True)\n",
      "\n",
      "Оптимизатор: ADAMW (LR=5.0e-04, WD=1.0e-04) - будет создан в пайплайне\n",
      "Планировщик: OneCycleLR (div=3.0, final_div=100) - будет создан в пайплайне\n",
      "\n",
      "--- Ячейка 8: Настройка Loss, Optimizer, Scheduler завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 8: Настройка Loss, Optimizer, Scheduler\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 8: Настройка Loss, Optimizer, Scheduler ---\")\n",
    "\n",
    "# Проверка зависимостей\n",
    "if 'BLANK_IDX' not in globals(): raise ValueError(\"BLANK_IDX не инициализирован!\")\n",
    "if 'TRAIN_CONFIG_MELSPEC' not in globals(): raise ValueError(\"TRAIN_CONFIG_MELSPEC не определен!\")\n",
    "if 'optim' not in globals(): import torch.optim as optim\n",
    "if 'nn' not in globals(): import torch.nn as nn\n",
    "if 'OneCycleLR' not in globals(): from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# --- Функция Потерь ---\n",
    "# Используем CTCLoss, стандарт для задач sequence-to-sequence без выравнивания\n",
    "criterion = nn.CTCLoss(blank=BLANK_IDX, reduction='mean', zero_infinity=True)\n",
    "print(f\"Функция потерь: CTCLoss (blank={BLANK_IDX}, reduction='mean', zero_infinity=True)\")\n",
    "\n",
    "# --- Оптимизатор и Планировщик (параметры из TRAIN_CONFIG_MELSPEC) ---\n",
    "# Сами объекты optimizer и scheduler будут создаваться внутри run_training_pipeline\n",
    "optimizer_name = TRAIN_CONFIG_MELSPEC.get('optimizer', 'AdamW').lower()\n",
    "lr = TRAIN_CONFIG_MELSPEC['learning_rate']\n",
    "wd = TRAIN_CONFIG_MELSPEC['weight_decay']\n",
    "print(f\"\\nОптимизатор: {optimizer_name.upper()} (LR={lr:.1e}, WD={wd:.1e}) - будет создан в пайплайне\")\n",
    "\n",
    "div_f = TRAIN_CONFIG_MELSPEC.get('div_factor', 25.0)\n",
    "final_div_f = TRAIN_CONFIG_MELSPEC.get('final_div_factor', 1e4)\n",
    "print(f\"Планировщик: OneCycleLR (div={div_f}, final_div={final_div_f}) - будет создан в пайплайне\")\n",
    "\n",
    "print(\"\\n--- Ячейка 8: Настройка Loss, Optimizer, Scheduler завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 9: Функции Декодирования и Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 9: Определение функций декодирования и метрики ---\n",
      "Функции ctc_greedy_decode и calculate_levenshtein определены.\n",
      "\n",
      "--- Ячейка 9: Определение функций декодирования и метрики завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 9: Функции Декодирования (Greedy) и Метрики (Levenshtein)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 9: Определение функций декодирования и метрики ---\")\n",
    "\n",
    "# Проверка зависимостей\n",
    "if 'index_to_char' not in globals(): raise ValueError(\"index_to_char не определен!\")\n",
    "if 'BLANK_IDX' not in globals(): raise ValueError(\"BLANK_IDX не определен!\")\n",
    "if 'PAD_IDX' not in globals(): raise ValueError(\"PAD_IDX не определен!\")\n",
    "if 'torch' not in globals(): import torch\n",
    "if 'Levenshtein' not in globals(): import Levenshtein\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# --- Greedy CTC Decoding ---\n",
    "def ctc_greedy_decode(logits: torch.Tensor, index_to_char_map: Dict[int, str], blank_idx: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Жадное CTC декодирование батча логитов.\n",
    "    Input: logits (Time, Batch, Classes) - выход модели после log_softmax не нужен.\n",
    "    Output: List[str] - список декодированных строк для батча.\n",
    "    \"\"\"\n",
    "    decoded_batch = []\n",
    "    # Находим наиболее вероятный индекс для каждого временного шага в каждом примере батча\n",
    "    best_path = torch.argmax(logits, dim=2) # (Time, Batch)\n",
    "    best_path_np = best_path.cpu().numpy()\n",
    "\n",
    "    # Итерируем по каждому примеру в батче\n",
    "    for i in range(best_path_np.shape[1]):\n",
    "        sequence_indices = best_path_np[:, i]\n",
    "        # 1. Схлопываем повторяющиеся символы\n",
    "        collapsed_indices = [idx for j, idx in enumerate(sequence_indices) if j == 0 or idx != sequence_indices[j-1]]\n",
    "        # 2. Удаляем BLANK символы\n",
    "        final_indices = [idx for idx in collapsed_indices if idx != blank_idx]\n",
    "        # 3. Преобразуем индексы в символы\n",
    "        decoded_string = \"\".join([index_to_char_map.get(idx, '?') for idx in final_indices]) # '?' для неизвестных индексов\n",
    "        decoded_batch.append(decoded_string)\n",
    "    return decoded_batch\n",
    "\n",
    "# --- Levenshtein Distance ---\n",
    "def calculate_levenshtein(predictions: List[str], targets_padded: torch.Tensor, target_lengths: torch.Tensor,\n",
    "                          index_to_char_map: Dict[int, str], pad_idx: int) -> Tuple[float, List[Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Вычисляет среднее расстояние Левенштейна для батча и возвращает пары (предсказание, реальность).\n",
    "    Input:\n",
    "        predictions: List[str] - список предсказанных строк.\n",
    "        targets_padded: torch.Tensor (Batch, MaxTargetLen) - тензор реальных таргетов с паддингом.\n",
    "        target_lengths: torch.Tensor (Batch) - тензор реальных длин таргетов.\n",
    "        index_to_char_map: Dict[int, str] - словарь для преобразования индексов в символы.\n",
    "        pad_idx: int - индекс PAD токена.\n",
    "    Output:\n",
    "        Tuple[float, List[Tuple[str, str]]] - среднее расстояние Левенштейна, список пар (предсказание, реальность).\n",
    "    \"\"\"\n",
    "    total_distance = 0.0\n",
    "    num_valid_pairs = 0\n",
    "    decoded_pairs = [] # Список для хранения пар (предсказание, реальность)\n",
    "    targets_np = targets_padded.cpu().numpy()\n",
    "    target_lengths_np = target_lengths.cpu().numpy()\n",
    "    batch_size = targets_padded.shape[0]\n",
    "\n",
    "    # Проверка соответствия размеров предсказаний и таргетов\n",
    "    if len(predictions) != batch_size:\n",
    "        print(f\"Warning: Levenshtein size mismatch! Preds:{len(predictions)}, Targets:{batch_size}\")\n",
    "        return float('inf'), [] # Возвращаем бесконечность и пустой список\n",
    "\n",
    "    # Итерируем по каждому примеру в батче\n",
    "    for i in range(batch_size):\n",
    "        real_target_len = target_lengths_np[i]\n",
    "        pred_str = predictions[i]\n",
    "\n",
    "        # Получаем реальную строку таргета, удаляя паддинг\n",
    "        if real_target_len <= 0:\n",
    "            # Если таргет пустой (маловероятно, но возможно)\n",
    "            target_str = \"\"\n",
    "            dist = len(pred_str) # Расстояние равно длине предсказания\n",
    "        else:\n",
    "            target_indices = targets_np[i, :real_target_len]\n",
    "            target_str = \"\".join([index_to_char_map.get(idx, '?') for idx in target_indices if idx != pad_idx])\n",
    "            try:\n",
    "                # Вычисляем расстояние Левенштейна\n",
    "                dist = Levenshtein.distance(pred_str, target_str)\n",
    "            except Exception as e:\n",
    "                # Обработка возможных ошибок в Levenshtein\n",
    "                print(f\"Levenshtein Error: ('{pred_str}', '{target_str}'). {e}\")\n",
    "                dist = max(len(pred_str), len(target_str)) # Используем максимальную длину как штраф\n",
    "\n",
    "        total_distance += dist\n",
    "        num_valid_pairs += 1\n",
    "        decoded_pairs.append((pred_str, target_str)) # Добавляем пару\n",
    "\n",
    "    # Вычисляем среднее расстояние\n",
    "    mean_levenshtein = total_distance / num_valid_pairs if num_valid_pairs > 0 else float('inf')\n",
    "    return mean_levenshtein, decoded_pairs\n",
    "\n",
    "print(\"Функции ctc_greedy_decode и calculate_levenshtein определены.\")\n",
    "print(\"\\n--- Ячейка 9: Определение функций декодирования и метрики завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 10: Функции Обучения и Валидации Эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 10: Определение функций обучения и валидации эпохи ---\n",
      "Функции train_epoch и validate_epoch определены.\n",
      "\n",
      "--- Ячейка 10: Определение функций обучения и валидации завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 10: Функции Обучения и Валидации Эпохи\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 10: Определение функций обучения и валидации эпохи ---\")\n",
    "\n",
    "# Проверка зависимостей (глобальные переменные и импорты)\n",
    "if 'F' not in globals(): import torch.nn.functional as F\n",
    "if 'tqdm' not in globals(): from tqdm.notebook import tqdm\n",
    "if 'np' not in globals(): import numpy as np\n",
    "if 'torch' not in globals(): import torch\n",
    "if 'optim' not in globals(): import torch.optim as optim\n",
    "if 'nn' not in globals(): import torch.nn as nn\n",
    "if 'traceback' not in globals(): import traceback\n",
    "if 'DataLoader' not in globals(): from torch.utils.data import DataLoader\n",
    "if 'itertools' not in globals(): import itertools\n",
    "# Функции из Ячейки 9 должны быть определены\n",
    "if 'ctc_greedy_decode' not in globals() or 'calculate_levenshtein' not in globals():\n",
    "    raise NameError(\"Функции ctc_greedy_decode или calculate_levenshtein не определены!\")\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "\n",
    "# --- Функция Обучения Одной Эпохи ---\n",
    "def train_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.CTCLoss, optimizer: optim.Optimizer,\n",
    "                scheduler: Optional[optim.lr_scheduler._LRScheduler], device: torch.device, epoch_num: int, total_epochs: int,\n",
    "                index_to_char_map: Dict[int, str], blank_idx: int, pad_idx: int, grad_clip_norm: float,\n",
    "                batches_per_epoch: int = 0) -> Tuple[float, float, float]:\n",
    "    \"\"\" Выполняет одну эпоху обучения модели. \"\"\"\n",
    "    model.train() # Переключаем модель в режим обучения\n",
    "    running_loss = 0.0\n",
    "    total_lev_dist = 0.0\n",
    "    total_lr = 0.0\n",
    "    num_batches_processed = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Получаем фактор сжатия времени из модели (для расчета длин для CTC)\n",
    "    try:\n",
    "        time_factor = max(model.get_time_reduction_factor(), 1.0)\n",
    "    except AttributeError:\n",
    "        print(\"Warning: Метод get_time_reduction_factor() не найден в модели. Используется time_factor=1.0\")\n",
    "        time_factor = 1.0\n",
    "\n",
    "    # Определяем итератор и количество батчей для обработки\n",
    "    total_batches_in_loader = len(dataloader)\n",
    "    iterator = dataloader\n",
    "    num_batches_to_process = total_batches_in_loader\n",
    "    if batches_per_epoch > 0 and batches_per_epoch < total_batches_in_loader:\n",
    "         # Используем только часть эпохи, если batches_per_epoch задан\n",
    "         iterator = itertools.islice(dataloader, batches_per_epoch)\n",
    "         num_batches_to_process = batches_per_epoch\n",
    "    if num_batches_to_process == 0: # Если loader пуст или batches_per_epoch=0\n",
    "        print(\"Warning: Нет батчей для обработки в train_epoch.\")\n",
    "        return 0.0, float('inf'), 0.0\n",
    "\n",
    "    # Создаем прогресс-бар\n",
    "    pbar = tqdm(iterator, total=num_batches_to_process, desc=f\"Эпоха {epoch_num}/{total_epochs} [Тренировка]\", leave=False, ncols=1000)\n",
    "\n",
    "    # Итерация по батчам\n",
    "    for batch_idx, batch_data in enumerate(pbar):\n",
    "        # Пропускаем батч, если collate_fn вернул None\n",
    "        if batch_data is None: continue\n",
    "        features, targets, feature_lengths, target_lengths = batch_data\n",
    "        # Пропускаем, если данные некорректны\n",
    "        if features is None or targets is None or feature_lengths is None or target_lengths is None: continue\n",
    "\n",
    "        batch_size = features.size(0)\n",
    "        if batch_size == 0: continue\n",
    "\n",
    "        # Перемещаем данные на устройство\n",
    "        features = features.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        # Длины оставляем на CPU для CTC Loss\n",
    "        feature_lengths_cpu = feature_lengths.cpu()\n",
    "        target_lengths_cpu = target_lengths.cpu()\n",
    "\n",
    "        # Рассчитываем длины выхода модели для CTC Loss\n",
    "        # Используем floor и clamp(min=1), т.к. длина не может быть 0\n",
    "        input_lengths_ctc = torch.floor(feature_lengths_cpu.float() / time_factor + 1e-9).long().clamp(min=1)\n",
    "\n",
    "        loss_value = float('inf')\n",
    "        lev_dist_batch = float('inf')\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        try:\n",
    "            # Обнуляем градиенты\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Прямой проход через модель\n",
    "            logits = model(features) # Ожидаемый выход: (T_red, B, C)\n",
    "\n",
    "            # Проверка размерности батча на выходе\n",
    "            if logits.shape[1] != batch_size:\n",
    "                print(f\"\\n!!! ERROR (Train): Batch size mismatch! Out:{logits.shape[1]} != In:{batch_size}. Skip batch.\")\n",
    "                continue\n",
    "\n",
    "            # Применяем log_softmax для CTC Loss\n",
    "            log_probs = F.log_softmax(logits, dim=2) # (T_red, B, C)\n",
    "\n",
    "            # Убеждаемся, что длины входа для CTC не превышают реальную длину выхода модели\n",
    "            output_length = log_probs.shape[0]\n",
    "            input_lengths_ctc_clamped = input_lengths_ctc.clamp(max=output_length)\n",
    "\n",
    "            # Убеждаемся, что длины таргетов не превышают размерность тензора таргетов\n",
    "            target_lengths_clamped = target_lengths_cpu.clamp(max=targets.shape[1])\n",
    "\n",
    "            # Вычисляем CTC Loss\n",
    "            # Обрабатываем случай, когда target_length может быть 0 (хотя collate_fn должен это фильтровать)\n",
    "            valid_target_mask = target_lengths_clamped > 0\n",
    "            if not torch.all(valid_target_mask):\n",
    "                 # Если есть таргеты с нулевой длиной, считаем loss только для валидных\n",
    "                 log_probs_valid = log_probs[:, valid_target_mask, :]\n",
    "                 targets_valid = targets[valid_target_mask, :]\n",
    "                 input_lengths_valid = input_lengths_ctc_clamped[valid_target_mask]\n",
    "                 target_lengths_valid = target_lengths_clamped[valid_target_mask]\n",
    "                 # Считаем loss только если есть валидные примеры\n",
    "                 loss = criterion(log_probs_valid, targets_valid, input_lengths_valid, target_lengths_valid) if log_probs_valid.shape[1] > 0 else torch.tensor(0.0, device=device)\n",
    "            else:\n",
    "                 # Все таргеты валидны\n",
    "                 loss = criterion(log_probs, targets, input_lengths_ctc_clamped, target_lengths_clamped)\n",
    "\n",
    "            # Проверка на NaN/Inf в loss\n",
    "            if not torch.isfinite(loss):\n",
    "                print(f\"\\n!!! WARNING (Train): NaN/Inf loss на батче {batch_idx}! Пропуск шага оптимизатора.\")\n",
    "                optimizer.zero_grad() # Сбрасываем градиенты на всякий случай\n",
    "                loss_value = 30.0 # Штраф для логгирования\n",
    "                lev_dist_batch = 30.0\n",
    "                continue # Переходим к следующему батчу\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "            # Обратный проход и шаг оптимизатора\n",
    "            if loss.requires_grad: # Убеждаемся, что loss требует градиентов\n",
    "                loss.backward()\n",
    "                # Обрезка градиентов для стабильности\n",
    "                if grad_clip_norm > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_norm)\n",
    "                optimizer.step()\n",
    "                # Шаг планировщика (если используется)\n",
    "                if scheduler:\n",
    "                    scheduler.step() # OneCycleLR обновляется после каждого батча\n",
    "\n",
    "            # Вычисление метрики Levenshtein (без градиентов)\n",
    "            with torch.no_grad():\n",
    "                decoded_preds = ctc_greedy_decode(logits, index_to_char_map, blank_idx)\n",
    "                lev_dist_batch, _ = calculate_levenshtein(decoded_preds, targets.cpu(), target_lengths_cpu, index_to_char_map, pad_idx)\n",
    "                if not np.isfinite(lev_dist_batch): lev_dist_batch = 20.0 # Ограничиваем для логгирования\n",
    "\n",
    "        except RuntimeError as e:\n",
    "             if \"CUDA out of memory\" in str(e):\n",
    "                 print(\"\\n!!! CUDA Out of Memory (Train) !!! Попробуйте уменьшить batch_size.\")\n",
    "                 # Можно добавить логику для уменьшения batch_size или остановки\n",
    "                 raise e # Перевыбрасываем ошибку\n",
    "             else:\n",
    "                 print(f\"\\n!!! RuntimeError (Train) на батче {batch_idx}: {e} !!!\")\n",
    "                 traceback.print_exc(limit=1)\n",
    "                 loss_value = 30.0; lev_dist_batch = 30.0 # Штрафы\n",
    "        except Exception as e:\n",
    "             print(f\"\\n!!! Error (Train) на батче {batch_idx}: {e} !!!\")\n",
    "             traceback.print_exc(limit=1)\n",
    "             loss_value = 30.0; lev_dist_batch = 30.0 # Штрафы\n",
    "\n",
    "        # Обновление статистики эпохи\n",
    "        running_loss += loss_value * batch_size\n",
    "        total_lev_dist += lev_dist_batch * batch_size\n",
    "        total_samples += batch_size\n",
    "        total_lr += current_lr\n",
    "        num_batches_processed += 1\n",
    "\n",
    "        # Обновление прогресс-бара\n",
    "        pbar.set_postfix(loss=f'{loss_value:.3f}', lev=f'{lev_dist_batch:.3f}', lr=f'{current_lr:.2e}')\n",
    "\n",
    "    pbar.close() # Закрываем прогресс-бар\n",
    "\n",
    "    # Вычисляем средние значения за эпоху\n",
    "    avg_loss = running_loss / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lev = total_lev_dist / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lr = total_lr / num_batches_processed if num_batches_processed > 0 else 0.0\n",
    "\n",
    "    return avg_loss, avg_lev, avg_lr\n",
    "\n",
    "# --- Функция Валидации Одной Эпохи ---\n",
    "def validate_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.CTCLoss, device: torch.device,\n",
    "                   index_to_char_map: Dict[int, str], blank_idx: int, pad_idx: int\n",
    "                  ) -> Tuple[float, float, List[Tuple[str, str]]]:\n",
    "    \"\"\" Выполняет одну эпоху валидации модели. \"\"\"\n",
    "    model.eval() # Переключаем модель в режим оценки\n",
    "    running_loss = 0.0\n",
    "    total_lev_dist = 0.0\n",
    "    total_samples = 0\n",
    "    all_decoded_pairs = [] # Список для примеров декодирования\n",
    "\n",
    "    # Получаем фактор сжатия времени\n",
    "    try: time_factor = max(model.get_time_reduction_factor(), 1.0)\n",
    "    except AttributeError: time_factor = 1.0\n",
    "\n",
    "    # Создаем прогресс-бар\n",
    "    pbar = tqdm(dataloader, desc=\"   [Валидация]\", leave=False, ncols=1000)\n",
    "\n",
    "    # Отключаем расчет градиентов\n",
    "    with torch.no_grad():\n",
    "        # Итерация по батчам\n",
    "        for batch_data in pbar:\n",
    "            if batch_data is None: continue\n",
    "            features, targets, feature_lengths, target_lengths = batch_data\n",
    "            if features is None or targets is None or feature_lengths is None or target_lengths is None: continue\n",
    "\n",
    "            batch_size = features.size(0)\n",
    "            if batch_size == 0: continue\n",
    "\n",
    "            # Перемещаем данные на устройство\n",
    "            features = features.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            feature_lengths_cpu = feature_lengths.cpu()\n",
    "            target_lengths_cpu = target_lengths.cpu()\n",
    "\n",
    "            # Рассчитываем длины для CTC\n",
    "            input_lengths_ctc = torch.floor(feature_lengths_cpu.float() / time_factor + 1e-9).long().clamp(min=1)\n",
    "\n",
    "            loss_value = float('inf')\n",
    "            lev_dist_batch = float('inf')\n",
    "            decoded_pairs_batch = []\n",
    "\n",
    "            try:\n",
    "                # Прямой проход\n",
    "                logits = model(features) # (T_red, B, C)\n",
    "                output_length = logits.shape[0]\n",
    "\n",
    "                # Проверка размерности батча\n",
    "                if logits.shape[1] != batch_size:\n",
    "                    print(f\"\\n!!! ERROR (Val): Batch size mismatch! Out:{logits.shape[1]} != In:{batch_size}. Skip batch.\")\n",
    "                    continue\n",
    "\n",
    "                # Log_softmax для CTC\n",
    "                log_probs = F.log_softmax(logits, dim=2)\n",
    "\n",
    "                # Клампинг длин\n",
    "                input_lengths_ctc_clamped = input_lengths_ctc.clamp(max=output_length)\n",
    "                target_lengths_clamped = target_lengths_cpu.clamp(max=targets.shape[1])\n",
    "\n",
    "                # Расчет Loss\n",
    "                valid_target_mask = target_lengths_clamped > 0\n",
    "                if not torch.all(valid_target_mask):\n",
    "                    log_probs_valid = log_probs[:, valid_target_mask, :]\n",
    "                    targets_valid = targets[valid_target_mask, :]\n",
    "                    input_lengths_valid = input_lengths_ctc_clamped[valid_target_mask]\n",
    "                    target_lengths_valid = target_lengths_clamped[valid_target_mask]\n",
    "                    loss = criterion(log_probs_valid, targets_valid, input_lengths_valid, target_lengths_valid) if log_probs_valid.shape[1] > 0 else torch.tensor(0.0, device=device)\n",
    "                else:\n",
    "                    loss = criterion(log_probs, targets, input_lengths_ctc_clamped, target_lengths_clamped)\n",
    "\n",
    "                if torch.isfinite(loss): loss_value = loss.item()\n",
    "                else: print(\"\\nWarning (Val): NaN/Inf loss.\")\n",
    "\n",
    "                # Декодирование и расчет Levenshtein\n",
    "                decoded_preds = ctc_greedy_decode(logits, index_to_char_map, blank_idx)\n",
    "                lev_dist_batch, decoded_pairs_batch = calculate_levenshtein(decoded_preds, targets.cpu(), target_lengths_cpu, index_to_char_map, pad_idx)\n",
    "                if not np.isfinite(lev_dist_batch): lev_dist_batch = 20.0\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n!!! Error (Val): {e} !!!\")\n",
    "                traceback.print_exc(limit=1)\n",
    "                loss_value=float('inf'); lev_dist_batch=float('inf')\n",
    "                decoded_pairs_batch = [(\"ERROR\",\"ERROR\")] * batch_size # Заполняем ошибками\n",
    "\n",
    "            # Обновление статистики эпохи\n",
    "            if np.isfinite(loss_value): # Учитываем только конечные значения loss\n",
    "                running_loss += loss_value * batch_size\n",
    "            total_lev_dist += lev_dist_batch * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # Сохраняем несколько примеров декодирования для вывода\n",
    "            if len(all_decoded_pairs) < 10: # Сохраняем первые 10 пар\n",
    "                all_decoded_pairs.extend(decoded_pairs_batch[:max(0, 10 - len(all_decoded_pairs))])\n",
    "\n",
    "            # Обновление прогресс-бара\n",
    "            pbar.set_postfix(loss=f'{loss_value:.3f}', lev=f'{lev_dist_batch:.3f}')\n",
    "\n",
    "    pbar.close() # Закрываем прогресс-бар\n",
    "\n",
    "    # Вычисляем средние значения за эпоху\n",
    "    avg_loss = running_loss / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lev = total_lev_dist / total_samples if total_samples > 0 else float('inf')\n",
    "\n",
    "    return avg_loss, avg_lev, all_decoded_pairs\n",
    "\n",
    "print(\"Функции train_epoch и validate_epoch определены.\")\n",
    "print(\"\\n--- Ячейка 10: Определение функций обучения и валидации завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 11 Интерактивная настройка RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 11: Интерактивная Настройка Мел-Спектрограмм (SR=8000 Гц, Маленькие n_fft) ---\n",
      ">>> Исследуем n_fft = [32, 64, 128, 256] <<<\n",
      "Параметры визуализации (Мел-Спектрограммы): SR=8000Hz (Найквист = 4000 Гц)\n",
      "  Defaults: n_fft=256, hop=64, n_mels=16, fmin=0, fmax=4200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d246daab1eb417db23449c57f26d91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Интерактивная настройка Мел-Спектрограммы (SR=8000Hz, Маленькие n_fft)</b>'), Dr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ячейка 11: Интерактивная настройка Мел-Спектрограмм готова (Маленькие n_fft) ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 11: Интерактивная Настройка Мел-Спектрограмм (Маленькие n_fft)\n",
    "# =============================================================================\n",
    "# Используем AUDIO_CONFIG_MELSPEC для параметров по умолчанию\n",
    "print(f\"--- Ячейка 11: Интерактивная Настройка Мел-Спектрограмм (SR={AUDIO_CONFIG_MELSPEC['sample_rate']} Гц, Маленькие n_fft) ---\")\n",
    "print(\">>> Исследуем n_fft = [32, 64, 128, 256] <<<\")\n",
    "\n",
    "if not IPYWIDGETS_AVAILABLE:\n",
    "    print(\"ipywidgets не доступен. Пропуск интерактивной ячейки.\")\n",
    "else:\n",
    "    # Импорты (остаются те же)\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, Audio, clear_output\n",
    "    import matplotlib.pyplot as plt\n",
    "    import librosa, librosa.display, numpy as np, pandas as pd\n",
    "    from pathlib import Path; import traceback, random\n",
    "\n",
    "    # Проверка глобальных переменных (остается та же)\n",
    "    required_globals_vis = ['AUDIO_CONFIG_MELSPEC', 'EXTRACTED_AUDIO_DIR', 'train_df', 'SEED']\n",
    "    missing_globals_vis = [v for v in required_globals_vis if v not in globals()]\n",
    "    if missing_globals_vis: raise NameError(f\"Отсутствуют переменные: {missing_globals_vis}\")\n",
    "    if train_df.empty: raise ValueError(\"train_df пуст.\")\n",
    "\n",
    "    # Базовые параметры из конфига\n",
    "    SR_VIS = AUDIO_CONFIG_MELSPEC['sample_rate']\n",
    "    # === ИЗМЕНЕНИЕ ЗДЕСЬ: Устанавливаем N_FFT_DEFAULT = 256 ===\n",
    "    N_FFT_DEFAULT = 256\n",
    "    # ========================================================\n",
    "    # === ИЗМЕНЕНИЕ ЗДЕСЬ: Устанавливаем HOP_LENGTH_DEFAULT = 64 ===\n",
    "    HOP_LENGTH_DEFAULT = 64 # Константа из Ячейки 2 для тренировки, используем как дефолт здесь\n",
    "    # ==========================================================\n",
    "    N_MELS_DEFAULT = AUDIO_CONFIG_MELSPEC['n_mels'] # n_mels пока не меняем\n",
    "    FMIN_DEFAULT = AUDIO_CONFIG_MELSPEC.get('fmin', 0.0)\n",
    "    FMAX_DEFAULT = AUDIO_CONFIG_MELSPEC.get('fmax', SR_VIS / 2.0) # Используем fmax=4200 из конфига\n",
    "    POWER_DEFAULT = AUDIO_CONFIG_MELSPEC.get('power', 2.0)\n",
    "    NYQUIST_FREQ = SR_VIS / 2.0\n",
    "\n",
    "    print(f\"Параметры визуализации (Мел-Спектрограммы): SR={SR_VIS}Hz (Найквист = {NYQUIST_FREQ:.0f} Гц)\")\n",
    "    print(f\"  Defaults: n_fft={N_FFT_DEFAULT}, hop={HOP_LENGTH_DEFAULT}, n_mels={N_MELS_DEFAULT}, fmin={FMIN_DEFAULT:.0f}, fmax={FMAX_DEFAULT:.0f}\")\n",
    "\n",
    "    # --- Функции расчета и отрисовки (остаются без изменений) ---\n",
    "    def calculate_interactive_melspec(waveform_np: np.ndarray, sr: int, n_fft: int, hop_length: int, n_mels: int, fmin: float, fmax: float, power: float, file_id_vis: str = \"N/A\") -> Optional[np.ndarray]:\n",
    "        if not isinstance(waveform_np, np.ndarray) or waveform_np.size == 0: return None\n",
    "        try: mel_spectrogram = librosa.feature.melspectrogram( y=waveform_np.astype(np.float32), sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, fmin=fmin, fmax=fmax, power=power ); mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max); return mel_spectrogram_db\n",
    "        except Exception as e: print(f\"Error calc interactive melspec ({file_id_vis}): {e}\"); traceback.print_exc(limit=1); return None\n",
    "    def plot_interactive_melspec(waveform: np.ndarray, mel_spec_db: np.ndarray, sr: int, hop_length: int, n_mels: int, fmin: float, fmax: float, n_fft: int, file_id: str, nyquist: float):\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(16, 8), sharex=True); win_ms = 1000 * n_fft / sr; hop_ms = 1000 * hop_length / sr\n",
    "        title = (f\"Интерактивный Анализ Мел-Спектрограммы: {file_id}\\nSR={sr}, n_fft={n_fft} (~{win_ms:.1f}ms), hop={hop_length} (~{hop_ms:.1f}ms), n_mels={n_mels}, fmin={fmin:.0f}, fmax={fmax:.0f}\")\n",
    "        fig.suptitle(title, fontsize=14); librosa.display.waveshow(waveform, sr=sr, ax=axes[0], color='grey', alpha=0.7); axes[0].set_title(\"Waveform\"); axes[0].label_outer(); axes[0].grid(True, linestyle=':')\n",
    "        if mel_spec_db is not None and mel_spec_db.size > 0: img = librosa.display.specshow(mel_spec_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='mel', ax=axes[1], fmin=fmin, fmax=fmax, cmap='magma'); axes[1].set_title(f\"Mel Spectrogram ({n_mels} bins)\"); axes[1].axhline(nyquist, color='cyan', linestyle='--', linewidth=1, label=f'Найквист ({nyquist:.0f} Hz)'); axes[1].legend(loc='upper right'); fig.colorbar(img, ax=axes[1], format='%+2.0f dB')\n",
    "        else: axes[1].set_title(\"Mel Spectrogram - Нет данных\"); axes[1].text(0.5, 0.5, 'Нет данных', ha='center', va='center', transform=axes[1].transAxes)\n",
    "        axes[1].set_xlabel(\"Время (с)\"); plt.tight_layout(rect=[0, 0.03, 1, 0.93]); plt.show()\n",
    "\n",
    "    # --- Виджеты ---\n",
    "    file_ids_vis_list = train_df['id'].unique().tolist(); file_ids_vis_list = random.sample(file_ids_vis_list, min(500, len(file_ids_vis_list)))\n",
    "    if not file_ids_vis_list: raise SystemExit(\"Остановка: Нет файлов для визуализации.\")\n",
    "    file_dd = widgets.Dropdown(options=file_ids_vis_list, description='Аудиофайл:', style={'description_width': 'initial'})\n",
    "\n",
    "    # === ИЗМЕНЕНИЕ ЗДЕСЬ: Обновляем опции и значение по умолчанию для n_fft_dd ===\n",
    "    n_fft_dd = widgets.Dropdown(\n",
    "        options=[32, 64, 128, 256], # Новые опции\n",
    "        value=N_FFT_DEFAULT, # Дефолт теперь 256\n",
    "        description='n_fft:', style={'description_width': 'initial'}\n",
    "    )\n",
    "    # ========================================================================\n",
    "\n",
    "    # === ИЗМЕНЕНИЕ ЗДЕСЬ: Обновляем дефолт и min/step для hop_length_slider ===\n",
    "    hop_length_slider = widgets.IntSlider(\n",
    "        value=HOP_LENGTH_DEFAULT, # Дефолт 64\n",
    "        min=16, # Минимальный шаг\n",
    "        max=N_FFT_DEFAULT, # Изначально max = дефолтный n_fft\n",
    "        step=16, # Шаг поменьше\n",
    "        description='hop_length:', style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px'), continuous_update=False\n",
    "    )\n",
    "    # ======================================================================\n",
    "\n",
    "    n_mels_slider = widgets.IntSlider(value=N_MELS_DEFAULT, min=20, max=128, step=4, description='n_mels:', style={'description_width': 'initial'}, layout=widgets.Layout(width='400px'), continuous_update=False)\n",
    "    fmin_slider = widgets.IntSlider( value=int(FMIN_DEFAULT), min=0, max=1000, step=50, description='fmin (Hz):', style={'description_width': 'initial'}, layout=widgets.Layout(width='400px'), continuous_update=False )\n",
    "    fmax_slider = widgets.IntSlider( value=int(FMAX_DEFAULT), min=500, max=4200, step=100, description='fmax (Hz):', style={'description_width': 'initial'}, layout=widgets.Layout(width='400px'), continuous_update=False )\n",
    "    info_label = widgets.Label(value=\"\")\n",
    "    warning_html = widgets.HTML( value=f\"<b style='color:orange;'>Внимание:</b> Частота Найквиста для SR={SR_VIS}Hz равна <b style='color:cyan;'>{NYQUIST_FREQ:.0f} Гц</b>. Установка <b>fmax</b> выше этого значения использует диапазон частот, где нет информации об исходном сигнале.\" )\n",
    "    params_box = widgets.VBox([ n_fft_dd, hop_length_slider, n_mels_slider, fmin_slider, fmax_slider, warning_html, info_label ])\n",
    "    plot_output = widgets.Output()\n",
    "\n",
    "    # --- Функции для связи виджетов (остаются те же, логика корректна) ---\n",
    "    def _link_fft_hop(change):\n",
    "        n_fft_val = n_fft_dd.value\n",
    "        # hop_length не должен превышать n_fft\n",
    "        hop_length_slider.max = n_fft_val\n",
    "        hop_length_slider.value = min(hop_length_slider.value, n_fft_val) # Гарантируем, что hop <= n_fft\n",
    "        win_ms = 1000 * n_fft_val / SR_VIS\n",
    "        hop_ms = 1000 * hop_length_slider.value / SR_VIS\n",
    "        info_label.value = f\"(Window: ~{win_ms:.1f}ms, Hop: ~{hop_ms:.1f}ms)\"\n",
    "    n_fft_dd.observe(_link_fft_hop, names='value'); hop_length_slider.observe(_link_fft_hop, names='value')\n",
    "    def _link_freqs(change):\n",
    "        fmin_val = fmin_slider.value; fmax_slider.min = fmin_val + 100; fmax_slider.value = max(fmax_slider.value, fmax_slider.min)\n",
    "    fmin_slider.observe(_link_freqs, names='value')\n",
    "\n",
    "    # --- Обработчик изменений (остается тот же) ---\n",
    "    def handle_melspec_vis_change(change):\n",
    "        file_id = file_dd.value; n_fft_val = n_fft_dd.value; hop_length_val = hop_length_slider.value\n",
    "        n_mels_val = n_mels_slider.value; fmin_val = fmin_slider.value; fmax_val = fmax_slider.value\n",
    "        if not file_id:\n",
    "            with plot_output: clear_output(wait=True); print(\"Выберите файл.\")\n",
    "            return\n",
    "        audio_path = EXTRACTED_AUDIO_DIR / file_id\n",
    "        if not audio_path.is_file():\n",
    "            with plot_output: clear_output(wait=True); print(f\"Ошибка: Файл не найден {audio_path}\")\n",
    "            return\n",
    "        try:\n",
    "            waveform, _ = librosa.load(audio_path, sr=SR_VIS, mono=True)\n",
    "            mel_spec_db_res = calculate_interactive_melspec( waveform, SR_VIS, n_fft_val, hop_length_val, n_mels_val, fmin_val, fmax_val, POWER_DEFAULT, file_id_vis=file_id )\n",
    "            with plot_output:\n",
    "                clear_output(wait=True); print(f\"Отображение: {file_id} (SR={SR_VIS}Hz)\")\n",
    "                plot_interactive_melspec( waveform, mel_spec_db_res, SR_VIS, hop_length_val, n_mels_val, fmin_val, fmax_val, n_fft_val, file_id, NYQUIST_FREQ )\n",
    "        except Exception as e:\n",
    "             with plot_output: clear_output(wait=True); print(f\"Ошибка обработки {file_id}:\\n{e}\"); traceback.print_exc(limit=2)\n",
    "\n",
    "    # --- Привязка обработчиков ко всем виджетам (остается та же) ---\n",
    "    file_dd.observe(handle_melspec_vis_change, names='value'); n_fft_dd.observe(handle_melspec_vis_change, names='value'); hop_length_slider.observe(handle_melspec_vis_change, names='value'); n_mels_slider.observe(handle_melspec_vis_change, names='value'); fmin_slider.observe(handle_melspec_vis_change, names='value'); fmax_slider.observe(handle_melspec_vis_change, names='value')\n",
    "\n",
    "    # --- Отображение UI и первый запуск (остается тем же) ---\n",
    "    ui_melspec_tuning = widgets.VBox([ widgets.HTML(f\"<b>Интерактивная настройка Мел-Спектрограммы (SR={SR_VIS}Hz, Маленькие n_fft)</b>\"), file_dd, params_box, plot_output ])\n",
    "    display(ui_melspec_tuning)\n",
    "    _link_fft_hop(None); _link_freqs(None); handle_melspec_vis_change(None) # Первый запуск\n",
    "\n",
    "    print(f\"\\n--- Ячейка 11: Интерактивная настройка Мел-Спектрограмм готова (Маленькие n_fft) ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 12: Функция Полного Цикла Обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 12: Определение функции run_training_pipeline ---\n",
      "--- Функция run_training_pipeline (Исправлена заглушка MLflow) определена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 12: Функция для Полного Цикла Обучения и Инференса (Исправлена заглушка MLflow)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 12: Определение функции run_training_pipeline ---\")\n",
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import numpy as np, pandas as pd, time, json, random, traceback\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Union, Tuple, List, Dict, Optional\n",
    "\n",
    "# --- Проверка и импорт MLflow или создание ЗАГЛУШКИ (ИСПРАВЛЕНО) ---\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"Предупреждение: mlflow не найден. Логирование экспериментов будет отключено.\")\n",
    "    class DummyRun:\n",
    "        def __enter__(self): return self\n",
    "        def __exit__(self, *args): pass\n",
    "        class DummyRunInfo: info = type('obj', (object,), {'run_id': 'mlflow_disabled'})()\n",
    "        info = DummyRunInfo()\n",
    "    class DummyMLflow:\n",
    "        def set_experiment(self, *args, **kwargs): pass\n",
    "        def start_run(self, *args, **kwargs): return DummyRun()\n",
    "        def log_param(self, *args, **kwargs): pass\n",
    "        def log_params(self, *args, **kwargs): pass\n",
    "        # === ИСПРАВЛЕНИЕ ЗДЕСЬ: Каждая функция на своей строке ===\n",
    "        def log_metric(self, *args, **kwargs): pass\n",
    "        def log_metrics(self, *args, **kwargs): pass\n",
    "        # =====================================================\n",
    "        def log_artifact(self, *args, **kwargs): pass\n",
    "        def log_dict(self, *args, **kwargs): pass\n",
    "        def set_tag(self, *args, **kwargs): pass\n",
    "        def active_run(self): return None\n",
    "        def end_run(self, status='FINISHED'): pass\n",
    "    mlflow = DummyMLflow()\n",
    "\n",
    "\n",
    "# --- Проверка глобальных зависимостей ---\n",
    "def check_global_dependencies():\n",
    "    required = ['MorseDataset', 'MorseRecognizer', 'collate_fn', 'train_epoch', 'validate_epoch',\n",
    "                'ctc_greedy_decode', 'calculate_levenshtein', 'set_seed']\n",
    "    missing = [r for r in required if not callable(globals().get(r))]\n",
    "    if missing: raise NameError(f\"Отсутствуют зависимости: {missing}. Убедитесь, что все ячейки выше выполнены.\")\n",
    "\n",
    "# --- Функция пайплайна ---\n",
    "def run_training_pipeline(\n",
    "    # Конфиги\n",
    "    audio_config: Dict, model_config: Dict, train_config: Dict,\n",
    "    # Данные/пути\n",
    "    full_train_df: pd.DataFrame, test_df: pd.DataFrame, audio_dir: Path, base_output_dir: Path,\n",
    "    # Словари/константы\n",
    "    char_to_index: Dict[str, int], index_to_char: Dict[int, str],\n",
    "    blank_idx: int, pad_idx: int, num_classes_ctc: int,\n",
    "    # Управление\n",
    "    device: torch.device, run_suffix: str, base_filename_suffix: str, # Используем полный базовый суффикс\n",
    "    seed: int = 42, mlflow_experiment_name: str = \"Morse_Experiment\"\n",
    ") -> Dict:\n",
    "    \"\"\" Выполняет полный цикл: данные, обучение, сохранение, инференс. \"\"\"\n",
    "    check_global_dependencies()\n",
    "    run_results = { \"run_suffix\": run_suffix, \"status\": \"pending\", \"best_val_lev\": float('inf'), \"best_epoch\": None,\n",
    "                    \"final_train_loss\": float('inf'), \"final_val_loss\": float('inf'), \"train_time_min\": 0.0,\n",
    "                    \"infer_time_sec\": 0.0, \"model_path\": None, \"params_path\": None, \"submission_path\": None, \"error\": None }\n",
    "    print(f\"\\n{'='*20} Запуск: {run_suffix} {'='*20}\")\n",
    "    print(f\"Audio Config: {json.dumps(audio_config)}\")\n",
    "    print(f\"Model Config: {json.dumps(model_config)}\") # Выводим конфиг модели\n",
    "    print(f\"Train Config: {json.dumps(train_config)}\")\n",
    "\n",
    "    # Формирование путей (используем полный базовый суффикс + суффикс запуска)\n",
    "    output_filename_base = f\"{base_filename_suffix}{run_suffix}\"\n",
    "    current_model_path = base_output_dir / f\"model_{output_filename_base}.pth\"\n",
    "    current_params_path = base_output_dir / f\"params_{output_filename_base}.json\"\n",
    "    current_submission_path = base_output_dir / f\"submission_greedy_{output_filename_base}.csv\"\n",
    "    run_results.update({ \"model_path\": str(current_model_path), \"params_path\": str(current_params_path), \"submission_path\": str(current_submission_path) })\n",
    "    print(f\"  Пути: Model={current_model_path.name}, Params={current_params_path.name}, Sub={current_submission_path.name}\")\n",
    "\n",
    "    # Объявление переменных для finally\n",
    "    model = None; criterion = None; optimizer = None; scheduler = None\n",
    "    full_dataset = None; train_subset = None; val_subset = None\n",
    "    train_loader = None; val_loader = None\n",
    "    inference_model_instance = None; infer_test_dataset = None; test_loader_infer = None\n",
    "    logits_infer = None; features_infer = None\n",
    "\n",
    "    try:\n",
    "        set_seed(seed)\n",
    "        # --- 1. Подготовка Данных ---\n",
    "        print(\"\\n1. Подготовка данных...\")\n",
    "        if 'MorseDataset' not in globals(): raise NameError(\"Класс MorseDataset не определен!\")\n",
    "        full_dataset = MorseDataset( dataframe=full_train_df, audio_dir=audio_dir, char_to_index=char_to_index,\n",
    "                                     audio_config=audio_config, model_input_feature_dim=model_config['input_feature_dim'],\n",
    "                                     is_train=True )\n",
    "        dataset_size = len(full_dataset);\n",
    "        if dataset_size == 0: raise ValueError(\"Обучающий датасет пуст!\")\n",
    "        val_split_ratio = train_config['validation_split_ratio']\n",
    "        val_size = int(np.floor(val_split_ratio * dataset_size)); train_size = dataset_size - val_size\n",
    "        if train_size <= 0 or val_size <= 0: raise ValueError(f\"Некорректное разделение: Train={train_size}, Val={val_size}\")\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "        train_subset, val_subset = random_split(full_dataset, [train_size, val_size], generator=generator)\n",
    "        bs = train_config['batch_size']; nw = train_config['num_workers']; pm = (device.type == 'cuda')\n",
    "        if 'collate_fn' not in globals(): raise NameError(\"Функция collate_fn не определена!\")\n",
    "        train_loader = DataLoader(train_subset, batch_size=bs, shuffle=True, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "        val_loader = DataLoader(val_subset, batch_size=bs*2, shuffle=False, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "        print(f\"  Данные готовы: Train={len(train_subset)} ({len(train_loader)} батчей), Val={len(val_subset)} ({len(val_loader)} батчей).\")\n",
    "\n",
    "        # --- 2. Инициализация Модели, Loss, Optimizer, Scheduler ---\n",
    "        print(\"\\n2. Инициализация компонентов...\")\n",
    "        if 'MorseRecognizer' not in globals(): raise NameError(\"Класс MorseRecognizer не определен!\")\n",
    "        model = MorseRecognizer(num_classes_ctc=num_classes_ctc, **model_config).to(device) # Используем переданный model_config\n",
    "        criterion = nn.CTCLoss(blank=blank_idx, reduction='mean', zero_infinity=True).to(device)\n",
    "        optimizer_name = train_config.get('optimizer', 'AdamW').lower(); lr = train_config['learning_rate']; wd = train_config['weight_decay']\n",
    "        if optimizer_name == 'adamw': optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        elif optimizer_name == 'adam': optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        else: print(f\"Warning: Неизвестный optimizer '{optimizer_name}'. Используется AdamW.\"); optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        print(f\"  Model, Loss, Optimizer ({type(optimizer).__name__}) готовы.\")\n",
    "        # Scheduler\n",
    "        total_batches_in_loader = len(train_loader); batches_per_epoch_run = train_config.get(\"batches_per_epoch\", 0)\n",
    "        steps_per_epoch = total_batches_in_loader\n",
    "        if batches_per_epoch_run > 0 and batches_per_epoch_run < total_batches_in_loader: steps_per_epoch = batches_per_epoch_run\n",
    "        if steps_per_epoch <= 0: raise ValueError(f\"Steps_per_epoch ({steps_per_epoch}) должен быть > 0!\")\n",
    "        total_steps = train_config['num_epochs'] * steps_per_epoch\n",
    "        div_f = train_config.get('div_factor', 25.0); final_div_f = train_config.get('final_div_factor', 1e4)\n",
    "        scheduler = OneCycleLR(optimizer, max_lr=lr, total_steps=total_steps, pct_start=0.3, anneal_strategy='cos', div_factor=div_f, final_div_factor=final_div_f)\n",
    "        print(f\"  Scheduler OneCycleLR создан (total_steps={total_steps}, div_factor={div_f}, final_div_factor={final_div_f}).\")\n",
    "\n",
    "        # --- 3. Цикл Обучения с MLflow ---\n",
    "        print(\"\\n3. Запуск цикла обучения...\")\n",
    "        mlflow.set_experiment(mlflow_experiment_name)\n",
    "        with mlflow.start_run(run_name=f\"run_{run_suffix}\") as current_run:\n",
    "            mlflow_run_id = current_run.info.run_id; print(f\"  MLflow Run ID: {mlflow_run_id}\")\n",
    "            run_results[\"mlflow_run_id\"] = mlflow_run_id; run_results[\"status\"] = \"training\"\n",
    "            mlflow.log_param(\"run_suffix\", run_suffix); mlflow.log_param(\"base_filename\", base_filename_suffix)\n",
    "            mlflow.log_params({\"seed\": seed, **train_config}); mlflow.log_dict(audio_config, \"audio_config.json\"); mlflow.log_dict(model_config, \"model_config.json\")\n",
    "            mlflow.set_tag(\"status\", \"training\")\n",
    "\n",
    "            start_time_train = time.time(); best_val_lev = float('inf'); epochs_without_improvement = 0; best_epoch = None\n",
    "            best_model_local_path_temp = base_output_dir / f\"temp_best_model_{mlflow_run_id}.pth\"\n",
    "\n",
    "            for epoch in range(1, train_config['num_epochs'] + 1):\n",
    "                print(f\"\\n--- Эпоха {epoch}/{train_config['num_epochs']} ---\")\n",
    "                if 'train_epoch' not in globals(): raise NameError(\"Функция train_epoch не определена!\")\n",
    "                avg_train_loss, avg_train_lev, avg_epoch_lr = train_epoch( model, train_loader, criterion, optimizer, scheduler, device, epoch, train_config['num_epochs'], index_to_char, blank_idx, pad_idx, train_config['gradient_clip_norm'], batches_per_epoch=batches_per_epoch_run )\n",
    "                if 'validate_epoch' not in globals(): raise NameError(\"Функция validate_epoch не определена!\")\n",
    "                avg_val_loss, avg_val_lev, _ = validate_epoch( model, val_loader, criterion, device, index_to_char, blank_idx, pad_idx )\n",
    "                run_results.update({ \"final_train_loss\": avg_train_loss, \"final_val_loss\": avg_val_loss })\n",
    "                mlflow.log_metrics({ \"train_loss\": avg_train_loss, \"train_levenshtein\": avg_train_lev, \"val_loss\": avg_val_loss, \"val_levenshtein\": avg_val_lev, \"learning_rate\": avg_epoch_lr }, step=epoch)\n",
    "                print(f\"  Итоги Эпохи {epoch}: Train Loss={avg_train_loss:.4f}, Train Lev={avg_train_lev:.4f}, Val Loss={avg_val_loss:.4f}, Val Lev={avg_val_lev:.4f}\")\n",
    "\n",
    "                if np.isfinite(avg_val_lev) and avg_val_lev < best_val_lev:\n",
    "                    print(f\"  ✨ Val Lev улучшился: {best_val_lev:.4f} -> {avg_val_lev:.4f}. Сохранение...\"); best_val_lev = avg_val_lev; best_epoch = epoch\n",
    "                    run_results.update({ \"best_val_lev\": best_val_lev, \"best_epoch\": best_epoch })\n",
    "                    try: torch.save(model.state_dict(), best_model_local_path_temp)\n",
    "                    except Exception as save_err: print(f\"  !!! Ошибка сохранения временной модели: {save_err} !!!\")\n",
    "                    epochs_without_improvement = 0\n",
    "                else:\n",
    "                    epochs_without_improvement += 1; print(f\"  Val Lev не улучшился ({avg_val_lev:.4f} vs best {best_val_lev:.4f}). Без улучшений: {epochs_without_improvement}/{train_config['early_stopping_patience']}\")\n",
    "                if epochs_without_improvement >= train_config['early_stopping_patience']:\n",
    "                    print(f\"  ❗️ Ранняя остановка на эпохе {epoch}!\"); mlflow.set_tag(\"status\", \"completed_early_stopping\"); run_results[\"status\"] = \"completed_early_stopping\"; break\n",
    "            # --- Конец цикла по эпохам ---\n",
    "            if run_results[\"status\"] == \"training\": run_results[\"status\"] = \"completed\"; mlflow.set_tag(\"status\", \"completed\")\n",
    "            train_duration_min = (time.time() - start_time_train) / 60; run_results[\"train_time_min\"] = train_duration_min\n",
    "            print(f\"\\n  Обучение завершено ({run_results['status']}) за {train_duration_min:.2f} мин. Лучший Val Lev: {best_val_lev:.4f} (Эпоха {best_epoch})\")\n",
    "\n",
    "            # --- 4. Сохранение Лучшей Модели и Параметров ---\n",
    "            print(\"\\n4. Сохранение артефактов...\")\n",
    "            if np.isfinite(best_val_lev): mlflow.log_metric(\"best_val_levenshtein\", best_val_lev)\n",
    "            if best_epoch is not None: mlflow.log_metric(\"best_epoch\", best_epoch)\n",
    "            mlflow.log_metric(\"training_time_min\", train_duration_min)\n",
    "\n",
    "            model_saved_final = False\n",
    "            if best_model_local_path_temp.exists() and np.isfinite(best_val_lev):\n",
    "                try:\n",
    "                    current_model_path.parent.mkdir(parents=True, exist_ok=True); current_model_path.unlink(missing_ok=True)\n",
    "                    best_model_local_path_temp.rename(current_model_path); print(f\"  Лучшая модель сохранена: {current_model_path.name}\")\n",
    "                    mlflow.log_artifact(str(current_model_path), artifact_path=\"model\"); model_saved_final = True\n",
    "                except Exception as e: print(f\"  !!! Ошибка перемещения/логирования модели: {e} !!!\")\n",
    "            else: print(\"  !!! Лучшая модель не сохранена.\"); mlflow.set_tag(\"model_saved\", \"False\")\n",
    "\n",
    "            final_params = { 'audio_config': audio_config, 'model_config': model_config, 'train_config': train_config,\n",
    "                             'char_map': { 'char_to_index': char_to_index, 'index_to_char': {str(k): v for k, v in index_to_char.items()},\n",
    "                                           'BLANK_IDX': blank_idx, 'PAD_IDX': pad_idx, 'NUM_CLASSES_CTC': num_classes_ctc },\n",
    "                             'results': { k: v for k, v in run_results.items() if k not in ['model_path', 'params_path', 'submission_path', 'mlflow_run_id'] and (np.isfinite(v) if isinstance(v, float) else True) } }\n",
    "            try:\n",
    "                current_params_path.parent.mkdir(parents=True, exist_ok=True); current_params_path.unlink(missing_ok=True)\n",
    "                with open(current_params_path, 'w', encoding='utf-8') as f: json.dump(final_params, f, indent=4, ensure_ascii=False)\n",
    "                print(f\"  Параметры сохранены: {current_params_path.name}\"); mlflow.log_artifact(str(current_params_path), artifact_path=\"config\")\n",
    "            except Exception as e: print(f\"  !!! Ошибка сохранения/логирования параметров: {e} !!!\")\n",
    "        # --- Конец MLflow run ---\n",
    "\n",
    "        # --- 5. Инференс на Тестовых Данных ---\n",
    "        print(\"\\n5. Запуск инференса...\")\n",
    "        infer_duration_sec = 0.0\n",
    "        if model_saved_final:\n",
    "            infer_start_time = time.time()\n",
    "            try:\n",
    "                 print(f\"  Загрузка: {current_model_path.name}, {current_params_path.name}\")\n",
    "                 with open(current_params_path, 'r', encoding='utf-8') as f: loaded_params_inf = json.load(f)\n",
    "                 loaded_audio_config_inf = loaded_params_inf['audio_config']; loaded_model_config_inf = loaded_params_inf['model_config']\n",
    "                 loaded_char_map_inf = loaded_params_inf['char_map']; loaded_index_to_char_inf = {int(k): v for k, v in loaded_char_map_inf['index_to_char'].items()}\n",
    "                 loaded_blank_idx_inf = loaded_char_map_inf['BLANK_IDX']; loaded_num_classes_inf = loaded_char_map_inf['NUM_CLASSES_CTC']\n",
    "\n",
    "                 if 'MorseRecognizer' not in globals(): raise NameError(\"Класс MorseRecognizer не определен для инференса!\")\n",
    "                 inference_model_instance = MorseRecognizer(num_classes_ctc=loaded_num_classes_inf, **loaded_model_config_inf).to(device)\n",
    "                 try: inference_model_instance.load_state_dict(torch.load(current_model_path, map_location=device, weights_only=True))\n",
    "                 except TypeError: print(\"   Warning: weights_only=True не поддерживается.\"); inference_model_instance.load_state_dict(torch.load(current_model_path, map_location=device))\n",
    "                 inference_model_instance.eval(); print(f\"  Модель для инференса загружена.\")\n",
    "\n",
    "                 print(f\"  Создание тестового DataLoader...\");\n",
    "                 if 'MorseDataset' not in globals(): raise NameError(\"Класс MorseDataset не определен для инференса!\")\n",
    "                 infer_test_dataset = MorseDataset( dataframe=test_df, audio_dir=audio_dir, char_to_index=loaded_char_map_inf['char_to_index'],\n",
    "                                                    audio_config=loaded_audio_config_inf, model_input_feature_dim=loaded_model_config_inf['input_feature_dim'], is_train=False )\n",
    "                 infer_bs = train_config.get('batch_size', 16) * 4\n",
    "                 if 'collate_fn' not in globals(): raise NameError(\"Функция collate_fn не определена для инференса!\")\n",
    "                 test_loader_infer = DataLoader(infer_test_dataset, batch_size=infer_bs, shuffle=False, collate_fn=collate_fn, num_workers=0, pin_memory=(device.type == 'cuda') )\n",
    "\n",
    "                 print(f\"  Предсказание...\"); predictions: Dict[str, str] = {}\n",
    "                 if 'ctc_greedy_decode' not in globals(): raise NameError(\"Функция ctc_greedy_decode не определена для инференса!\")\n",
    "                 with torch.no_grad():\n",
    "                     pbar_infer = tqdm(test_loader_infer, desc=\"Инференс\", leave=False, ncols=1000)\n",
    "                     for batch_data_infer in pbar_infer:\n",
    "                         if batch_data_infer is None: continue\n",
    "                         features_infer, file_ids_infer, _, _ = batch_data_infer\n",
    "                         if features_infer is None or file_ids_infer is None or len(features_infer) == 0: continue\n",
    "                         features_infer = features_infer.to(device, non_blocking=True)\n",
    "                         try:\n",
    "                             logits_infer = inference_model_instance(features_infer)\n",
    "                             decoded_batch_infer = ctc_greedy_decode(logits_infer, loaded_index_to_char_inf, loaded_blank_idx_inf)\n",
    "                             for file_id, pred_text in zip(file_ids_infer, decoded_batch_infer): predictions[file_id] = pred_text\n",
    "                         except Exception as e_inf_batch: print(f\"\\nОшибка инференса батча: {e_inf_batch}\"); [predictions.update({fid:\"ERROR_INFER\"}) for fid in file_ids_infer]\n",
    "\n",
    "                 infer_duration_sec = time.time() - infer_start_time; run_results[\"infer_time_sec\"] = infer_duration_sec\n",
    "                 print(f\"  Инференс завершен за {infer_duration_sec:.2f} сек. Предсказаний: {len(predictions)}/{len(test_df)}\")\n",
    "\n",
    "                 if predictions:\n",
    "                     print(f\"  Формирование submission: {current_submission_path.name}\")\n",
    "                     submission_df = pd.DataFrame({'id': test_df['id']}); submission_df['message'] = submission_df['id'].map(predictions).fillna(\"ERROR_MISSING\")\n",
    "                     current_submission_path.unlink(missing_ok=True)\n",
    "                     submission_df.to_csv(current_submission_path, index=False); print(f\"  Submission сохранен.\"); mlflow.log_artifact(str(current_submission_path), artifact_path=\"submission\")\n",
    "                 else: print(\"  Предсказания не сгенерированы.\"); mlflow.set_tag(\"submission_generated\", \"False\")\n",
    "            except Exception as e_infer: print(f\"  !!! Ошибка инференса: {e_infer} !!!\"); traceback.print_exc(limit=2); run_results[\"error\"] = f\"Inference Error: {e_infer}\"; run_results[\"status\"] = \"failed_inference\"; mlflow.set_tag(\"status\", \"failed_inference\")\n",
    "            finally:\n",
    "                 try: del inference_model_instance\n",
    "                 except NameError: pass\n",
    "                 try: del test_loader_infer\n",
    "                 except NameError: pass\n",
    "                 try: del infer_test_dataset\n",
    "                 except NameError: pass\n",
    "                 if 'logits_infer' in locals(): del logits_infer\n",
    "                 if 'features_infer' in locals(): del features_infer\n",
    "                 if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "        else: print(\"  Инференс пропущен (лучшая модель не сохранена).\"); run_results[\"status\"] += \"_no_inference\"; mlflow.set_tag(\"inference_skipped\", \"True\")\n",
    "\n",
    "    except Exception as e_main: print(f\"!!! КРИТИЧЕСКАЯ ОШИБКА в {run_suffix}: {e_main} !!!\"); traceback.print_exc(); run_results[\"error\"] = str(e_main); run_results[\"status\"] = \"failed_critical\";\n",
    "    try: mlflow.set_tag(\"status\", \"failed_critical\"); mlflow.set_tag(\"error\", str(e_main)[:250])\n",
    "    except: pass\n",
    "\n",
    "    finally:\n",
    "        try: del model\n",
    "        except NameError: pass\n",
    "        try: del criterion\n",
    "        except NameError: pass\n",
    "        try: del optimizer\n",
    "        except NameError: pass\n",
    "        try: del scheduler\n",
    "        except NameError: pass\n",
    "        if 'full_dataset' in locals(): del full_dataset\n",
    "        if 'train_subset' in locals(): del train_subset\n",
    "        if 'val_subset' in locals(): del val_subset\n",
    "        if 'train_loader' in locals(): del train_loader\n",
    "        if 'val_loader' in locals(): del val_loader\n",
    "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "        print(f\"{'='*20} Завершение: {run_suffix} {'='*20}\\n\")\n",
    "    return run_results\n",
    "\n",
    "print(\"--- Функция run_training_pipeline (Исправлена заглушка MLflow) определена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 13: Основной Цикл Обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 13: Запуск Цикла Обучения (Тест n_mels = 8, 12, hop=64, УПРОЩЕННАЯ модель) ---\n",
      "\n",
      "1. Определение параметров для цикла экспериментов...\n",
      "  Значения n_mels для теста: [12]\n",
      "  Константа hop_length: 64\n",
      "  Используется УПРОЩЕННАЯ модель для калибровки.\n",
      "\n",
      "2. Копирование конфигурации обучения (с уменьшенными эпохами)...\n",
      "\n",
      "--- Начало цикла запусков (1 итераций) ---\n",
      "MLflow эксперимент: 'Morse_MelSpec_NMels_Calibration_SimpleModel_Hop64'\n",
      "\n",
      "--- Попытка завершить ЛЮБОЙ активный MLflow run перед циклом ---\n",
      "!!! Обнаружен активный MLflow run (e99ccd86c412461dbc19c5fbc3a2cc88). Принудительно завершаем... !!!\n",
      "Предупреждение: Ошибка при проверке/завершении активного MLflow run: The run e99ccd86c412461dbc19c5fbc3a2cc88 must be in 'active' lifecycle_stage.\n",
      "\n",
      "========== Запуск 1/1: n_mels = 12, hop_length = 64, Simple Model ==========\n",
      "  Аудио параметры: {\"feature_type\": \"melspec\", \"sample_rate\": 8000, \"n_fft\": 128, \"hop_length\": 64, \"n_mels\": 12, \"fmin\": 0.0, \"fmax\": 4200.0, \"power\": 2.0, \"apply_trimming\": false, \"trim_top_db\": 30}\n",
      "  Параметры модели (Упрощенной): {\"input_feature_dim\": 12, \"cnn_out_channels\": [64, 128, 128], \"cnn_kernel_size\": 9, \"cnn_stride\": 1, \"cnn_padding\": \"same\", \"cnn_pool_kernel\": 2, \"rnn_hidden_size\": 512, \"rnn_num_layers\": 2, \"dropout_rate\": 0.2, \"activation_fn\": \"GELU\", \"classifier_type\": \"single\", \"bidirectional\": true}\n",
      "------------------------------\n",
      "--- Проверка/Завершение MLflow run перед итерацией 1... ---\n",
      "--- Активный run не найден перед итерацией 1. Продолжаем. ---\n",
      "--- Вызов run_training_pipeline для n_mels=12 (Simple Model) ---\n",
      "\n",
      "==================== Запуск: _nMels12_Simple ====================\n",
      "Audio Config: {\"feature_type\": \"melspec\", \"sample_rate\": 8000, \"n_fft\": 128, \"hop_length\": 64, \"n_mels\": 12, \"fmin\": 0.0, \"fmax\": 4200.0, \"power\": 2.0, \"apply_trimming\": false, \"trim_top_db\": 30}\n",
      "Model Config: {\"input_feature_dim\": 12, \"cnn_out_channels\": [64, 128, 128], \"cnn_kernel_size\": 9, \"cnn_stride\": 1, \"cnn_padding\": \"same\", \"cnn_pool_kernel\": 2, \"rnn_hidden_size\": 512, \"rnn_num_layers\": 2, \"dropout_rate\": 0.2, \"activation_fn\": \"GELU\", \"classifier_type\": \"single\", \"bidirectional\": true}\n",
      "Train Config: {\"batch_size\": 8, \"num_workers\": 0, \"num_epochs\": 10, \"learning_rate\": 0.0005, \"div_factor\": 3.0, \"final_div_factor\": 100, \"weight_decay\": 0.0001, \"optimizer\": \"AdamW\", \"early_stopping_patience\": 5, \"gradient_clip_norm\": 2.0, \"validation_split_ratio\": 0.1, \"base_seed\": 42, \"batches_per_epoch\": 1000}\n",
      "  Пути: Model=model_SR8k_MelSpec12_fft128h64_f0-4k2_CNN128_RNN2x512_GRU_GELU_Clssingle_LR5e-04_WD1e-04_nMels12_Simple.pth, Params=params_SR8k_MelSpec12_fft128h64_f0-4k2_CNN128_RNN2x512_GRU_GELU_Clssingle_LR5e-04_WD1e-04_nMels12_Simple.json, Sub=submission_greedy_SR8k_MelSpec12_fft128h64_f0-4k2_CNN128_RNN2x512_GRU_GELU_Clssingle_LR5e-04_WD1e-04_nMels12_Simple.csv\n",
      "Установлен SEED = 42\n",
      "\n",
      "1. Подготовка данных...\n",
      "  Предупреждение Dataset: fmax (4200 Hz) > Найквиста (4000 Hz).\n",
      "  Данные готовы: Train=27000 (3375 батчей), Val=3000 (188 батчей).\n",
      "\n",
      "2. Инициализация компонентов...\n",
      "  Model, Loss, Optimizer (AdamW) готовы.\n",
      "  Scheduler OneCycleLR создан (total_steps=10000, div_factor=3.0, final_div_factor=100).\n",
      "\n",
      "3. Запуск цикла обучения...\n",
      "  MLflow Run ID: c8286a08ab364d918ec7d767a4d9123a\n",
      "\n",
      "--- Эпоха 1/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5401280eb704b5cbec3376ab1ff493d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 1/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a27465d36a46abbba66139e51b0dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 1: Train Loss=4.2039, Train Lev=8.9545, Val Loss=4.0138, Val Lev=8.8780\n",
      "  ✨ Val Lev улучшился: inf -> 8.8780. Сохранение...\n",
      "\n",
      "--- Эпоха 2/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d163a2a5b53f414491052587f1d14122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 2/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c7d689fb374813ab0178054933d4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 2: Train Loss=1.6866, Train Lev=3.8174, Val Loss=0.6665, Val Lev=1.4747\n",
      "  ✨ Val Lev улучшился: 8.8780 -> 1.4747. Сохранение...\n",
      "\n",
      "--- Эпоха 3/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60318b304db24f699e18150099edba28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 3/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cc14dea3474174bc869b1a9b352406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 3: Train Loss=0.6334, Train Lev=1.3906, Val Loss=0.5054, Val Lev=1.1553\n",
      "  ✨ Val Lev улучшился: 1.4747 -> 1.1553. Сохранение...\n",
      "\n",
      "--- Эпоха 4/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d99396f0af3442980c001400e05ca48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 4/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a1615c1f794449b2e6be7030effd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 4: Train Loss=0.5446, Train Lev=1.2291, Val Loss=0.4294, Val Lev=0.9890\n",
      "  ✨ Val Lev улучшился: 1.1553 -> 0.9890. Сохранение...\n",
      "\n",
      "--- Эпоха 5/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e191e4a367b42a1bc7127b4311e679c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 5/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 13: Цикл Запуска Обучения (Тест n_mels = 8, 12 с hop_length=64, УПРОЩЕННАЯ модель) - ОБНОВЛЕНА\n",
    "# =============================================================================\n",
    "print(f\"--- Ячейка 13: Запуск Цикла Обучения (Тест n_mels = 8, 12, hop={HOP_LENGTH_CONST}, УПРОЩЕННАЯ модель) ---\")\n",
    "\n",
    "# Импорты, необходимые для этой ячейки\n",
    "import time, pandas as pd, numpy as np, json, random, copy, traceback\n",
    "from pathlib import Path; import torch\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Проверка глобальных зависимостей ---\n",
    "required_globals_loop = [\n",
    "    'train_df', 'test_df', 'EXTRACTED_AUDIO_DIR',\n",
    "    'char_to_index', 'index_to_char', 'BLANK_IDX', 'PAD_IDX', 'NUM_CLASSES_CTC',\n",
    "    'device', 'OUTPUT_DIR',\n",
    "    'BASE_FILENAME_SUFFIX_TEMPLATE_SIMPLE', # <-- Используем шаблон для УПРОЩЕННОЙ модели\n",
    "    'SEED', 'run_training_pipeline',\n",
    "    'AUDIO_CONFIG_MELSPEC',         # Базовый конфиг аудио\n",
    "    'MODEL_CONFIG_SIMPLE',          # <-- Используем конфиг УПРОЩЕННОЙ модели\n",
    "    'TRAIN_CONFIG_MELSPEC',         # Конфиг обучения (с уменьшенными эпохами)\n",
    "    'HOP_LENGTH_CONST',             # Константа hop_length\n",
    "    'mlflow'\n",
    "]\n",
    "missing_globals_loop = [v for v in required_globals_loop if v not in globals() or globals().get(v) is None]\n",
    "if missing_globals_loop: raise NameError(f\"Отсутствуют переменные/функции или они None: {missing_globals_loop}\")\n",
    "\n",
    "# ============================================================================\n",
    "# === БЛОК 1: Определение Параметров для Цикла Экспериментов ===\n",
    "# ============================================================================\n",
    "print(\"\\n1. Определение параметров для цикла экспериментов...\")\n",
    "\n",
    "N_MELS_TO_TEST = [12] # <-- Пробуем [8, 12] и добавим [16, 24, 32] для сравнения\n",
    "print(f\"  Значения n_mels для теста: {N_MELS_TO_TEST}\")\n",
    "print(f\"  Константа hop_length: {HOP_LENGTH_CONST}\")\n",
    "print(f\"  Используется УПРОЩЕННАЯ модель для калибровки.\")\n",
    "\n",
    "# --- 2. Копирование Базовой Конфигурации Обучения ---\n",
    "print(\"\\n2. Копирование конфигурации обучения (с уменьшенными эпохами)...\")\n",
    "fixed_train_config = TRAIN_CONFIG_MELSPEC.copy() # Используем конфиг из Ячейки 2 (уже с уменьшенными эпохами)\n",
    "\n",
    "# --- 3. Инициализация Списка для Результатов ---\n",
    "all_run_results_list: List[Dict] = []\n",
    "\n",
    "# ============================================================================\n",
    "# === БЛОК 2: Цикл запуска обучения по значениям n_mels ===\n",
    "# ============================================================================\n",
    "print(f\"\\n--- Начало цикла запусков ({len(N_MELS_TO_TEST)} итераций) ---\")\n",
    "overall_start_time = time.time()\n",
    "# === Имя эксперимента MLflow ===\n",
    "MLFLOW_EXPERIMENT_NAME = f\"Morse_MelSpec_NMels_Calibration_SimpleModel_Hop{HOP_LENGTH_CONST}\" # <-- ОБНОВЛЕНО\n",
    "# ==============================\n",
    "print(f\"MLflow эксперимент: '{MLFLOW_EXPERIMENT_NAME}'\")\n",
    "\n",
    "# --- Надежное завершение ЛЮБОГО активного MLflow run перед циклом ---\n",
    "print(\"\\n--- Попытка завершить ЛЮБОЙ активный MLflow run перед циклом ---\")\n",
    "try:\n",
    "    if mlflow.active_run(): active_run_id = mlflow.active_run().info.run_id; print(f\"!!! Обнаружен активный MLflow run ({active_run_id}). Принудительно завершаем... !!!\"); mlflow.end_run(); time.sleep(1); print(\"--- Проверка: Активный MLflow run отсутствует.\" if not mlflow.active_run() else \"!!! ПРЕДУПРЕЖДЕНИЕ: MLflow run ВСЕ ЕЩЕ АКТИВЕН! !!!\")\n",
    "    else: print(\"--- Активный MLflow run не обнаружен. ---\")\n",
    "except Exception as e_check_run: print(f\"Предупреждение: Ошибка при проверке/завершении активного MLflow run: {e_check_run}\")\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# --- Основной цикл по значениям n_mels ---\n",
    "for i, n_mels_current in enumerate(N_MELS_TO_TEST):\n",
    "\n",
    "    print(f\"\\n{'='*10} Запуск {i+1}/{len(N_MELS_TO_TEST)}: n_mels = {n_mels_current}, hop_length = {HOP_LENGTH_CONST}, Simple Model {'='*10}\")\n",
    "\n",
    "    # --- Создание специфичных конфигураций для текущего запуска ---\n",
    "    current_audio_config = AUDIO_CONFIG_MELSPEC.copy()\n",
    "    current_audio_config['n_mels'] = n_mels_current\n",
    "    current_audio_config['hop_length'] = HOP_LENGTH_CONST # Убеждаемся еще раз\n",
    "\n",
    "    current_model_config = MODEL_CONFIG_SIMPLE.copy() # <-- Используем УПРОЩЕННУЮ модель\n",
    "    current_model_config['input_feature_dim'] = n_mels_current # Ключевое изменение для модели\n",
    "\n",
    "    print(f\"  Аудио параметры: {json.dumps(current_audio_config)}\")\n",
    "    print(f\"  Параметры модели (Упрощенной): {json.dumps(current_model_config)}\")\n",
    "    print(f\"{'-'*30}\")\n",
    "\n",
    "    # --- Генерация уникального базового суффикса для этого запуска ---\n",
    "    current_base_filename_suffix = BASE_FILENAME_SUFFIX_TEMPLATE_SIMPLE.format(n_mels=n_mels_current) # <-- Используем шаблон SIMPLE\n",
    "    current_run_suffix = f\"_nMels{n_mels_current}_Simple\" # Добавляем \"_Simple\" для ясности\n",
    "\n",
    "    # === Дополнительная попытка завершить run ПЕРЕД start_run ВНУТРИ цикла ===\n",
    "    print(f\"--- Проверка/Завершение MLflow run перед итерацией {i+1}... ---\")\n",
    "    try:\n",
    "        if mlflow.active_run(): lingering_run_id = mlflow.active_run().info.run_id; print(f\"!!! ПРЕДУПРЕЖДЕНИЕ: Обнаружен активный run ({lingering_run_id}) ПЕРЕД start_run в итерации {i+1}. Попытка завершения... !!!\"); mlflow.end_run(); time.sleep(0.5); print(f\"--- Зависший run {lingering_run_id} успешно завершен.\" if not mlflow.active_run() else f\"!!! ОШИБКА: Run {lingering_run_id} все еще активен! !!!\")\n",
    "        else: print(f\"--- Активный run не найден перед итерацией {i+1}. Продолжаем. ---\")\n",
    "    except Exception as e_inner_end: print(f\"Предупреждение: Ошибка при попытке end_run внутри цикла: {e_inner_end}\")\n",
    "    # ======================================================================\n",
    "\n",
    "    # --- Вызов основной функции обучения/инференса ---\n",
    "    try:\n",
    "        print(f\"--- Вызов run_training_pipeline для n_mels={n_mels_current} (Simple Model) ---\")\n",
    "        run_result_dict = run_training_pipeline(\n",
    "            audio_config=current_audio_config,\n",
    "            model_config=current_model_config, # <-- Передаем УПРОЩЕННУЮ модель\n",
    "            train_config=fixed_train_config, # Используем общий конфиг обучения (с уменьшенными эпохами)\n",
    "            full_train_df=train_df, test_df=test_df, audio_dir=EXTRACTED_AUDIO_DIR, base_output_dir=OUTPUT_DIR,\n",
    "            char_to_index=char_to_index, index_to_char=index_to_char, blank_idx=BLANK_IDX, pad_idx=PAD_IDX, num_classes_ctc=NUM_CLASSES_CTC,\n",
    "            device=device,\n",
    "            run_suffix=current_run_suffix, # Суффикс для MLflow\n",
    "            base_filename_suffix=current_base_filename_suffix, # Полный суффикс для файлов\n",
    "            seed=SEED,\n",
    "            mlflow_experiment_name=MLFLOW_EXPERIMENT_NAME\n",
    "        )\n",
    "        print(f\"--- Успешное завершение run_training_pipeline для n_mels={n_mels_current} (Simple Model) ---\")\n",
    "\n",
    "    except Exception as e_pipeline:\n",
    "        print(f\"!!! КРИТИЧЕСКАЯ ОШИБКА ПРИ ВЫЗОВЕ ПАЙПЛАЙНА для n_mels={n_mels_current} (Simple Model) !!!\")\n",
    "        print(f\"Ошибка: {e_pipeline}\"); traceback.print_exc()\n",
    "        run_result_dict = { \"run_suffix\": current_run_suffix, \"status\": \"failed_launch\", \"best_val_lev\": float('inf'),\n",
    "                            \"error\": f\"Pipeline launch error: {e_pipeline}\", \"n_mels\": n_mels_current }\n",
    "\n",
    "    # Добавляем параметры этого запуска в результаты\n",
    "    run_result_dict['n_mels'] = n_mels_current\n",
    "    run_result_dict['hop_length'] = HOP_LENGTH_CONST\n",
    "    run_result_dict['config_name'] = f\"nMels{n_mels_current}_Hop{HOP_LENGTH_CONST}_Simple\" # Имя конфигурации\n",
    "    run_result_dict['trimming_status'] = f\"ON (db={current_audio_config.get('trim_top_db', 'N/A')})\" if current_audio_config.get('apply_trimming', False) else \"OFF\"\n",
    "    all_run_results_list.append(run_result_dict)\n",
    "\n",
    "    print(f\"--- Завершение обработки Запуска {i+1}/{len(N_MELS_TO_TEST)} (n_mels={n_mels_current}, Simple Model) ---\")\n",
    "\n",
    "# --- Конец цикла запусков ---\n",
    "# ============================================================================\n",
    "# === КОНЕЦ БЛОКА 2 ===\n",
    "# ============================================================================\n",
    "\n",
    "overall_end_time = time.time(); total_duration_hours = (overall_end_time - overall_start_time) / 3600\n",
    "print(f\"\\n--- Цикл запусков (УПРОЩЕННАЯ модель) завершен за {total_duration_hours:.2f} часов ---\")\n",
    "\n",
    "# ============================================================================\n",
    "# === БЛОК 3: Анализ и вывод итогов ===\n",
    "# ============================================================================\n",
    "print(f\"\\n--- Итоги Теста n_mels = {N_MELS_TO_TEST} (hop_length={HOP_LENGTH_CONST}, УПРОЩЕННАЯ модель) ---\") # <-- ОБНОВЛЕНО\n",
    "if not all_run_results_list: print(\"Нет результатов для анализа.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(all_run_results_list)\n",
    "    # Определяем колонки для сохранения и отображения\n",
    "    required_cols = ['config_name', 'n_mels', 'hop_length', 'best_val_lev', 'best_epoch', 'final_train_loss', 'final_val_loss',\n",
    "                     'status', 'train_time_min', 'infer_time_sec', 'error', 'run_suffix', 'mlflow_run_id']\n",
    "    available_cols = [col for col in required_cols if col in results_df.columns]\n",
    "    results_df = results_df[available_cols]\n",
    "    # Сортируем по лучшей метрике валидации\n",
    "    if 'best_val_lev' in results_df.columns: results_df = results_df.sort_values(by='best_val_lev', ascending=True, na_position='last')\n",
    "    else: print(\"Предупреждение: Колонка 'best_val_lev' отсутствует, сортировка невозможна.\")\n",
    "\n",
    "    # Настройки отображения Pandas\n",
    "    pd.set_option('display.max_rows', 100); pd.set_option('display.max_columns', 20);\n",
    "    pd.set_option('display.width', 180); pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "    print(\"\\nСводная таблица результатов (УПРОЩЕННАЯ модель):\")\n",
    "    display_cols = ['config_name', 'n_mels', 'best_val_lev', 'best_epoch', 'status', 'train_time_min', 'error']\n",
    "    display_cols_present = [col for col in display_cols if col in results_df.columns]\n",
    "    display(results_df[display_cols_present].head(len(results_df)))\n",
    "\n",
    "    # Вывод лучшего результата\n",
    "    if 'best_val_lev' in results_df.columns and not results_df.empty:\n",
    "        best_run = results_df.iloc[0]\n",
    "        if pd.notna(best_run['best_val_lev']) and np.isfinite(best_run['best_val_lev']):\n",
    "            best_n_mels_simple = best_run.get('n_mels', 'N/A')\n",
    "            print(f\"\\n--- Лучший результат калибровки (УПРОЩЕННАЯ модель) ---\")\n",
    "            print(f\"  n_mels: {best_n_mels_simple}\")\n",
    "            print(f\"  Best Val Levenshtein: {best_run['best_val_lev']:.4f} (Эпоха {best_run.get('best_epoch', 'N/A')})\")\n",
    "            print(f\"\\n>>> РЕКОМЕНДАЦИЯ: Провести финальное обучение ПОЛНОЙ модели с n_mels = {best_n_mels_simple} (и hop_length={HOP_LENGTH_CONST}). <<<\")\n",
    "        else: print(\"\\nНе удалось найти валидный лучший результат в этом цикле калибровки.\")\n",
    "    else: print(\"\\nНе удалось определить лучший результат калибровки.\")\n",
    "\n",
    "    # Сохранение полной таблицы результатов\n",
    "    results_csv_path = OUTPUT_DIR / f\"melspec_nmels_calibration_simplemodel_hop{HOP_LENGTH_CONST}_results.csv\" # <-- ОБНОВЛЕНО\n",
    "    try: results_df.to_csv(results_csv_path, index=False); print(f\"\\nПолные результаты калибровки сохранены в CSV: {results_csv_path}\")\n",
    "    except Exception as e: print(f\"\\nНе удалось сохранить результаты калибровки в CSV: {e}\")\n",
    "# ============================================================================\n",
    "# === КОНЕЦ БЛОКА 3 ===\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n--- Ячейка 13: Завершена (Тест n_mels = {N_MELS_TO_TEST}, hop_length={HOP_LENGTH_CONST}, УПРОЩЕННАЯ модель) ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
