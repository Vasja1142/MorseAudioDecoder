{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 1: Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 1: Импорты и Базовая Настройка ---\n",
      "\n",
      "--- Статус ключевых библиотек ---\n",
      "PyTorch Версия: 2.5.1+cu121\n",
      "LibROSA Версия: 0.11.0\n",
      "NumPy Версия: 2.0.2\n",
      "Pandas Версия: 2.2.3\n",
      "Levenshtein Версия: 0.27.1\n",
      "MLflow доступен: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 1: Импорты и Базовая Настройка\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 1: Импорты и Базовая Настройка ---\")\n",
    "\n",
    "# --- Базовые библиотеки ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# Допускаем дублирование библиотек (например, Intel MKL) - частый workaround\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "import zipfile\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import random\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple, List, Dict, Optional # Обновлены аннотации типов\n",
    "\n",
    "# --- Аудио и Сигналы ---\n",
    "import librosa\n",
    "import librosa.display\n",
    "# import scipy # scipy.signal больше не нужен, т.к. нет фильтра\n",
    "\n",
    "# --- Визуализация и Интерактивность ---\n",
    "try:\n",
    "    # Убрали ipywidgets, т.к. ячейка 11 удалена\n",
    "    from IPython.display import display, Audio, clear_output\n",
    "except ImportError:\n",
    "    print(\"Предупреждение: IPython не найден. Отображение может работать некорректно.\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- PyTorch ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset # Добавлен Subset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# --- Метрики и Утилиты ---\n",
    "import Levenshtein\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools # Для train_epoch с batches_per_epoch\n",
    "\n",
    "# --- Логирование Экспериментов ---\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"Предупреждение: mlflow не найден. Логирование экспериментов будет отключено.\")\n",
    "\n",
    "# --- Настройка окружения и предупреждений ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "print(\"\\n--- Статус ключевых библиотек ---\")\n",
    "print(f\"PyTorch Версия: {torch.__version__}\")\n",
    "print(f\"LibROSA Версия: {librosa.__version__}\")\n",
    "print(f\"NumPy Версия: {np.__version__}\")\n",
    "print(f\"Pandas Версия: {pd.__version__}\")\n",
    "print(f\"Levenshtein Версия: {Levenshtein.__version__}\")\n",
    "print(f\"MLflow доступен: {MLFLOW_AVAILABLE}\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 2: Конфигурация и Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 2: Конфигурация и Параметры (Обновлена Базовая Модель до 3x512) ---\n",
      "Базовая директория: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_dev\\MorseAudioDecoder\n",
      "Ожидаемая директория аудио: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_dev\\MorseAudioDecoder\\morse_dataset\\morse_dataset\n",
      "Директория для вывода: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_dev\\MorseAudioDecoder\\output_final_trim_test\n",
      "\n",
      "Аудио параметры (Готовы к тесту Trimming):\n",
      "{\n",
      "  \"sample_rate\": 8000,\n",
      "  \"frame_length_rms\": 128,\n",
      "  \"hop_length_rms\": 64,\n",
      "  \"apply_filter\": false,\n",
      "  \"apply_trimming\": false,\n",
      "  \"trim_top_db\": 30\n",
      "}\n",
      "\n",
      "Параметры модели (ЛУЧШАЯ НАЙДЕННАЯ - 3x512):\n",
      "{\n",
      "  \"input_feature_dim\": 2,\n",
      "  \"cnn_out_channels\": [\n",
      "    64,\n",
      "    128,\n",
      "    128\n",
      "  ],\n",
      "  \"cnn_kernel_size\": 9,\n",
      "  \"cnn_stride\": 1,\n",
      "  \"cnn_padding\": \"same\",\n",
      "  \"cnn_pool_kernel\": 2,\n",
      "  \"rnn_hidden_size\": 512,\n",
      "  \"rnn_num_layers\": 3,\n",
      "  \"dropout_rate\": 0.2,\n",
      "  \"activation_fn\": \"GELU\",\n",
      "  \"classifier_type\": \"double\"\n",
      "}\n",
      "\n",
      "Параметры обучения (Для теста Trimming - короткие эпохи):\n",
      "{\n",
      "  \"batch_size\": 8,\n",
      "  \"num_workers\": 0,\n",
      "  \"num_epochs\": 10,\n",
      "  \"learning_rate\": 0.0003,\n",
      "  \"div_factor\": 3.0,\n",
      "  \"final_div_factor\": 100,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"optimizer\": \"AdamW\",\n",
      "  \"early_stopping_patience\": 7,\n",
      "  \"gradient_clip_norm\": 2.0,\n",
      "  \"validation_split_ratio\": 0.1,\n",
      "  \"base_seed\": 42,\n",
      "  \"batches_per_epoch\": 1000\n",
      "}\n",
      "\n",
      "Базовый суффикс имени файла (Финал. тест): SR8k_F128h64_FiltOFF_CNN128_RNN3x512_GELU_Clsdouble_LR3e-04_WD1e-04\n",
      "\n",
      "Используемое устройство: cuda\n",
      "  GPU: NVIDIA GeForce GTX 1050 Ti\n",
      "Установлен SEED = 42\n",
      "\n",
      "--- Ячейка 2: Конфигурация для ФИНАЛЬНОГО ТЕСТА Trimming готова ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 2: Конфигурация и Параметры (Обновлена Базовая Модель до 3x512)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 2: Конфигурация и Параметры (Обновлена Базовая Модель до 3x512) ---\")\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# --- Пути ---\n",
    "BASE_DIR = Path('.').resolve()\n",
    "DATA_DIR = BASE_DIR\n",
    "ZIP_PATH = DATA_DIR / 'morse_dataset.zip'\n",
    "AUDIO_DIR_NAME = 'morse_dataset'\n",
    "EXTRACTED_AUDIO_DIR = DATA_DIR / AUDIO_DIR_NAME/ AUDIO_DIR_NAME\n",
    "TRAIN_CSV_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_CSV_PATH = DATA_DIR / 'test.csv'\n",
    "SAMPLE_SUB_PATH = DATA_DIR / 'sample_submission.csv'\n",
    "# Папка для финального теста Trimming\n",
    "OUTPUT_DIR = BASE_DIR / 'output_final_trim_test'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Базовая директория: {BASE_DIR}\")\n",
    "print(f\"Ожидаемая директория аудио: {EXTRACTED_AUDIO_DIR}\")\n",
    "print(f\"Директория для вывода: {OUTPUT_DIR}\")\n",
    "\n",
    "# --- Параметры обработки аудио (Готовы к тесту Trimming) ---\n",
    "AUDIO_CONFIG = {\n",
    "    \"sample_rate\": 8000,\n",
    "    \"frame_length_rms\": 128,\n",
    "    \"hop_length_rms\": 64,\n",
    "    \"apply_filter\": False,\n",
    "    \"apply_trimming\": False, # Будет меняться в Ячейке 13\n",
    "    \"trim_top_db\": 30\n",
    "}\n",
    "print(f\"\\nАудио параметры (Готовы к тесту Trimming):\")\n",
    "print(json.dumps(AUDIO_CONFIG, indent=2))\n",
    "\n",
    "# === ИЗМЕНЕНИЕ ЗДЕСЬ: Устанавливаем ЛУЧШУЮ МОДЕЛЬ (3x512) как базовую ===\n",
    "MODEL_CONFIG_BASE = {\n",
    "    \"input_feature_dim\": 2,\n",
    "    \"cnn_out_channels\": [64, 128, 128],\n",
    "    \"cnn_kernel_size\": 9, \"cnn_stride\": 1, \"cnn_padding\": 'same',\n",
    "    \"cnn_pool_kernel\": 2,\n",
    "    \"rnn_hidden_size\": 512, # <--- ЛУЧШИЙ РЕЗУЛЬТАТ\n",
    "    \"rnn_num_layers\": 3,    # <--- ЛУЧШИЙ РЕЗУЛЬТАТ\n",
    "    \"dropout_rate\": 0.2,    # Оставляем 0.2, т.к. 0.3 было хуже\n",
    "    \"activation_fn\": \"GELU\",\n",
    "    \"classifier_type\": \"double\" # Оставляем single, т.к. double было хуже\n",
    "}\n",
    "print(f\"\\nПараметры модели (ЛУЧШАЯ НАЙДЕННАЯ - 3x512):\")\n",
    "print(json.dumps(MODEL_CONFIG_BASE, indent=2))\n",
    "# ============================================================================\n",
    "\n",
    "# --- Параметры Обучения (Для ФИНАЛЬНОГО СРАВНЕНИЯ - можно оставить короткие эпохи) ---\n",
    "# Оставим короткие эпохи для быстрого сравнения Trimming ON vs OFF\n",
    "TRAIN_CONFIG = {\n",
    "    \"batch_size\": 8, # Оставим 8, т.к. модель стала больше\n",
    "    \"num_workers\": 0,\n",
    "    \"num_epochs\": 10,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"div_factor\": 3.0,\n",
    "    \"final_div_factor\": 100,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"early_stopping_patience\": 7,\n",
    "    \"gradient_clip_norm\": 2.0,\n",
    "    \"validation_split_ratio\": 0.1,\n",
    "    \"base_seed\": SEED,\n",
    "    \"batches_per_epoch\": 1000 # <-- Короткие эпохи для сравнения\n",
    "    # \"batches_per_epoch\": 0 # <-- РАСКОММЕНТИРОВАТЬ ДЛЯ ФИНАЛЬНОГО ОБУЧЕНИЯ\n",
    "}\n",
    "print(f\"\\nПараметры обучения (Для теста Trimming - короткие эпохи):\")\n",
    "print(json.dumps(TRAIN_CONFIG, indent=2))\n",
    "\n",
    "# --- Специальные Токены и Глобальные Переменные ---\n",
    "PAD_TOKEN = '<pad>'; BLANK_TOKEN = '_'\n",
    "PAD_IDX = -1; BLANK_IDX = -1; NUM_CLASSES_CTC = -1\n",
    "char_to_index: Dict[str, int] = {}; index_to_char: Dict[int, str] = {}\n",
    "\n",
    "# --- Формирование Базового Имени Файла для финального теста ---\n",
    "# Описывает лучшую модель (3x512)\n",
    "BASE_FILENAME_SUFFIX_FINAL = (\n",
    "    f\"SR{AUDIO_CONFIG['sample_rate'] // 1000}k_\"\n",
    "    f\"F{AUDIO_CONFIG['frame_length_rms']}h{AUDIO_CONFIG['hop_length_rms']}_FiltOFF_\"\n",
    "    f\"CNN{MODEL_CONFIG_BASE['cnn_out_channels'][-1]}_\"\n",
    "    f\"RNN{MODEL_CONFIG_BASE['rnn_num_layers']}x{MODEL_CONFIG_BASE['rnn_hidden_size']}_\" # Лучшая 3x512\n",
    "    f\"{MODEL_CONFIG_BASE['activation_fn']}_Cls{MODEL_CONFIG_BASE['classifier_type']}_\"\n",
    "    f\"LR{TRAIN_CONFIG['learning_rate']:.0e}_WD{TRAIN_CONFIG['weight_decay']:.0e}\"\n",
    ")\n",
    "print(f\"\\nБазовый суффикс имени файла (Финал. тест): {BASE_FILENAME_SUFFIX_FINAL}\")\n",
    "\n",
    "# --- Выбор устройства ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nИспользуемое устройство: {device}\")\n",
    "if device.type == 'cuda': print(f\"  GPU: {torch.cuda.get_device_name(0)}\"); torch.cuda.empty_cache()\n",
    "\n",
    "# --- Установка SEED ---\n",
    "def set_seed(seed_value: int):\n",
    "    random.seed(seed_value); np.random.seed(seed_value); torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed_value)\n",
    "    print(f\"Установлен SEED = {seed_value}\")\n",
    "set_seed(TRAIN_CONFIG['base_seed'])\n",
    "\n",
    "print(\"\\n--- Ячейка 2: Конфигурация для ФИНАЛЬНОГО ТЕСТА Trimming готова ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 3: Загрузка данных и распаковка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 3: Загрузка метаданных и распаковка аудио ---\n",
      "Папка с аудио (C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_dev\\MorseAudioDecoder\\morse_dataset\\morse_dataset) уже существует. Распаковка пропускается.\n",
      "\n",
      "Загрузка CSV файлов...\n",
      "  Train DataFrame загружен: 30000 записей, Колонки: ['id', 'message']\n",
      "  Test DataFrame загружен: 5000 записей, Колонки: ['id']\n",
      "  Предупреждение: Файл Sample Submission (C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_dev\\MorseAudioDecoder\\sample_submission.csv) не найден.\n",
      "\n",
      "Проверка данных...\n",
      "\n",
      "Выборочная проверка наличия аудиофайлов...\n",
      "  Проверено 5 файлов - все найдены (например, C:\\Users\\vasja\\OneDrive\\Рабочий стол\\Morse_dev\\MorseAudioDecoder\\morse_dataset\\morse_dataset\\2309.opus).\n",
      "\n",
      "--- Ячейка 3: Загрузка данных завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 3: Загрузка Метаданных и Распаковка Аудио\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 3: Загрузка метаданных и распаковка аудио ---\")\n",
    "\n",
    "# --- Проверка и Распаковка Архива ---\n",
    "if not EXTRACTED_AUDIO_DIR.exists():\n",
    "    print(f\"Папка для аудио ({EXTRACTED_AUDIO_DIR}) не найдена.\")\n",
    "    if ZIP_PATH.is_file():\n",
    "        print(f\"Найден архив: {ZIP_PATH}. Распаковка...\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref: zip_ref.extractall(DATA_DIR)\n",
    "            print(f\"Архив распакован в: {DATA_DIR}\")\n",
    "            if not EXTRACTED_AUDIO_DIR.is_dir(): raise FileNotFoundError(f\"Не удалось найти папку '{EXTRACTED_AUDIO_DIR.name}' после распаковки в {DATA_DIR}.\")\n",
    "            else: print(f\"Папка с аудио найдена: {EXTRACTED_AUDIO_DIR}\")\n",
    "        except Exception as e: print(f\"Критическая ошибка при распаковке: {e}\"); traceback.print_exc(); raise SystemExit(\"Остановка.\")\n",
    "    else: print(f\"Критическая ошибка: Архив {ZIP_PATH} не найден.\"); raise SystemExit(\"Остановка.\")\n",
    "else: print(f\"Папка с аудио ({EXTRACTED_AUDIO_DIR}) уже существует. Распаковка пропускается.\")\n",
    "\n",
    "# --- Загрузка CSV файлов метаданных ---\n",
    "print(\"\\nЗагрузка CSV файлов...\")\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    print(f\"  Train DataFrame загружен: {len(train_df)} записей, Колонки: {train_df.columns.tolist()}\")\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "    print(f\"  Test DataFrame загружен: {len(test_df)} записей, Колонки: {test_df.columns.tolist()}\")\n",
    "    try: sample_sub_df = pd.read_csv(SAMPLE_SUB_PATH); print(f\"  Sample Submission загружен: {len(sample_sub_df)} записей.\")\n",
    "    except FileNotFoundError: print(f\"  Предупреждение: Файл Sample Submission ({SAMPLE_SUB_PATH}) не найден.\"); sample_sub_df = None\n",
    "except FileNotFoundError as e: print(f\"Критическая ошибка: Не найден CSV файл: {e}.\"); raise SystemExit(\"Остановка.\")\n",
    "except Exception as e: print(f\"Критическая ошибка при чтении CSV: {e}\"); traceback.print_exc(); raise SystemExit(\"Остановка.\")\n",
    "\n",
    "# --- Проверка наличия файлов и колонок ---\n",
    "print(\"\\nПроверка данных...\")\n",
    "if 'id' not in train_df.columns or 'message' not in train_df.columns: raise ValueError(\"В train_df нет 'id' или 'message'.\")\n",
    "if 'id' not in test_df.columns: raise ValueError(\"В test_df нет 'id'.\")\n",
    "\n",
    "# --- Выборочная проверка существования аудиофайлов ---\n",
    "print(\"\\nВыборочная проверка наличия аудиофайлов...\")\n",
    "if EXTRACTED_AUDIO_DIR.is_dir():\n",
    "    num_check = 5; example_ids = train_df['id'].sample(min(num_check, len(train_df)), random_state=SEED).tolist(); missing_files = []\n",
    "    for file_id in example_ids:\n",
    "        if not (EXTRACTED_AUDIO_DIR / file_id).is_file(): missing_files.append(file_id)\n",
    "    if not missing_files: print(f\"  Проверено {len(example_ids)} файлов - все найдены (например, {EXTRACTED_AUDIO_DIR / example_ids[0]}).\")\n",
    "    else: print(f\"  !!! ПРЕДУПРЕЖДЕНИЕ: Не найдены файлы для ID: {missing_files} !!!\")\n",
    "else: print(f\"  Проверка невозможна: Папка {EXTRACTED_AUDIO_DIR} не существует.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 3: Загрузка данных завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 4: Создание словаря символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 4: Создание словаря символов ---\n",
      "Найдено уникальных символов: 44\n",
      "Размер словаря (включая BLANK и PAD): 46\n",
      "Индекс BLANK ('_'): 44, Индекс PAD ('<pad>'): 45\n",
      "Количество классов для CTC Loss: 45\n",
      "\n",
      "--- Ячейка 4: Создание словаря завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 4: Создание Словаря Символов\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 4: Создание словаря символов ---\")\n",
    "\n",
    "if 'train_df' not in globals() or train_df is None: raise SystemExit(\"Остановка: train_df не найден.\")\n",
    "if 'message' not in train_df.columns: raise SystemExit(\"Остановка: В train_df нет 'message'.\")\n",
    "\n",
    "try:\n",
    "    all_texts = train_df['message'].fillna('').astype(str)\n",
    "    unique_chars = sorted(list(set(char for text in all_texts for char in text)))\n",
    "    char_to_index = {char: i for i, char in enumerate(unique_chars)}\n",
    "    index_to_char = {i: char for char, i in char_to_index.items()}\n",
    "    BLANK_IDX = len(char_to_index)\n",
    "    PAD_IDX = len(char_to_index) + 1\n",
    "    char_to_index[BLANK_TOKEN] = BLANK_IDX; char_to_index[PAD_TOKEN] = PAD_IDX\n",
    "    index_to_char[BLANK_IDX] = BLANK_TOKEN; index_to_char[PAD_IDX] = PAD_TOKEN\n",
    "    NUM_CLASSES_CTC = BLANK_IDX + 1\n",
    "    print(f\"Найдено уникальных символов: {len(unique_chars)}\")\n",
    "    print(f\"Размер словаря (включая BLANK и PAD): {len(char_to_index)}\")\n",
    "    print(f\"Индекс BLANK ('{BLANK_TOKEN}'): {BLANK_IDX}, Индекс PAD ('{PAD_TOKEN}'): {PAD_IDX}\")\n",
    "    print(f\"Количество классов для CTC Loss: {NUM_CLASSES_CTC}\")\n",
    "except Exception as e: print(f\"Критическая ошибка при создании словаря: {e}\"); traceback.print_exc(); raise SystemExit(\"Остановка.\")\n",
    "if not char_to_index or not index_to_char or BLANK_IDX == -1 or PAD_IDX == -1 or NUM_CLASSES_CTC <= 0: raise SystemExit(\"Остановка: Ошибка инициализации словаря.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 4: Создание словаря завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 5: Класс MorseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 5: Определение класса MorseDataset (Добавлена Обрезка Тишины) ---\n",
      "\n",
      "--- Ячейка 5: Определение MorseDataset (Добавлена Обрезка Тишины) завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 5: Класс MorseDataset (Добавлена Обрезка Тишины)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 5: Определение класса MorseDataset (Добавлена Обрезка Тишины) ---\")\n",
    "\n",
    "if 'BLANK_IDX' not in globals() or 'PAD_IDX' not in globals(): raise ValueError(\"Индексы BLANK/PAD не инициализированы.\")\n",
    "if 'AUDIO_CONFIG' not in globals(): raise ValueError(\"AUDIO_CONFIG не определен.\")\n",
    "if 'MODEL_CONFIG_BASE' not in globals(): raise ValueError(\"MODEL_CONFIG_BASE не определен.\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "from typing import Union, Tuple, Optional, Dict, List\n",
    "\n",
    "class MorseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет для Морзе.\n",
    "    Выполняет: Загрузка -> Ресэмплинг -> [Опционально Trimming] -> RMS -> Delta -> Z-Score Нормализация.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dataframe: pd.DataFrame,\n",
    "                 audio_dir: Path,\n",
    "                 char_to_index: Dict[str, int],\n",
    "                 audio_config: Dict,\n",
    "                 model_input_feature_dim: int,\n",
    "                 is_train: bool = True):\n",
    "        super().__init__()\n",
    "        if not isinstance(dataframe, pd.DataFrame): raise TypeError(\"dataframe должен быть pandas DataFrame\")\n",
    "        if not isinstance(audio_dir, Path): raise TypeError(\"audio_dir должен быть pathlib.Path\")\n",
    "        if not isinstance(char_to_index, dict): raise TypeError(\"char_to_index должен быть словарем\")\n",
    "        if not isinstance(audio_config, dict): raise TypeError(\"audio_config должен быть словарем\")\n",
    "\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.char_to_index = char_to_index\n",
    "        self.is_train = is_train\n",
    "        self.audio_config = audio_config\n",
    "        self.expected_feature_dim = model_input_feature_dim\n",
    "\n",
    "        # --- Извлечение параметров из audio_config ---\n",
    "        try:\n",
    "            self.sample_rate = int(self.audio_config['sample_rate'])\n",
    "            self.frame_length_rms = int(self.audio_config['frame_length_rms'])\n",
    "            self.hop_length_rms = int(self.audio_config['hop_length_rms'])\n",
    "            # === НОВЫЕ ПАРАМЕТРЫ ===\n",
    "            self.apply_trimming = bool(self.audio_config.get('apply_trimming', False))\n",
    "            self.trim_top_db = float(self.audio_config.get('trim_top_db', 30))\n",
    "            # =======================\n",
    "        except KeyError as e: raise ValueError(f\"Отсутствует ключ в audio_config: {e}\")\n",
    "        except (TypeError, ValueError) as e: raise ValueError(f\"Ошибка типа/значения в audio_config: {e}\")\n",
    "\n",
    "        # --- Валидация параметров ---\n",
    "        if self.sample_rate <= 0: raise ValueError(\"sample_rate > 0\")\n",
    "        if self.frame_length_rms <= 0: raise ValueError(\"frame_length_rms > 0\")\n",
    "        if self.hop_length_rms <= 0: raise ValueError(\"hop_length_rms > 0\")\n",
    "        if self.apply_trimming and self.trim_top_db <= 0: raise ValueError(\"trim_top_db должен быть > 0, если apply_trimming=True\")\n",
    "\n",
    "        # --- Информационное сообщение ---\n",
    "        trim_status = f\"Trimming ON (top_db={self.trim_top_db})\" if self.apply_trimming else \"Trimming OFF\"\n",
    "        print(f\"MorseDataset: is_train={self.is_train}, SR={self.sample_rate}Hz, {trim_status}\")\n",
    "        print(f\"  Признаки: RMS(f={self.frame_length_rms}, h={self.hop_length_rms}) + Delta(standard)\")\n",
    "        print(f\"  Нормализация: Z-Score\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def _normalize_feature(self, feature_array: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Стандартная Z-score нормализация. \"\"\"\n",
    "        if not isinstance(feature_array, np.ndarray) or feature_array.size == 0: return np.array([], dtype=np.float32)\n",
    "        epsilon = 1e-8; mean = np.mean(feature_array); std = np.std(feature_array)\n",
    "        if std < epsilon: return np.zeros_like(feature_array, dtype=np.float32)\n",
    "        return ((feature_array - mean) / (std + epsilon)).astype(np.float32)\n",
    "\n",
    "    def _calculate_features(self, waveform_np: np.ndarray, file_id_for_log: str = \"N/A\") -> Optional[torch.Tensor]:\n",
    "        \"\"\" Вычисляет признаки: RMS -> Delta -> Z-Score -> Стек. \"\"\"\n",
    "        empty_tensor = torch.empty((self.expected_feature_dim, 0), dtype=torch.float32)\n",
    "        if not isinstance(waveform_np, np.ndarray) or waveform_np.size == 0: return empty_tensor\n",
    "        try:\n",
    "            processed_waveform = waveform_np.astype(np.float32)\n",
    "\n",
    "            # 1. Расчет RMS\n",
    "            rms_envelope_raw = librosa.feature.rms(y=processed_waveform, frame_length=self.frame_length_rms, hop_length=self.hop_length_rms, center=True, pad_mode='reflect')[0]\n",
    "            if rms_envelope_raw.size < 2: return empty_tensor\n",
    "\n",
    "            # 2. Расчет Дельты\n",
    "            delta_raw = np.diff(rms_envelope_raw, n=1, prepend=rms_envelope_raw[0])\n",
    "\n",
    "            # 3. Нормализация Z-Score\n",
    "            norm_rms = self._normalize_feature(rms_envelope_raw)\n",
    "            norm_delta = self._normalize_feature(delta_raw)\n",
    "\n",
    "            # 4. Сборка тензора\n",
    "            if norm_rms.size == 0 or norm_delta.size == 0 or norm_rms.shape != norm_delta.shape:\n",
    "                 print(f\"WARNING ({file_id_for_log}): Проблема с формой/содержимым признаков после нормализации. RMS:{norm_rms.shape}, Delta:{norm_delta.shape}\")\n",
    "                 return empty_tensor\n",
    "            features_np = np.vstack([norm_rms, norm_delta]).astype(np.float32)\n",
    "            features_tensor = torch.from_numpy(features_np)\n",
    "            if not torch.isfinite(features_tensor).all(): print(f\"ERROR ({file_id_for_log}): NaN/Inf в финальном тензоре! Пропуск.\"); return None\n",
    "            return features_tensor\n",
    "        except Exception as e: print(f\"CRITICAL ERROR в _calculate_features ({file_id_for_log}): {e}\"); traceback.print_exc(limit=1); return None\n",
    "\n",
    "    def __getitem__(self, index: int) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor, str], Tuple[None, Optional[str]]]:\n",
    "        \"\"\" Загрузка, обработка и возврат примера. \"\"\"\n",
    "        if not (0 <= index < len(self.dataframe)): return None, (f\"InvalidIndex_{index}\" if not self.is_train else None)\n",
    "        try: row = self.dataframe.iloc[index]; file_id = row['id']; audio_path = self.audio_dir / file_id\n",
    "        except Exception as e: print(f\"Error get item data index {index}: {e}\"); return None, (f\"DataAccessError_{index}\" if not self.is_train else None)\n",
    "\n",
    "        # 1. Загрузка и Ресэмплинг\n",
    "        waveform_np: Optional[np.ndarray] = None\n",
    "        original_len = 0\n",
    "        try:\n",
    "            waveform_np, _ = librosa.load(audio_path, sr=self.sample_rate, mono=True)\n",
    "            if waveform_np is None or waveform_np.size == 0: print(f\"Warning ({file_id}): Файл пуст.\"); return None, (file_id if not self.is_train else None)\n",
    "            original_len = len(waveform_np)\n",
    "        except FileNotFoundError: print(f\"ERROR ({file_id}): Файл не найден {audio_path}\"); return None, (file_id if not self.is_train else None)\n",
    "        except Exception as e: print(f\"ERROR ({file_id}): Ошибка загрузки librosa: {e}\"); traceback.print_exc(limit=1); return None, (file_id if not self.is_train else None)\n",
    "\n",
    "        # === НОВЫЙ ШАГ: Обрезка тишины (Trimming) ===\n",
    "        trimmed_len = original_len\n",
    "        if self.apply_trimming:\n",
    "            try:\n",
    "                waveform_trimmed, _ = librosa.effects.trim(waveform_np, top_db=self.trim_top_db, frame_length=512, hop_length=128) # Параметры trim можно тоже тюнить\n",
    "                if waveform_trimmed is not None and waveform_trimmed.size > 0:\n",
    "                    waveform_np = waveform_trimmed\n",
    "                    trimmed_len = len(waveform_np)\n",
    "                # else: # Оставляем исходный, если trim вернул пустоту\n",
    "                #     print(f\"Warning ({file_id}): Trimming удалил весь сигнал, используется исходный.\")\n",
    "            except Exception as e_trim:\n",
    "                print(f\"ERROR ({file_id}): Ошибка librosa.effects.trim: {e_trim}. Используется исходный сигнал.\")\n",
    "        # ============================================\n",
    "\n",
    "        # 2. Вычисление признаков (RMS -> Delta -> Z-Score)\n",
    "        features: Optional[torch.Tensor] = self._calculate_features(waveform_np, file_id)\n",
    "        if features is None or features.shape[1] == 0:\n",
    "            # print(f\"Debug ({file_id}): Features None/Empty. Orig len={original_len}, Trimmed len={trimmed_len}\")\n",
    "            return None, (file_id if not self.is_train else None)\n",
    "\n",
    "        # 3. Подготовка цели или возврат ID\n",
    "        if self.is_train:\n",
    "            message_text = str(row.get('message', ''))\n",
    "            target_indices = [self.char_to_index.get(c) for c in message_text if c in self.char_to_index]\n",
    "            if not target_indices: return None, None\n",
    "            target_tensor = torch.tensor(target_indices, dtype=torch.long)\n",
    "            return features, target_tensor\n",
    "        else: return features, file_id\n",
    "\n",
    "print(\"\\n--- Ячейка 5: Определение MorseDataset (Добавлена Обрезка Тишины) завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 6: Функция collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 6: Определение функции collate_fn ---\n",
      "Функция collate_fn определена.\n",
      "\n",
      "--- Ячейка 6: Определение collate_fn завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 6: Функция collate_fn (Сборка Батчей)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 6: Определение функции collate_fn ---\")\n",
    "\n",
    "if 'PAD_IDX' not in globals(): raise ValueError(\"PAD_IDX не инициализирован!\")\n",
    "if 'torch' not in globals(): import torch\n",
    "if 'pad_sequence' not in globals(): from torch.nn.utils.rnn import pad_sequence\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "def collate_fn(batch: List[Tuple[Optional[torch.Tensor], Optional[Union[torch.Tensor, str]]]]) \\\n",
    "    -> Optional[Tuple[torch.Tensor, Union[torch.Tensor, List[str]], torch.Tensor, Optional[torch.Tensor]]]:\n",
    "    \"\"\" Собирает батч, фильтрует некорректные, выполняет паддинг. \"\"\"\n",
    "    valid_batch = [item for item in batch if item[0] is not None and item[1] is not None and item[0].shape[1] > 0]\n",
    "    if not valid_batch: return None\n",
    "\n",
    "    is_train_or_val_batch = isinstance(valid_batch[0][1], torch.Tensor)\n",
    "    features_list = [item[0].permute(1, 0) for item in valid_batch] # (T, F)\n",
    "    targets_or_ids_list = [item[1] for item in valid_batch]\n",
    "\n",
    "    features_padded_time_first = pad_sequence(features_list, batch_first=True, padding_value=0.0)\n",
    "    features_padded = features_padded_time_first.permute(0, 2, 1) # (B, F, T_max)\n",
    "    feature_lengths = torch.tensor([f.shape[0] for f in features_list], dtype=torch.long)\n",
    "\n",
    "    if is_train_or_val_batch:\n",
    "        targets_list: List[torch.Tensor] = targets_or_ids_list\n",
    "        targets_padded: torch.Tensor = pad_sequence(targets_list, batch_first=True, padding_value=PAD_IDX)\n",
    "        target_lengths: torch.Tensor = torch.tensor([len(t) for t in targets_list], dtype=torch.long)\n",
    "        return features_padded, targets_padded, feature_lengths, target_lengths\n",
    "    else:\n",
    "        file_ids: List[str] = targets_or_ids_list\n",
    "        return features_padded, file_ids, feature_lengths, None\n",
    "\n",
    "print(\"Функция collate_fn определена.\")\n",
    "print(\"\\n--- Ячейка 6: Определение collate_fn завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 7: Модель MorseRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 7: Определение модели MorseRecognizer (Обновлена) ---\n",
      "\n",
      "Создание экземпляра БАЗОВОЙ модели для проверки...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Архитектура MorseRecognizer:\n",
      "  CNN: 3 layers, OutChannels=[64, 128, 128], Kernel=9, Pool=2\n",
      "       Output Dim=128, Time Reduction Factor=8.0x\n",
      "  RNN: BiGRU, Layers=3, Hidden Size=512\n",
      "       Output Dim=1024\n",
      "  Activation: GELU\n",
      "  Classifier: DoubleLinear(1024->1024->45)\n",
      "  Dropout: 0.2\n",
      "Модель 'MorseRecognizer' (базовая) создана (12,740,717 параметров) на cuda.\n",
      "\n",
      "Проверка forward pass базовой модели...\n",
      "  Вход: torch.Size([4, 2, 1000]), Выход: torch.Size([125, 4, 45])\n",
      "  Размерности выхода (T, B, C) корректны.\n",
      "\n",
      "--- Ячейка 7: Определение и проверка модели завершены (finally исправлен) ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 7: Модель MorseRecognizer (Исправлен finally)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 7: Определение модели MorseRecognizer (Обновлена) ---\")\n",
    "\n",
    "if 'MODEL_CONFIG_BASE' not in globals(): raise ValueError(\"MODEL_CONFIG_BASE не определен!\")\n",
    "if 'NUM_CLASSES_CTC' not in globals() or NUM_CLASSES_CTC <= 0: raise ValueError(\"NUM_CLASSES_CTC не корректен!\")\n",
    "if 'torch' not in globals(): import torch\n",
    "if 'nn' not in globals(): import torch.nn as nn\n",
    "from typing import Union, Tuple, List, Dict, Optional # Добавим импорт типов сюда на всякий случай\n",
    "\n",
    "class MorseRecognizer(nn.Module):\n",
    "    \"\"\" Модель для распознавания Морзе (CNN + BiGRU). Обновлена для поддержки разного типа классификатора. \"\"\"\n",
    "    def __init__(self, num_classes_ctc: int, input_feature_dim: int,\n",
    "                 cnn_out_channels: List[int], cnn_kernel_size: int, cnn_stride: int,\n",
    "                 cnn_padding: Union[int, str], cnn_pool_kernel: int,\n",
    "                 rnn_hidden_size: int, rnn_num_layers: int, dropout_rate: float,\n",
    "                 activation_fn: str = \"GELU\", classifier_type: str = \"single\"): # Добавлен classifier_type\n",
    "        super().__init__()\n",
    "        self.input_feature_dim = input_feature_dim\n",
    "        self._time_reduction_factor = 1.0\n",
    "        cnn_layers = []; in_channels = input_feature_dim\n",
    "        try: ActivationLayer = getattr(nn, activation_fn)\n",
    "        except AttributeError: print(f\"Warning: Activation '{activation_fn}' не найдена. Используется GELU.\"); ActivationLayer = nn.GELU\n",
    "\n",
    "        # CNN Extractor\n",
    "        for i, out_channels in enumerate(cnn_out_channels):\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, cnn_kernel_size, cnn_stride, padding=cnn_padding),\n",
    "                nn.BatchNorm1d(out_channels), ActivationLayer(),\n",
    "                nn.MaxPool1d(cnn_pool_kernel), nn.Dropout(dropout_rate) )\n",
    "            cnn_layers.append(layer); in_channels = out_channels\n",
    "            self._time_reduction_factor *= cnn_pool_kernel\n",
    "        self.cnn_extractor = nn.Sequential(*cnn_layers)\n",
    "        self.cnn_output_dim = in_channels\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.GRU( self.cnn_output_dim, rnn_hidden_size, rnn_num_layers,\n",
    "                           batch_first=True, bidirectional=True, dropout=dropout_rate if rnn_num_layers > 1 else 0.0 )\n",
    "        rnn_output_dim = rnn_hidden_size * 2\n",
    "\n",
    "        # Classifier (Single or Double Linear)\n",
    "        self.classifier_type = classifier_type\n",
    "        if self.classifier_type == \"double\":\n",
    "            intermediate_dim = rnn_output_dim\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(rnn_output_dim, intermediate_dim),\n",
    "                ActivationLayer(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(intermediate_dim, num_classes_ctc)\n",
    "            )\n",
    "            classifier_str = f\"DoubleLinear({rnn_output_dim}->{intermediate_dim}->{num_classes_ctc})\"\n",
    "        elif self.classifier_type == \"single\":\n",
    "            self.classifier = nn.Linear(rnn_output_dim, num_classes_ctc)\n",
    "            classifier_str = f\"SingleLinear({rnn_output_dim}->{num_classes_ctc})\"\n",
    "        else:\n",
    "            raise ValueError(f\"Неизвестный classifier_type: {self.classifier_type}. Допустимы 'single', 'double'.\")\n",
    "\n",
    "        print(f\"Архитектура MorseRecognizer:\")\n",
    "        print(f\"  CNN: {len(cnn_out_channels)} layers, OutChannels={cnn_out_channels}, Kernel={cnn_kernel_size}, Pool={cnn_pool_kernel}\")\n",
    "        print(f\"       Output Dim={self.cnn_output_dim}, Time Reduction Factor={self._time_reduction_factor:.1f}x\")\n",
    "        print(f\"  RNN: BiGRU, Layers={rnn_num_layers}, Hidden Size={rnn_hidden_size}\")\n",
    "        print(f\"       Output Dim={rnn_output_dim}\")\n",
    "        print(f\"  Activation: {activation_fn}\")\n",
    "        print(f\"  Classifier: {classifier_str}\")\n",
    "        print(f\"  Dropout: {dropout_rate}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Input: (B, F, T_in) -> CNN -> (B, C, T_red) -> Permute -> (B, T_red, C) -> RNN -> (B, T_red, H*2) -> Classifier -> (B, T_red, N_classes) -> Permute -> Output: (T_red, B, N_classes) \"\"\"\n",
    "        if x.shape[1] != self.input_feature_dim: raise ValueError(f\"Input feature dim mismatch! Expected {self.input_feature_dim}, got {x.shape[1]}. Shape: {x.shape}\")\n",
    "        x = self.cnn_extractor(x)   # (B, C_cnn, T_reduced)\n",
    "        x = x.permute(0, 2, 1)      # (B, T_reduced, C_cnn)\n",
    "        x_rnn, _ = self.rnn(x)      # (B, T_reduced, Hidden*2)\n",
    "        logits = self.classifier(x_rnn) # (B, T_reduced, NumClasses)\n",
    "        logits = logits.permute(1, 0, 2) # (T_reduced, B, NumClasses) - для CTC\n",
    "        return logits\n",
    "\n",
    "    def get_time_reduction_factor(self) -> float: return self._time_reduction_factor\n",
    "\n",
    "# --- Создание и Проверка Экземпляра БАЗОВОЙ Модели ---\n",
    "model_created_successfully = False\n",
    "model = None # Объявляем переменные до try\n",
    "dummy_input = None\n",
    "dummy_output = None\n",
    "try:\n",
    "    print(\"\\nСоздание экземпляра БАЗОВОЙ модели для проверки...\")\n",
    "    model = MorseRecognizer(\n",
    "        num_classes_ctc=NUM_CLASSES_CTC,\n",
    "        **MODEL_CONFIG_BASE # Используем базовый конфиг для проверки\n",
    "    ).to(device)\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Модель '{type(model).__name__}' (базовая) создана ({total_params:,} параметров) на {device}.\")\n",
    "\n",
    "    print(\"\\nПроверка forward pass базовой модели...\"); model.eval()\n",
    "    dummy_batch_size = 4; dummy_time_steps = 1000\n",
    "    dummy_input = torch.randn(dummy_batch_size, MODEL_CONFIG_BASE['input_feature_dim'], dummy_time_steps).to(device)\n",
    "    with torch.no_grad(): dummy_output = model(dummy_input)\n",
    "    print(f\"  Вход: {dummy_input.shape}, Выход: {dummy_output.shape}\")\n",
    "    expected_time_dim = int(dummy_time_steps / model.get_time_reduction_factor())\n",
    "    if abs(dummy_output.shape[0] - expected_time_dim) > 2: print(f\"  ПРЕДУПРЕЖДЕНИЕ: Неожиданная длина выхода! Ожидалось ~{expected_time_dim}, получено {dummy_output.shape[0]}.\")\n",
    "    assert dummy_output.shape[1] == dummy_batch_size, \"Batch size mismatch!\"\n",
    "    assert dummy_output.shape[2] == NUM_CLASSES_CTC, \"Num classes mismatch!\"\n",
    "    print(\"  Размерности выхода (T, B, C) корректны.\"); model_created_successfully = True\n",
    "except Exception as e: print(f\"\\n!!! КРИТИЧЕСКАЯ ОШИБКА при создании/проверке модели: {e} !!!\"); traceback.print_exc()\n",
    "finally:\n",
    "    # === ИСПРАВЛЕНИЕ ЗДЕСЬ ===\n",
    "    # Каждая команда на новой строке с отступом\n",
    "    if model is not None: del model\n",
    "    if dummy_input is not None: del dummy_input\n",
    "    if dummy_output is not None: del dummy_output\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache() # Очищаем память после проверки\n",
    "    # ========================\n",
    "\n",
    "if not model_created_successfully: raise SystemExit(\"Остановка: Не удалось создать/проверить модель.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 7: Определение и проверка модели завершены (finally исправлен) ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 8: Loss, Optimizer, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 8: Настройка Loss, Optimizer, Scheduler ---\n",
      "Функция потерь: CTCLoss (blank=44, reduction='mean', zero_infinity=True)\n",
      "\n",
      "Оптимизатор: ADAMW (LR=3.0e-04, WD=1.0e-04) - будет создан в пайплайне\n",
      "\n",
      "Планировщик: OneCycleLR (div=3.0, final_div=100) - будет создан в пайплайне\n",
      "\n",
      "--- Ячейка 8: Настройка Loss, Optimizer, Scheduler завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"--- Ячейка 8: Настройка Loss, Optimizer, Scheduler ---\")\n",
    "\n",
    "if 'BLANK_IDX' not in globals(): raise ValueError(\"BLANK_IDX не инициализирован!\")\n",
    "if 'TRAIN_CONFIG' not in globals(): raise ValueError(\"TRAIN_CONFIG не определен!\")\n",
    "if 'optim' not in globals(): import torch.optim as optim\n",
    "if 'nn' not in globals(): import torch.nn as nn\n",
    "if 'OneCycleLR' not in globals(): from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "criterion = nn.CTCLoss(blank=BLANK_IDX, reduction='mean', zero_infinity=True)\n",
    "print(f\"Функция потерь: CTCLoss (blank={BLANK_IDX}, reduction='mean', zero_infinity=True)\")\n",
    "\n",
    "optimizer_name = TRAIN_CONFIG.get('optimizer', 'AdamW').lower()\n",
    "lr = TRAIN_CONFIG['learning_rate']; wd = TRAIN_CONFIG['weight_decay']\n",
    "print(f\"\\nОптимизатор: {optimizer_name.upper()} (LR={lr:.1e}, WD={wd:.1e}) - будет создан в пайплайне\")\n",
    "\n",
    "div_f = TRAIN_CONFIG.get('div_factor', 25.0); final_div_f = TRAIN_CONFIG.get('final_div_factor', 1e4)\n",
    "print(f\"\\nПланировщик: OneCycleLR (div={div_f}, final_div={final_div_f}) - будет создан в пайплайне\")\n",
    "print(\"\\n--- Ячейка 8: Настройка Loss, Optimizer, Scheduler завершена ---\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 9: Функции Декодирования и Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 9: Определение функций декодирования и метрики ---\n",
      "Функции ctc_greedy_decode и calculate_levenshtein определены.\n",
      "\n",
      "--- Ячейка 9: Определение функций декодирования и метрики завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Ячейка 9: Функции Декодирования (Greedy) и Метрики (Levenshtein)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 9: Определение функций декодирования и метрики ---\")\n",
    "\n",
    "if 'index_to_char' not in globals(): raise ValueError(\"index_to_char не определен!\")\n",
    "if 'BLANK_IDX' not in globals(): raise ValueError(\"BLANK_IDX не определен!\")\n",
    "if 'PAD_IDX' not in globals(): raise ValueError(\"PAD_IDX не определен!\")\n",
    "if 'torch' not in globals(): import torch\n",
    "if 'Levenshtein' not in globals(): import Levenshtein\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# --- Greedy CTC Decoding ---\n",
    "def ctc_greedy_decode(logits: torch.Tensor, index_to_char_map: Dict[int, str], blank_idx: int) -> List[str]:\n",
    "    \"\"\" Жадное CTC декодирование батча логитов (Time, Batch, Classes). \"\"\"\n",
    "    decoded_batch = []\n",
    "    best_path = torch.argmax(logits, dim=2) # (Time, Batch)\n",
    "    best_path_np = best_path.cpu().numpy()\n",
    "    for i in range(best_path_np.shape[1]):\n",
    "        sequence_indices = best_path_np[:, i]\n",
    "        collapsed_indices = [idx for j, idx in enumerate(sequence_indices) if j == 0 or idx != sequence_indices[j-1]]\n",
    "        final_indices = [idx for idx in collapsed_indices if idx != blank_idx]\n",
    "        decoded_string = \"\".join([index_to_char_map.get(idx, '?') for idx in final_indices])\n",
    "        decoded_batch.append(decoded_string)\n",
    "    return decoded_batch\n",
    "\n",
    "# --- Levenshtein Distance ---\n",
    "def calculate_levenshtein(predictions: List[str], targets_padded: torch.Tensor, target_lengths: torch.Tensor,\n",
    "                          index_to_char_map: Dict[int, str], pad_idx: int) -> Tuple[float, List[Tuple[str, str]]]:\n",
    "    \"\"\" Вычисляет средний Levenshtein и возвращает пары (предсказание, реальность). \"\"\"\n",
    "    total_distance = 0.0; num_valid_pairs = 0; decoded_pairs = []\n",
    "    targets_np = targets_padded.cpu().numpy(); target_lengths_np = target_lengths.cpu().numpy()\n",
    "    batch_size = targets_padded.shape[0]\n",
    "    if len(predictions) != batch_size: print(f\"Warning: Levenshtein size mismatch! Preds:{len(predictions)}, Targets:{batch_size}\"); return float('inf'), []\n",
    "    for i in range(batch_size):\n",
    "        real_target_len = target_lengths_np[i]; pred_str = predictions[i]\n",
    "        if real_target_len <= 0: target_str = \"\"; dist = len(pred_str)\n",
    "        else:\n",
    "            target_indices = targets_np[i, :real_target_len]\n",
    "            target_str = \"\".join([index_to_char_map.get(idx, '?') for idx in target_indices if idx != pad_idx])\n",
    "            try: dist = Levenshtein.distance(pred_str, target_str)\n",
    "            except Exception as e: print(f\"Levenshtein Error: ('{pred_str}', '{target_str}'). {e}\"); dist = max(len(pred_str), len(target_str))\n",
    "        total_distance += dist; num_valid_pairs += 1; decoded_pairs.append((pred_str, target_str))\n",
    "    mean_levenshtein = total_distance / num_valid_pairs if num_valid_pairs > 0 else float('inf')\n",
    "    return mean_levenshtein, decoded_pairs\n",
    "\n",
    "print(\"Функции ctc_greedy_decode и calculate_levenshtein определены.\")\n",
    "print(\"\\n--- Ячейка 9: Определение функций декодирования и метрики завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 10: Функции Обучения и Валидации Эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 10: Определение функций обучения и валидации эпохи ---\n",
      "Функции train_epoch и validate_epoch определены (SyntaxError исправлен).\n",
      "\n",
      "--- Ячейка 10: Определение функций обучения и валидации завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 10: Функции Обучения и Валидации Эпохи (Исправлен SyntaxError в train_epoch)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 10: Определение функций обучения и валидации эпохи ---\")\n",
    "\n",
    "# Зависимости проверяются в run_training_pipeline\n",
    "if 'F' not in globals(): import torch.nn.functional as F\n",
    "if 'tqdm' not in globals(): from tqdm.notebook import tqdm\n",
    "if 'np' not in globals(): import numpy as np\n",
    "if 'torch' not in globals(): import torch\n",
    "if 'optim' not in globals(): import torch.optim as optim\n",
    "if 'nn' not in globals(): import torch.nn as nn\n",
    "if 'traceback' not in globals(): import traceback\n",
    "if 'DataLoader' not in globals(): from torch.utils.data import DataLoader\n",
    "if 'itertools' not in globals(): import itertools\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "\n",
    "# --- Функция Обучения Одной Эпохи ---\n",
    "def train_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.CTCLoss, optimizer: optim.Optimizer,\n",
    "                scheduler: Optional[optim.lr_scheduler._LRScheduler], device: torch.device, epoch_num: int, total_epochs: int,\n",
    "                index_to_char_map: Dict[int, str], blank_idx: int, pad_idx: int, grad_clip_norm: float,\n",
    "                batches_per_epoch: int = 0) -> Tuple[float, float, float]:\n",
    "    \"\"\" Выполняет одну эпоху обучения. \"\"\"\n",
    "    model.train(); running_loss = 0.0; total_lev_dist = 0.0; total_lr = 0.0; num_batches_processed = 0; total_samples = 0\n",
    "    try: time_factor = max(model.get_time_reduction_factor(), 1.0)\n",
    "    except AttributeError: time_factor = 1.0\n",
    "\n",
    "    total_batches_in_loader = len(dataloader); iterator = dataloader; num_batches_to_process = total_batches_in_loader\n",
    "    if batches_per_epoch > 0 and batches_per_epoch < total_batches_in_loader:\n",
    "         iterator = itertools.islice(dataloader, batches_per_epoch); num_batches_to_process = batches_per_epoch\n",
    "    if num_batches_to_process == 0: return 0.0, float('inf'), 0.0\n",
    "\n",
    "    pbar = tqdm(iterator, total=num_batches_to_process, desc=f\"Эпоха {epoch_num}/{total_epochs} [Тренировка]\", leave=False, ncols=1000)\n",
    "    for batch_idx, batch_data in enumerate(pbar):\n",
    "        if batch_data is None: continue\n",
    "        features, targets, feature_lengths, target_lengths = batch_data\n",
    "        if features is None or targets is None: continue\n",
    "        batch_size = features.size(0)\n",
    "        if batch_size == 0: continue\n",
    "\n",
    "        features = features.to(device, non_blocking=True); targets = targets.to(device, non_blocking=True)\n",
    "        feature_lengths_cpu = feature_lengths.cpu(); target_lengths_cpu = target_lengths.cpu()\n",
    "        input_lengths_ctc = torch.floor(feature_lengths_cpu.float() / time_factor + 1e-9).long().clamp(min=1)\n",
    "        loss_value = float('inf'); lev_dist_batch = float('inf'); current_lr = optimizer.param_groups[0]['lr']\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(features) # (T_red, B, C)\n",
    "            if logits.shape[1] != batch_size: print(f\"\\n!!! ERROR (Train): Batch size mismatch! Out:{logits.shape[1]} != In:{batch_size}. Skip.\"); continue\n",
    "            log_probs = F.log_softmax(logits, dim=2)\n",
    "            output_length = log_probs.shape[0]\n",
    "            input_lengths_ctc_clamped = input_lengths_ctc.clamp(max=output_length)\n",
    "            target_lengths_clamped = target_lengths_cpu.clamp(max=targets.shape[1])\n",
    "            valid_target_mask = target_lengths_clamped > 0\n",
    "            if not torch.all(valid_target_mask):\n",
    "                 log_probs_valid = log_probs[:, valid_target_mask, :]; targets_valid = targets[valid_target_mask, :]\n",
    "                 input_lengths_valid = input_lengths_ctc_clamped[valid_target_mask]; target_lengths_valid = target_lengths_clamped[valid_target_mask]\n",
    "                 loss = criterion(log_probs_valid, targets_valid, input_lengths_valid, target_lengths_valid) if log_probs_valid.shape[1] > 0 else torch.tensor(0.0, device=device)\n",
    "            else: loss = criterion(log_probs, targets, input_lengths_ctc_clamped, target_lengths_clamped)\n",
    "            if not torch.isfinite(loss): print(f\"\\n!!! WARNING (Train): NaN/Inf loss! Skip step.\"); optimizer.zero_grad(); continue\n",
    "            loss_value = loss.item()\n",
    "            if loss.requires_grad:\n",
    "                loss.backward()\n",
    "                if grad_clip_norm > 0: torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_norm)\n",
    "                optimizer.step()\n",
    "                if scheduler: scheduler.step()\n",
    "            with torch.no_grad():\n",
    "                if 'ctc_greedy_decode' not in globals(): raise NameError(\"ctc_greedy_decode missing\")\n",
    "                decoded_preds = ctc_greedy_decode(logits, index_to_char_map, blank_idx)\n",
    "                if 'calculate_levenshtein' not in globals(): raise NameError(\"calculate_levenshtein missing\")\n",
    "                lev_dist_batch, _ = calculate_levenshtein(decoded_preds, targets.cpu(), target_lengths_cpu, index_to_char_map, pad_idx)\n",
    "                if not np.isfinite(lev_dist_batch): lev_dist_batch = 20.0\n",
    "        except RuntimeError as e:\n",
    "             if \"CUDA out of memory\" in str(e): print(\"\\n!!! CUDA OOM (Train) !!!\"); raise e\n",
    "             else: print(f\"\\n!!! RuntimeError (Train): {e} !!!\"); traceback.print_exc(limit=1); loss_value = 30.0; lev_dist_batch = 30.0\n",
    "        except Exception as e: print(f\"\\n!!! Error (Train): {e} !!!\"); traceback.print_exc(limit=1); loss_value = 30.0; lev_dist_batch = 30.0\n",
    "\n",
    "        # === ИСПРАВЛЕНИЕ ЗДЕСЬ ===\n",
    "        if np.isfinite(loss_value):\n",
    "            running_loss += loss_value * batch_size\n",
    "        else:\n",
    "            running_loss += 30.0 * batch_size # Штраф за NaN/Inf loss\n",
    "        # ========================\n",
    "\n",
    "        total_lev_dist += lev_dist_batch * batch_size; total_samples += batch_size; total_lr += current_lr; num_batches_processed += 1\n",
    "        pbar.set_postfix(loss=f'{loss_value:.3f}', lev=f'{lev_dist_batch:.3f}', lr=f'{current_lr:.2e}')\n",
    "    pbar.close()\n",
    "    avg_loss = running_loss / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lev = total_lev_dist / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lr = total_lr / num_batches_processed if num_batches_processed > 0 else 0.0\n",
    "    return avg_loss, avg_lev, avg_lr\n",
    "\n",
    "# --- Функция Валидации Одной Эпохи ---\n",
    "def validate_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.CTCLoss, device: torch.device,\n",
    "                   index_to_char_map: Dict[int, str], blank_idx: int, pad_idx: int\n",
    "                  ) -> Tuple[float, float, List[Tuple[str, str]]]:\n",
    "    \"\"\" Выполняет одну эпоху валидации. \"\"\"\n",
    "    model.eval(); running_loss = 0.0; total_lev_dist = 0.0; total_samples = 0; all_decoded_pairs = []\n",
    "    try: time_factor = max(model.get_time_reduction_factor(), 1.0)\n",
    "    except AttributeError: time_factor = 1.0\n",
    "    pbar = tqdm(dataloader, desc=\"   [Валидация]\", leave=False, ncols=1000)\n",
    "    with torch.no_grad():\n",
    "        for batch_data in pbar:\n",
    "            if batch_data is None: continue\n",
    "            features, targets, feature_lengths, target_lengths = batch_data\n",
    "            if features is None or targets is None: continue\n",
    "            batch_size = features.size(0)\n",
    "            if batch_size == 0: continue\n",
    "\n",
    "            features = features.to(device, non_blocking=True); targets = targets.to(device, non_blocking=True)\n",
    "            feature_lengths_cpu = feature_lengths.cpu(); target_lengths_cpu = target_lengths.cpu()\n",
    "            input_lengths_ctc = torch.floor(feature_lengths_cpu.float() / time_factor + 1e-9).long().clamp(min=1)\n",
    "            loss_value = float('inf'); lev_dist_batch = float('inf'); decoded_pairs_batch = []\n",
    "            try:\n",
    "                logits = model(features); output_length = logits.shape[0]\n",
    "                if logits.shape[1] != batch_size: print(f\"\\n!!! ERROR (Val): Batch size mismatch! Out:{logits.shape[1]} != In:{batch_size}. Skip.\"); continue\n",
    "                log_probs = F.log_softmax(logits, dim=2)\n",
    "                input_lengths_ctc_clamped = input_lengths_ctc.clamp(max=output_length)\n",
    "                target_lengths_clamped = target_lengths_cpu.clamp(max=targets.shape[1])\n",
    "                valid_target_mask = target_lengths_clamped > 0\n",
    "                if not torch.all(valid_target_mask):\n",
    "                    log_probs_valid = log_probs[:, valid_target_mask, :]; targets_valid = targets[valid_target_mask, :]\n",
    "                    input_lengths_valid = input_lengths_ctc_clamped[valid_target_mask]; target_lengths_valid = target_lengths_clamped[valid_target_mask]\n",
    "                    loss = criterion(log_probs_valid, targets_valid, input_lengths_valid, target_lengths_valid) if log_probs_valid.shape[1] > 0 else torch.tensor(0.0, device=device)\n",
    "                else: loss = criterion(log_probs, targets, input_lengths_ctc_clamped, target_lengths_clamped)\n",
    "\n",
    "                # === ИСПРАВЛЕНИЕ ЗДЕСЬ (на всякий случай, хотя здесь не было ошибки) ===\n",
    "                if torch.isfinite(loss):\n",
    "                    loss_value = loss.item()\n",
    "                else:\n",
    "                    print(\"\\nWarning (Val): NaN/Inf loss.\")\n",
    "                    loss_value = float('inf') # Оставляем inf для валидации\n",
    "                # =======================================================================\n",
    "\n",
    "                if 'ctc_greedy_decode' not in globals(): raise NameError(\"ctc_greedy_decode missing\")\n",
    "                decoded_preds = ctc_greedy_decode(logits, index_to_char_map, blank_idx)\n",
    "                if 'calculate_levenshtein' not in globals(): raise NameError(\"calculate_levenshtein missing\")\n",
    "                lev_dist_batch, decoded_pairs_batch = calculate_levenshtein(decoded_preds, targets.cpu(), target_lengths_cpu, index_to_char_map, pad_idx)\n",
    "                if not np.isfinite(lev_dist_batch): lev_dist_batch = 20.0\n",
    "            except Exception as e: print(f\"\\n!!! Error (Val): {e} !!!\"); traceback.print_exc(limit=1); loss_value=float('inf'); lev_dist_batch=float('inf'); decoded_pairs_batch = [(\"ERROR\",\"ERROR\")] * batch_size\n",
    "\n",
    "            # === ИСПРАВЛЕНИЕ ЗДЕСЬ ===\n",
    "            if np.isfinite(loss_value): # Используем numpy isfinite для единообразия\n",
    "                running_loss += loss_value * batch_size\n",
    "            # Если loss inf, то running_loss не увеличивается, что логично для валидации\n",
    "            # ========================\n",
    "\n",
    "            total_lev_dist += lev_dist_batch * batch_size; total_samples += batch_size\n",
    "            if len(all_decoded_pairs) < 10: all_decoded_pairs.extend(decoded_pairs_batch[:max(0, 10 - len(all_decoded_pairs))])\n",
    "            pbar.set_postfix(loss=f'{loss_value:.3f}', lev=f'{lev_dist_batch:.3f}')\n",
    "    pbar.close()\n",
    "    avg_loss = running_loss / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lev = total_lev_dist / total_samples if total_samples > 0 else float('inf')\n",
    "    return avg_loss, avg_lev, all_decoded_pairs\n",
    "\n",
    "print(\"Функции train_epoch и validate_epoch определены (SyntaxError исправлен).\")\n",
    "print(\"\\n--- Ячейка 10: Определение функций обучения и валидации завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 11 Интерактивная настройка RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 11: Интерактивная Настройка RMS (SR=8000 Гц) ---\n",
      "Параметры визуализации: SR=8000Hz, Filter=False, Norm=Z-Score\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce807e0453744d18d591b33da7433df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Интерактивная настройка RMS (SR=8000Hz, Z-Score)</b>'), Dropdown(description='Ау…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ячейка 11: Интерактивная настройка RMS (Исправлена) готова ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 11: Интерактивная Настройка RMS (Исправлена + Упрощена)\n",
    "# =============================================================================\n",
    "print(f\"--- Ячейка 11: Интерактивная Настройка RMS (SR={AUDIO_CONFIG['sample_rate']} Гц) ---\")\n",
    "\n",
    "if not IPYWIDGETS_AVAILABLE:\n",
    "    print(\"ipywidgets не доступен. Пропуск интерактивной ячейки.\")\n",
    "else:\n",
    "    # Импорты\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, Audio, clear_output\n",
    "    import matplotlib.pyplot as plt\n",
    "    import librosa, librosa.display, numpy as np, pandas as pd\n",
    "    from pathlib import Path; import traceback, random\n",
    "    # Добавим signal из scipy, если его нет глобально к этому моменту\n",
    "    if 'signal' not in globals(): import scipy.signal as signal\n",
    "\n",
    "    # Проверка глобальных переменных\n",
    "    required_globals_vis = ['AUDIO_CONFIG', 'EXTRACTED_AUDIO_DIR', 'train_df', 'SEED']\n",
    "    missing_globals_vis = [v for v in required_globals_vis if v not in globals()]\n",
    "    if missing_globals_vis: raise NameError(f\"Отсутствуют переменные: {missing_globals_vis}\")\n",
    "    if train_df.empty: raise ValueError(\"train_df пуст.\")\n",
    "\n",
    "    # Параметры из базового конфига\n",
    "    SR_VIS = AUDIO_CONFIG['sample_rate']\n",
    "    APPLY_FILTER_VIS = AUDIO_CONFIG.get('apply_filter', True)\n",
    "    FILTER_ORDER_VIS = AUDIO_CONFIG.get('filter_order', 5)\n",
    "    FILTER_FMIN_VIS = AUDIO_CONFIG.get('filter_fmin', 0)\n",
    "    FILTER_FMAX_VIS = AUDIO_CONFIG.get('filter_fmax', SR_VIS/2*0.999)\n",
    "    # Нормализация всегда Z-Score, Delta всегда standard\n",
    "    print(f\"Параметры визуализации: SR={SR_VIS}Hz, Filter={APPLY_FILTER_VIS}, Norm=Z-Score\")\n",
    "\n",
    "    # --- Упрощенная функция расчета признаков для визуализации ---\n",
    "    def calculate_interactive_features_simple(waveform_np: np.ndarray, sr: int,\n",
    "                                              frame_len_samples: int, hop_len_samples: int,\n",
    "                                              apply_filter: bool, filter_order: int, fmin: float, fmax: float,\n",
    "                                              file_id_vis: str = \"N/A\") -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\" Расчет RMS и Delta с Z-Score нормализацией для визуализации. \"\"\"\n",
    "        rms_norm_res = np.array([], dtype=np.float32); delta_norm_res = np.array([], dtype=np.float32)\n",
    "        if not isinstance(waveform_np, np.ndarray) or waveform_np.size < frame_len_samples: return rms_norm_res, delta_norm_res\n",
    "        try:\n",
    "            processed_waveform = waveform_np.astype(np.float32)\n",
    "            # 1. Фильтрация (если включена)\n",
    "            if apply_filter:\n",
    "                nyquist_vis = sr / 2.0; fmax_eff = min(fmax, nyquist_vis * 0.999); fmin_eff = max(0.0, fmin)\n",
    "                is_lowcut = fmin_eff > 1e-3; is_highcut = fmax_eff < (nyquist_vis * 0.995)\n",
    "                if is_lowcut or is_highcut:\n",
    "                    try:\n",
    "                        if is_lowcut and is_highcut: ftype, freqs = 'bandpass', [fmin_eff, fmax_eff]\n",
    "                        elif is_lowcut: ftype, freqs = 'highpass', fmin_eff\n",
    "                        else: ftype, freqs = 'lowpass', fmax_eff\n",
    "                        if not (isinstance(freqs, list) and freqs[0] >= freqs[1]):\n",
    "                            sos = signal.butter(filter_order, freqs, btype=ftype, fs=sr, output='sos')\n",
    "                            processed_waveform = signal.sosfiltfilt(sos, processed_waveform)\n",
    "                    except Exception as filter_e: print(f\"Warning ({file_id_vis}): Ошибка фильтрации виз: {filter_e}\")\n",
    "            # 2. RMS\n",
    "            rms_env = librosa.feature.rms(y=processed_waveform, frame_length=frame_len_samples, hop_length=hop_len_samples, center=True, pad_mode='reflect')[0]\n",
    "            if rms_env.size < 2: return rms_norm_res, delta_norm_res\n",
    "            # 3. Delta (standard)\n",
    "            delta_feat = np.diff(rms_env, n=1, prepend=rms_env[0])\n",
    "            # 4. Нормализация Z-Score\n",
    "            epsilon = 1e-8\n",
    "            mean_rms = np.mean(rms_env); std_rms = np.std(rms_env); rms_norm_res = ((rms_env - mean_rms) / (std_rms + epsilon)).astype(np.float32) if std_rms >= epsilon else np.zeros_like(rms_env)\n",
    "            mean_del = np.mean(delta_feat); std_del = np.std(delta_feat); delta_norm_res = ((delta_feat - mean_del) / (std_del + epsilon)).astype(np.float32) if std_del >= epsilon else np.zeros_like(delta_feat)\n",
    "            return rms_norm_res, delta_norm_res\n",
    "        except Exception as e: print(f\"Error calc interactive features ({file_id_vis}): {e}\"); traceback.print_exc(limit=1); return np.array([]), np.array([])\n",
    "\n",
    "    # --- Функция отрисовки графиков ---\n",
    "    def plot_interactive_rms_simple(times: np.ndarray, waveform: np.ndarray, rms_norm: np.ndarray, delta_norm: np.ndarray,\n",
    "                                    sr: int, frame_len_samples: int, hop_len_samples: int, file_id: str, frame_ms: float, hop_ms: float):\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(16, 10), sharex=True)\n",
    "        title = f\"Интерактивный Анализ RMS (Z-Score): {file_id}\\nSR={sr}, Frame={frame_len_samples} samples (~{frame_ms:.1f}ms), Hop={hop_len_samples} samples (~{hop_ms:.1f}ms)\"\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "        librosa.display.waveshow(waveform, sr=sr, ax=axes[0], color='grey', alpha=0.7); axes[0].set_title(\"Waveform\"); axes[0].label_outer(); axes[0].grid(True, linestyle=':')\n",
    "        if times.size > 0 and rms_norm.size == times.size and delta_norm.size == times.size:\n",
    "            axes[1].plot(times, rms_norm, label='RMS (Z-Score)', color='blue', linewidth=1.5); axes[1].set_title(\"Норм. RMS (Z-Score)\"); axes[1].legend(); axes[1].grid(True, linestyle=':'); axes[1].label_outer()\n",
    "            axes[2].plot(times, delta_norm, label='Delta (Z-Score)', color='red', linewidth=1.5); axes[2].axhline(0, color='black', linestyle=':', linewidth=1); axes[2].set_title(\"Норм. Delta (Z-Score)\"); axes[2].legend(); axes[2].grid(True, linestyle=':'); axes[2].label_outer()\n",
    "            img = axes[3].imshow(rms_norm.reshape(1, -1), aspect='auto', cmap='magma', interpolation='nearest', extent=[times.min(), times.max(), 0, 1]); axes[3].set_title(\"Норм. RMS (Heatmap)\"); axes[3].set_yticks([])\n",
    "            fig.colorbar(img, ax=axes[3], orientation='horizontal', label='Норм. RMS (Z-Score)', pad=0.2)\n",
    "        else:\n",
    "            for i in range(1, 4): axes[i].set_title(f\"График {i+1} - Нет данных\"); axes[i].text(0.5, 0.5, 'Нет данных', ha='center', va='center', transform=axes[i].transAxes); axes[i].label_outer()\n",
    "        axes[-1].set_xlabel(\"Время (с)\"); plt.tight_layout(rect=[0, 0.03, 1, 0.94]); plt.show()\n",
    "\n",
    "    # --- Виджеты ---\n",
    "    file_ids_vis_list = train_df['id'].unique().tolist(); file_ids_vis_list = random.sample(file_ids_vis_list, min(500, len(file_ids_vis_list)))\n",
    "    if not file_ids_vis_list: raise SystemExit(\"Остановка: Нет файлов для визуализации.\")\n",
    "    file_dd = widgets.Dropdown(options=file_ids_vis_list, description='Аудиофайл:', style={'description_width': 'initial'})\n",
    "    frame_ms_slider = widgets.IntSlider(value=24, min=8, max=64, step=2, description='Frame (ms):', style={'description_width': 'initial'}, layout=widgets.Layout(width='400px'), continuous_update=False)\n",
    "    hop_ms_slider = widgets.IntSlider(value=12, min=4, max=24, step=1, description='Hop (ms):', style={'description_width': 'initial'}, layout=widgets.Layout(width='400px'), continuous_update=False)\n",
    "    samples_label = widgets.Label(value=\"\")\n",
    "    params_box = widgets.VBox([frame_ms_slider, hop_ms_slider, samples_label])\n",
    "    plot_output = widgets.Output()\n",
    "    def _link_sliders_ms(change): frame_ms = frame_ms_slider.value; hop_ms_slider.max = frame_ms; hop_ms_slider.value = min(hop_ms_slider.value, frame_ms)\n",
    "    frame_ms_slider.observe(_link_sliders_ms, names='value')\n",
    "\n",
    "    # --- Обработчик (С ИСПРАВЛЕНИЕМ) ---\n",
    "    def handle_rms_vis_change_simple(change):\n",
    "        frame_ms = frame_ms_slider.value; hop_ms = hop_ms_slider.value; file_id = file_dd.value\n",
    "        frame_samples = max(1, int(frame_ms * SR_VIS / 1000)); hop_samples = max(1, int(hop_ms * SR_VIS / 1000))\n",
    "        if frame_samples < hop_samples: frame_samples = hop_samples\n",
    "        samples_label.value = f\"(Frame: {frame_samples} сэмплов, Hop: {hop_samples} сэмплов)\"\n",
    "\n",
    "        # === ИСПРАВЛЕНИЕ ЗДЕСЬ ===\n",
    "        if not file_id:\n",
    "            with plot_output: # Отдельный блок with\n",
    "                clear_output(wait=True)\n",
    "                print(\"Выберите файл.\")\n",
    "            return # Выход из функции\n",
    "        # ========================\n",
    "\n",
    "        audio_path = EXTRACTED_AUDIO_DIR / file_id;\n",
    "        # === ИСПРАВЛЕНИЕ ЗДЕСЬ ===\n",
    "        if not audio_path.is_file():\n",
    "            with plot_output: # Отдельный блок with\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Ошибка: Файл не найден {audio_path}\")\n",
    "            return # Выход из функции\n",
    "        # ========================\n",
    "\n",
    "        try:\n",
    "            waveform, _ = librosa.load(audio_path, sr=SR_VIS, mono=True)\n",
    "            # Расчет УПРОЩЕННЫХ признаков\n",
    "            rms_norm_res, delta_norm_res = calculate_interactive_features_simple(\n",
    "                waveform, SR_VIS, frame_samples, hop_samples,\n",
    "                APPLY_FILTER_VIS, FILTER_ORDER_VIS, FILTER_FMIN_VIS, FILTER_FMAX_VIS,\n",
    "                file_id_vis=file_id )\n",
    "            times_res = librosa.times_like(rms_norm_res, sr=SR_VIS, hop_length=hop_samples) if rms_norm_res.size > 0 else np.array([])\n",
    "            with plot_output:\n",
    "                clear_output(wait=True); print(f\"Отображение: {file_id} (SR={SR_VIS}Hz)\")\n",
    "                # Вызов УПРОЩЕННОЙ функции отрисовки\n",
    "                plot_interactive_rms_simple(times_res, waveform, rms_norm_res, delta_norm_res, SR_VIS, frame_samples, hop_samples, file_id, frame_ms, hop_ms)\n",
    "        except Exception as e:\n",
    "             # === ИСПРАВЛЕНИЕ ЗДЕСЬ (на всякий случай) ===\n",
    "            with plot_output: # Отдельный блок with\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Ошибка обработки {file_id}:\\n{e}\")\n",
    "                traceback.print_exc(limit=2)\n",
    "            # ========================\n",
    "\n",
    "    # --- Привязка и отображение ---\n",
    "    file_dd.observe(handle_rms_vis_change_simple, names='value')\n",
    "    frame_ms_slider.observe(handle_rms_vis_change_simple, names='value')\n",
    "    hop_ms_slider.observe(handle_rms_vis_change_simple, names='value')\n",
    "    ui_rms_tuning = widgets.VBox([ widgets.HTML(f\"<b>Интерактивная настройка RMS (SR={SR_VIS}Hz, Z-Score)</b>\"), file_dd, params_box, plot_output ])\n",
    "    display(ui_rms_tuning)\n",
    "    _link_sliders_ms(None); handle_rms_vis_change_simple(None) # Первый запуск\n",
    "\n",
    "    print(f\"\\n--- Ячейка 11: Интерактивная настройка RMS (Исправлена) готова ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 12: Функция Полного Цикла Обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 12: Определение функции run_training_pipeline ---\n",
      "--- Функция run_training_pipeline (Исправлена заглушка MLflow) определена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 12: Функция для Полного Цикла Обучения и Инференса (Исправлена заглушка MLflow)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 12: Определение функции run_training_pipeline ---\")\n",
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import numpy as np, pandas as pd, time, json, random, traceback\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Union, Tuple, List, Dict, Optional\n",
    "\n",
    "# --- Проверка и импорт MLflow или создание ЗАГЛУШКИ (ИСПРАВЛЕНО) ---\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"Предупреждение: mlflow не найден. Логирование экспериментов будет отключено.\")\n",
    "    class DummyRun:\n",
    "        def __enter__(self): return self\n",
    "        def __exit__(self, *args): pass\n",
    "        class DummyRunInfo: info = type('obj', (object,), {'run_id': 'mlflow_disabled'})()\n",
    "        info = DummyRunInfo()\n",
    "    class DummyMLflow:\n",
    "        def set_experiment(self, *args, **kwargs): pass\n",
    "        def start_run(self, *args, **kwargs): return DummyRun()\n",
    "        def log_param(self, *args, **kwargs): pass\n",
    "        def log_params(self, *args, **kwargs): pass\n",
    "        # === ИСПРАВЛЕНИЕ ЗДЕСЬ: Каждая функция на своей строке ===\n",
    "        def log_metric(self, *args, **kwargs): pass\n",
    "        def log_metrics(self, *args, **kwargs): pass\n",
    "        # =====================================================\n",
    "        def log_artifact(self, *args, **kwargs): pass\n",
    "        def log_dict(self, *args, **kwargs): pass\n",
    "        def set_tag(self, *args, **kwargs): pass\n",
    "        def active_run(self): return None\n",
    "        def end_run(self, status='FINISHED'): pass\n",
    "    mlflow = DummyMLflow()\n",
    "\n",
    "\n",
    "# --- Проверка глобальных зависимостей ---\n",
    "def check_global_dependencies():\n",
    "    required = ['MorseDataset', 'MorseRecognizer', 'collate_fn', 'train_epoch', 'validate_epoch',\n",
    "                'ctc_greedy_decode', 'calculate_levenshtein', 'set_seed']\n",
    "    missing = [r for r in required if not callable(globals().get(r))]\n",
    "    if missing: raise NameError(f\"Отсутствуют зависимости: {missing}. Убедитесь, что все ячейки выше выполнены.\")\n",
    "\n",
    "# --- Функция пайплайна ---\n",
    "def run_training_pipeline(\n",
    "    # Конфиги\n",
    "    audio_config: Dict, model_config: Dict, train_config: Dict,\n",
    "    # Данные/пути\n",
    "    full_train_df: pd.DataFrame, test_df: pd.DataFrame, audio_dir: Path, base_output_dir: Path,\n",
    "    # Словари/константы\n",
    "    char_to_index: Dict[str, int], index_to_char: Dict[int, str],\n",
    "    blank_idx: int, pad_idx: int, num_classes_ctc: int,\n",
    "    # Управление\n",
    "    device: torch.device, run_suffix: str, base_filename_suffix: str, # Используем полный базовый суффикс\n",
    "    seed: int = 42, mlflow_experiment_name: str = \"Morse_Experiment\"\n",
    ") -> Dict:\n",
    "    \"\"\" Выполняет полный цикл: данные, обучение, сохранение, инференс. \"\"\"\n",
    "    check_global_dependencies()\n",
    "    run_results = { \"run_suffix\": run_suffix, \"status\": \"pending\", \"best_val_lev\": float('inf'), \"best_epoch\": None,\n",
    "                    \"final_train_loss\": float('inf'), \"final_val_loss\": float('inf'), \"train_time_min\": 0.0,\n",
    "                    \"infer_time_sec\": 0.0, \"model_path\": None, \"params_path\": None, \"submission_path\": None, \"error\": None }\n",
    "    print(f\"\\n{'='*20} Запуск: {run_suffix} {'='*20}\")\n",
    "    print(f\"Audio Config: {json.dumps(audio_config)}\")\n",
    "    print(f\"Model Config: {json.dumps(model_config)}\") # Выводим конфиг модели\n",
    "    print(f\"Train Config: {json.dumps(train_config)}\")\n",
    "\n",
    "    # Формирование путей (используем полный базовый суффикс + суффикс запуска)\n",
    "    output_filename_base = f\"{base_filename_suffix}{run_suffix}\"\n",
    "    current_model_path = base_output_dir / f\"model_{output_filename_base}.pth\"\n",
    "    current_params_path = base_output_dir / f\"params_{output_filename_base}.json\"\n",
    "    current_submission_path = base_output_dir / f\"submission_greedy_{output_filename_base}.csv\"\n",
    "    run_results.update({ \"model_path\": str(current_model_path), \"params_path\": str(current_params_path), \"submission_path\": str(current_submission_path) })\n",
    "    print(f\"  Пути: Model={current_model_path.name}, Params={current_params_path.name}, Sub={current_submission_path.name}\")\n",
    "\n",
    "    # Объявление переменных для finally\n",
    "    model = None; criterion = None; optimizer = None; scheduler = None\n",
    "    full_dataset = None; train_subset = None; val_subset = None\n",
    "    train_loader = None; val_loader = None\n",
    "    inference_model_instance = None; infer_test_dataset = None; test_loader_infer = None\n",
    "    logits_infer = None; features_infer = None\n",
    "\n",
    "    try:\n",
    "        set_seed(seed)\n",
    "        # --- 1. Подготовка Данных ---\n",
    "        print(\"\\n1. Подготовка данных...\")\n",
    "        if 'MorseDataset' not in globals(): raise NameError(\"Класс MorseDataset не определен!\")\n",
    "        full_dataset = MorseDataset( dataframe=full_train_df, audio_dir=audio_dir, char_to_index=char_to_index,\n",
    "                                     audio_config=audio_config, model_input_feature_dim=model_config['input_feature_dim'],\n",
    "                                     is_train=True )\n",
    "        dataset_size = len(full_dataset);\n",
    "        if dataset_size == 0: raise ValueError(\"Обучающий датасет пуст!\")\n",
    "        val_split_ratio = train_config['validation_split_ratio']\n",
    "        val_size = int(np.floor(val_split_ratio * dataset_size)); train_size = dataset_size - val_size\n",
    "        if train_size <= 0 or val_size <= 0: raise ValueError(f\"Некорректное разделение: Train={train_size}, Val={val_size}\")\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "        train_subset, val_subset = random_split(full_dataset, [train_size, val_size], generator=generator)\n",
    "        bs = train_config['batch_size']; nw = train_config['num_workers']; pm = (device.type == 'cuda')\n",
    "        if 'collate_fn' not in globals(): raise NameError(\"Функция collate_fn не определена!\")\n",
    "        train_loader = DataLoader(train_subset, batch_size=bs, shuffle=True, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "        val_loader = DataLoader(val_subset, batch_size=bs*2, shuffle=False, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "        print(f\"  Данные готовы: Train={len(train_subset)} ({len(train_loader)} батчей), Val={len(val_subset)} ({len(val_loader)} батчей).\")\n",
    "\n",
    "        # --- 2. Инициализация Модели, Loss, Optimizer, Scheduler ---\n",
    "        print(\"\\n2. Инициализация компонентов...\")\n",
    "        if 'MorseRecognizer' not in globals(): raise NameError(\"Класс MorseRecognizer не определен!\")\n",
    "        model = MorseRecognizer(num_classes_ctc=num_classes_ctc, **model_config).to(device) # Используем переданный model_config\n",
    "        criterion = nn.CTCLoss(blank=blank_idx, reduction='mean', zero_infinity=True).to(device)\n",
    "        optimizer_name = train_config.get('optimizer', 'AdamW').lower(); lr = train_config['learning_rate']; wd = train_config['weight_decay']\n",
    "        if optimizer_name == 'adamw': optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        elif optimizer_name == 'adam': optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        else: print(f\"Warning: Неизвестный optimizer '{optimizer_name}'. Используется AdamW.\"); optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        print(f\"  Model, Loss, Optimizer ({type(optimizer).__name__}) готовы.\")\n",
    "        # Scheduler\n",
    "        total_batches_in_loader = len(train_loader); batches_per_epoch_run = train_config.get(\"batches_per_epoch\", 0)\n",
    "        steps_per_epoch = total_batches_in_loader\n",
    "        if batches_per_epoch_run > 0 and batches_per_epoch_run < total_batches_in_loader: steps_per_epoch = batches_per_epoch_run\n",
    "        if steps_per_epoch <= 0: raise ValueError(f\"Steps_per_epoch ({steps_per_epoch}) должен быть > 0!\")\n",
    "        total_steps = train_config['num_epochs'] * steps_per_epoch\n",
    "        div_f = train_config.get('div_factor', 25.0); final_div_f = train_config.get('final_div_factor', 1e4)\n",
    "        scheduler = OneCycleLR(optimizer, max_lr=lr, total_steps=total_steps, pct_start=0.3, anneal_strategy='cos', div_factor=div_f, final_div_factor=final_div_f)\n",
    "        print(f\"  Scheduler OneCycleLR создан (total_steps={total_steps}, div_factor={div_f}, final_div_factor={final_div_f}).\")\n",
    "\n",
    "        # --- 3. Цикл Обучения с MLflow ---\n",
    "        print(\"\\n3. Запуск цикла обучения...\")\n",
    "        mlflow.set_experiment(mlflow_experiment_name)\n",
    "        with mlflow.start_run(run_name=f\"run_{run_suffix}\") as current_run:\n",
    "            mlflow_run_id = current_run.info.run_id; print(f\"  MLflow Run ID: {mlflow_run_id}\")\n",
    "            run_results[\"mlflow_run_id\"] = mlflow_run_id; run_results[\"status\"] = \"training\"\n",
    "            mlflow.log_param(\"run_suffix\", run_suffix); mlflow.log_param(\"base_filename\", base_filename_suffix)\n",
    "            mlflow.log_params({\"seed\": seed, **train_config}); mlflow.log_dict(audio_config, \"audio_config.json\"); mlflow.log_dict(model_config, \"model_config.json\")\n",
    "            mlflow.set_tag(\"status\", \"training\")\n",
    "\n",
    "            start_time_train = time.time(); best_val_lev = float('inf'); epochs_without_improvement = 0; best_epoch = None\n",
    "            best_model_local_path_temp = base_output_dir / f\"temp_best_model_{mlflow_run_id}.pth\"\n",
    "\n",
    "            for epoch in range(1, train_config['num_epochs'] + 1):\n",
    "                print(f\"\\n--- Эпоха {epoch}/{train_config['num_epochs']} ---\")\n",
    "                if 'train_epoch' not in globals(): raise NameError(\"Функция train_epoch не определена!\")\n",
    "                avg_train_loss, avg_train_lev, avg_epoch_lr = train_epoch( model, train_loader, criterion, optimizer, scheduler, device, epoch, train_config['num_epochs'], index_to_char, blank_idx, pad_idx, train_config['gradient_clip_norm'], batches_per_epoch=batches_per_epoch_run )\n",
    "                if 'validate_epoch' not in globals(): raise NameError(\"Функция validate_epoch не определена!\")\n",
    "                avg_val_loss, avg_val_lev, _ = validate_epoch( model, val_loader, criterion, device, index_to_char, blank_idx, pad_idx )\n",
    "                run_results.update({ \"final_train_loss\": avg_train_loss, \"final_val_loss\": avg_val_loss })\n",
    "                mlflow.log_metrics({ \"train_loss\": avg_train_loss, \"train_levenshtein\": avg_train_lev, \"val_loss\": avg_val_loss, \"val_levenshtein\": avg_val_lev, \"learning_rate\": avg_epoch_lr }, step=epoch)\n",
    "                print(f\"  Итоги Эпохи {epoch}: Train Loss={avg_train_loss:.4f}, Train Lev={avg_train_lev:.4f}, Val Loss={avg_val_loss:.4f}, Val Lev={avg_val_lev:.4f}\")\n",
    "\n",
    "                if np.isfinite(avg_val_lev) and avg_val_lev < best_val_lev:\n",
    "                    print(f\"  ✨ Val Lev улучшился: {best_val_lev:.4f} -> {avg_val_lev:.4f}. Сохранение...\"); best_val_lev = avg_val_lev; best_epoch = epoch\n",
    "                    run_results.update({ \"best_val_lev\": best_val_lev, \"best_epoch\": best_epoch })\n",
    "                    try: torch.save(model.state_dict(), best_model_local_path_temp)\n",
    "                    except Exception as save_err: print(f\"  !!! Ошибка сохранения временной модели: {save_err} !!!\")\n",
    "                    epochs_without_improvement = 0\n",
    "                else:\n",
    "                    epochs_without_improvement += 1; print(f\"  Val Lev не улучшился ({avg_val_lev:.4f} vs best {best_val_lev:.4f}). Без улучшений: {epochs_without_improvement}/{train_config['early_stopping_patience']}\")\n",
    "                if epochs_without_improvement >= train_config['early_stopping_patience']:\n",
    "                    print(f\"  ❗️ Ранняя остановка на эпохе {epoch}!\"); mlflow.set_tag(\"status\", \"completed_early_stopping\"); run_results[\"status\"] = \"completed_early_stopping\"; break\n",
    "            # --- Конец цикла по эпохам ---\n",
    "            if run_results[\"status\"] == \"training\": run_results[\"status\"] = \"completed\"; mlflow.set_tag(\"status\", \"completed\")\n",
    "            train_duration_min = (time.time() - start_time_train) / 60; run_results[\"train_time_min\"] = train_duration_min\n",
    "            print(f\"\\n  Обучение завершено ({run_results['status']}) за {train_duration_min:.2f} мин. Лучший Val Lev: {best_val_lev:.4f} (Эпоха {best_epoch})\")\n",
    "\n",
    "            # --- 4. Сохранение Лучшей Модели и Параметров ---\n",
    "            print(\"\\n4. Сохранение артефактов...\")\n",
    "            if np.isfinite(best_val_lev): mlflow.log_metric(\"best_val_levenshtein\", best_val_lev)\n",
    "            if best_epoch is not None: mlflow.log_metric(\"best_epoch\", best_epoch)\n",
    "            mlflow.log_metric(\"training_time_min\", train_duration_min)\n",
    "\n",
    "            model_saved_final = False\n",
    "            if best_model_local_path_temp.exists() and np.isfinite(best_val_lev):\n",
    "                try:\n",
    "                    current_model_path.parent.mkdir(parents=True, exist_ok=True); current_model_path.unlink(missing_ok=True)\n",
    "                    best_model_local_path_temp.rename(current_model_path); print(f\"  Лучшая модель сохранена: {current_model_path.name}\")\n",
    "                    mlflow.log_artifact(str(current_model_path), artifact_path=\"model\"); model_saved_final = True\n",
    "                except Exception as e: print(f\"  !!! Ошибка перемещения/логирования модели: {e} !!!\")\n",
    "            else: print(\"  !!! Лучшая модель не сохранена.\"); mlflow.set_tag(\"model_saved\", \"False\")\n",
    "\n",
    "            final_params = { 'audio_config': audio_config, 'model_config': model_config, 'train_config': train_config,\n",
    "                             'char_map': { 'char_to_index': char_to_index, 'index_to_char': {str(k): v for k, v in index_to_char.items()},\n",
    "                                           'BLANK_IDX': blank_idx, 'PAD_IDX': pad_idx, 'NUM_CLASSES_CTC': num_classes_ctc },\n",
    "                             'results': { k: v for k, v in run_results.items() if k not in ['model_path', 'params_path', 'submission_path', 'mlflow_run_id'] and (np.isfinite(v) if isinstance(v, float) else True) } }\n",
    "            try:\n",
    "                current_params_path.parent.mkdir(parents=True, exist_ok=True); current_params_path.unlink(missing_ok=True)\n",
    "                with open(current_params_path, 'w', encoding='utf-8') as f: json.dump(final_params, f, indent=4, ensure_ascii=False)\n",
    "                print(f\"  Параметры сохранены: {current_params_path.name}\"); mlflow.log_artifact(str(current_params_path), artifact_path=\"config\")\n",
    "            except Exception as e: print(f\"  !!! Ошибка сохранения/логирования параметров: {e} !!!\")\n",
    "        # --- Конец MLflow run ---\n",
    "\n",
    "        # --- 5. Инференс на Тестовых Данных ---\n",
    "        print(\"\\n5. Запуск инференса...\")\n",
    "        infer_duration_sec = 0.0\n",
    "        if model_saved_final:\n",
    "            infer_start_time = time.time()\n",
    "            try:\n",
    "                 print(f\"  Загрузка: {current_model_path.name}, {current_params_path.name}\")\n",
    "                 with open(current_params_path, 'r', encoding='utf-8') as f: loaded_params_inf = json.load(f)\n",
    "                 loaded_audio_config_inf = loaded_params_inf['audio_config']; loaded_model_config_inf = loaded_params_inf['model_config']\n",
    "                 loaded_char_map_inf = loaded_params_inf['char_map']; loaded_index_to_char_inf = {int(k): v for k, v in loaded_char_map_inf['index_to_char'].items()}\n",
    "                 loaded_blank_idx_inf = loaded_char_map_inf['BLANK_IDX']; loaded_num_classes_inf = loaded_char_map_inf['NUM_CLASSES_CTC']\n",
    "\n",
    "                 if 'MorseRecognizer' not in globals(): raise NameError(\"Класс MorseRecognizer не определен для инференса!\")\n",
    "                 inference_model_instance = MorseRecognizer(num_classes_ctc=loaded_num_classes_inf, **loaded_model_config_inf).to(device)\n",
    "                 try: inference_model_instance.load_state_dict(torch.load(current_model_path, map_location=device, weights_only=True))\n",
    "                 except TypeError: print(\"   Warning: weights_only=True не поддерживается.\"); inference_model_instance.load_state_dict(torch.load(current_model_path, map_location=device))\n",
    "                 inference_model_instance.eval(); print(f\"  Модель для инференса загружена.\")\n",
    "\n",
    "                 print(f\"  Создание тестового DataLoader...\");\n",
    "                 if 'MorseDataset' not in globals(): raise NameError(\"Класс MorseDataset не определен для инференса!\")\n",
    "                 infer_test_dataset = MorseDataset( dataframe=test_df, audio_dir=audio_dir, char_to_index=loaded_char_map_inf['char_to_index'],\n",
    "                                                    audio_config=loaded_audio_config_inf, model_input_feature_dim=loaded_model_config_inf['input_feature_dim'], is_train=False )\n",
    "                 infer_bs = train_config.get('batch_size', 16) * 4\n",
    "                 if 'collate_fn' not in globals(): raise NameError(\"Функция collate_fn не определена для инференса!\")\n",
    "                 test_loader_infer = DataLoader(infer_test_dataset, batch_size=infer_bs, shuffle=False, collate_fn=collate_fn, num_workers=0, pin_memory=(device.type == 'cuda') )\n",
    "\n",
    "                 print(f\"  Предсказание...\"); predictions: Dict[str, str] = {}\n",
    "                 if 'ctc_greedy_decode' not in globals(): raise NameError(\"Функция ctc_greedy_decode не определена для инференса!\")\n",
    "                 with torch.no_grad():\n",
    "                     pbar_infer = tqdm(test_loader_infer, desc=\"Инференс\", leave=False, ncols=1000)\n",
    "                     for batch_data_infer in pbar_infer:\n",
    "                         if batch_data_infer is None: continue\n",
    "                         features_infer, file_ids_infer, _, _ = batch_data_infer\n",
    "                         if features_infer is None or file_ids_infer is None or len(features_infer) == 0: continue\n",
    "                         features_infer = features_infer.to(device, non_blocking=True)\n",
    "                         try:\n",
    "                             logits_infer = inference_model_instance(features_infer)\n",
    "                             decoded_batch_infer = ctc_greedy_decode(logits_infer, loaded_index_to_char_inf, loaded_blank_idx_inf)\n",
    "                             for file_id, pred_text in zip(file_ids_infer, decoded_batch_infer): predictions[file_id] = pred_text\n",
    "                         except Exception as e_inf_batch: print(f\"\\nОшибка инференса батча: {e_inf_batch}\"); [predictions.update({fid:\"ERROR_INFER\"}) for fid in file_ids_infer]\n",
    "\n",
    "                 infer_duration_sec = time.time() - infer_start_time; run_results[\"infer_time_sec\"] = infer_duration_sec\n",
    "                 print(f\"  Инференс завершен за {infer_duration_sec:.2f} сек. Предсказаний: {len(predictions)}/{len(test_df)}\")\n",
    "\n",
    "                 if predictions:\n",
    "                     print(f\"  Формирование submission: {current_submission_path.name}\")\n",
    "                     submission_df = pd.DataFrame({'id': test_df['id']}); submission_df['message'] = submission_df['id'].map(predictions).fillna(\"ERROR_MISSING\")\n",
    "                     current_submission_path.unlink(missing_ok=True)\n",
    "                     submission_df.to_csv(current_submission_path, index=False); print(f\"  Submission сохранен.\"); mlflow.log_artifact(str(current_submission_path), artifact_path=\"submission\")\n",
    "                 else: print(\"  Предсказания не сгенерированы.\"); mlflow.set_tag(\"submission_generated\", \"False\")\n",
    "            except Exception as e_infer: print(f\"  !!! Ошибка инференса: {e_infer} !!!\"); traceback.print_exc(limit=2); run_results[\"error\"] = f\"Inference Error: {e_infer}\"; run_results[\"status\"] = \"failed_inference\"; mlflow.set_tag(\"status\", \"failed_inference\")\n",
    "            finally:\n",
    "                 try: del inference_model_instance\n",
    "                 except NameError: pass\n",
    "                 try: del test_loader_infer\n",
    "                 except NameError: pass\n",
    "                 try: del infer_test_dataset\n",
    "                 except NameError: pass\n",
    "                 if 'logits_infer' in locals(): del logits_infer\n",
    "                 if 'features_infer' in locals(): del features_infer\n",
    "                 if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "        else: print(\"  Инференс пропущен (лучшая модель не сохранена).\"); run_results[\"status\"] += \"_no_inference\"; mlflow.set_tag(\"inference_skipped\", \"True\")\n",
    "\n",
    "    except Exception as e_main: print(f\"!!! КРИТИЧЕСКАЯ ОШИБКА в {run_suffix}: {e_main} !!!\"); traceback.print_exc(); run_results[\"error\"] = str(e_main); run_results[\"status\"] = \"failed_critical\";\n",
    "    try: mlflow.set_tag(\"status\", \"failed_critical\"); mlflow.set_tag(\"error\", str(e_main)[:250])\n",
    "    except: pass\n",
    "\n",
    "    finally:\n",
    "        try: del model\n",
    "        except NameError: pass\n",
    "        try: del criterion\n",
    "        except NameError: pass\n",
    "        try: del optimizer\n",
    "        except NameError: pass\n",
    "        try: del scheduler\n",
    "        except NameError: pass\n",
    "        if 'full_dataset' in locals(): del full_dataset\n",
    "        if 'train_subset' in locals(): del train_subset\n",
    "        if 'val_subset' in locals(): del val_subset\n",
    "        if 'train_loader' in locals(): del train_loader\n",
    "        if 'val_loader' in locals(): del val_loader\n",
    "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "        print(f\"{'='*20} Завершение: {run_suffix} {'='*20}\\n\")\n",
    "    return run_results\n",
    "\n",
    "print(\"--- Функция run_training_pipeline (Исправлена заглушка MLflow) определена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 13: Основной Цикл Обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 00:45:08 INFO mlflow.tracking.fluent: Experiment with name 'Morse_Final_ClsDouble_Test' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 13: Запуск Цикла Обучения (Тест Double Classifier для лучшей модели 3x512) ---\n",
      "\n",
      "1. Определение конфигурации для теста Double Classifier...\n",
      "\n",
      "Конфигурация для запуска (1):\n",
      "  - BestModel_3x512_ClsDouble: RNN=3x512, Drop=0.2, Cls=double, Trim OFF\n",
      "\n",
      "2. Копирование базовой конфигурации обучения...\n",
      "\n",
      "--- Начало цикла запусков (1 итерация) ---\n",
      "MLflow эксперимент: 'Morse_Final_ClsDouble_Test'\n",
      "\n",
      "--- Попытка завершить ЛЮБОЙ активный MLflow run перед циклом ---\n",
      "--- Активный MLflow run не обнаружен. ---\n",
      "\n",
      "========== Запуск 1/1: Конфигурация 'BestModel_3x512_ClsDouble' ==========\n",
      "  Аудио параметры: {\"sample_rate\": 8000, \"frame_length_rms\": 128, \"hop_length_rms\": 64, \"apply_filter\": false, \"apply_trimming\": false, \"trim_top_db\": 30}\n",
      "  Параметры модели: {\"input_feature_dim\": 2, \"cnn_out_channels\": [64, 128, 128], \"cnn_kernel_size\": 9, \"cnn_stride\": 1, \"cnn_padding\": \"same\", \"cnn_pool_kernel\": 2, \"rnn_hidden_size\": 512, \"rnn_num_layers\": 3, \"dropout_rate\": 0.2, \"activation_fn\": \"GELU\", \"classifier_type\": \"double\"}\n",
      "------------------------------\n",
      "--- Проверка/Завершение MLflow run перед итерацией 1... ---\n",
      "--- Активный run не найден перед итерацией 1. Продолжаем. ---\n",
      "--- Вызов run_training_pipeline для конфигурации 'BestModel_3x512_ClsDouble' ---\n",
      "\n",
      "==================== Запуск: _BestModel_3x512_ClsDouble ====================\n",
      "Audio Config: {\"sample_rate\": 8000, \"frame_length_rms\": 128, \"hop_length_rms\": 64, \"apply_filter\": false, \"apply_trimming\": false, \"trim_top_db\": 30}\n",
      "Model Config: {\"input_feature_dim\": 2, \"cnn_out_channels\": [64, 128, 128], \"cnn_kernel_size\": 9, \"cnn_stride\": 1, \"cnn_padding\": \"same\", \"cnn_pool_kernel\": 2, \"rnn_hidden_size\": 512, \"rnn_num_layers\": 3, \"dropout_rate\": 0.2, \"activation_fn\": \"GELU\", \"classifier_type\": \"double\"}\n",
      "Train Config: {\"batch_size\": 8, \"num_workers\": 0, \"num_epochs\": 10, \"learning_rate\": 0.0003, \"div_factor\": 3.0, \"final_div_factor\": 100, \"weight_decay\": 0.0001, \"optimizer\": \"AdamW\", \"early_stopping_patience\": 7, \"gradient_clip_norm\": 2.0, \"validation_split_ratio\": 0.1, \"base_seed\": 42, \"batches_per_epoch\": 1000}\n",
      "  Пути: Model=model_SR8k_F128h64_FiltOFF_CNN128_RNN3x512_GELU_Clsdouble_LR3e-04_WD1e-04_BestModel_3x512_ClsDouble.pth, Params=params_SR8k_F128h64_FiltOFF_CNN128_RNN3x512_GELU_Clsdouble_LR3e-04_WD1e-04_BestModel_3x512_ClsDouble.json, Sub=submission_greedy_SR8k_F128h64_FiltOFF_CNN128_RNN3x512_GELU_Clsdouble_LR3e-04_WD1e-04_BestModel_3x512_ClsDouble.csv\n",
      "Установлен SEED = 42\n",
      "\n",
      "1. Подготовка данных...\n",
      "MorseDataset: is_train=True, SR=8000Hz, Trimming OFF\n",
      "  Признаки: RMS(f=128, h=64) + Delta(standard)\n",
      "  Нормализация: Z-Score\n",
      "  Данные готовы: Train=27000 (3375 батчей), Val=3000 (188 батчей).\n",
      "\n",
      "2. Инициализация компонентов...\n",
      "Архитектура MorseRecognizer:\n",
      "  CNN: 3 layers, OutChannels=[64, 128, 128], Kernel=9, Pool=2\n",
      "       Output Dim=128, Time Reduction Factor=8.0x\n",
      "  RNN: BiGRU, Layers=3, Hidden Size=512\n",
      "       Output Dim=1024\n",
      "  Activation: GELU\n",
      "  Classifier: DoubleLinear(1024->1024->45)\n",
      "  Dropout: 0.2\n",
      "  Model, Loss, Optimizer (AdamW) готовы.\n",
      "  Scheduler OneCycleLR создан (total_steps=10000, div_factor=3.0, final_div_factor=100).\n",
      "\n",
      "3. Запуск цикла обучения...\n",
      "  MLflow Run ID: 4de5ccc507b8483c896805df0f25906d\n",
      "\n",
      "--- Эпоха 1/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f78054764548f787be72ec3d43f5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 1/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5644f2461b0491782f2400b2c61832f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 1: Train Loss=4.2909, Train Lev=8.9002, Val Loss=3.9788, Val Lev=8.8077\n",
      "  ✨ Val Lev улучшился: inf -> 8.8077. Сохранение...\n",
      "\n",
      "--- Эпоха 2/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06108d1ff3d34d7b8d2a480c079f9c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 2/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dfc2385abc4e2abf5aac5ed4617153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 2: Train Loss=2.2848, Train Lev=5.2150, Val Loss=0.5574, Val Lev=1.2030\n",
      "  ✨ Val Lev улучшился: 8.8077 -> 1.2030. Сохранение...\n",
      "\n",
      "--- Эпоха 3/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019bf433e23043598b6184fc61fd04e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 3/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5118ec7262b8493886bfb217111cf55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 3: Train Loss=0.5621, Train Lev=1.2299, Val Loss=0.4689, Val Lev=0.9953\n",
      "  ✨ Val Lev улучшился: 1.2030 -> 0.9953. Сохранение...\n",
      "\n",
      "--- Эпоха 4/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c552219896b84b04a4a72f1059297142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 4/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28db90ab5ae94d979d347401ad8ba2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 4: Train Loss=0.4847, Train Lev=1.0656, Val Loss=0.4056, Val Lev=0.9353\n",
      "  ✨ Val Lev улучшился: 0.9953 -> 0.9353. Сохранение...\n",
      "\n",
      "--- Эпоха 5/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896b386f8bd64d63b9fc231272e0a9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 5/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f322aeff384a9aaf45d74b9036ed61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Итоги Эпохи 5: Train Loss=0.4301, Train Lev=0.9759, Val Loss=0.3829, Val Lev=0.8763\n",
      "  ✨ Val Lev улучшился: 0.9353 -> 0.8763. Сохранение...\n",
      "\n",
      "--- Эпоха 6/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acedd867413f4e2d9fc9d287d43c66c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 6/10 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[617], line 103\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Вызов run_training_pipeline для конфигурации \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m     run_result_dict \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43maudio_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_audio_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_model_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_train_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Короткие эпохи\u001b[39;49;00m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_train_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEXTRACTED_AUDIO_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchar_to_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchar_to_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_to_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_to_char\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblank_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBLANK_IDX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPAD_IDX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes_ctc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CLASSES_CTC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_run_suffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_filename_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBASE_FILENAME_SUFFIX_FINAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Используем тот же базовый суффикс\u001b[39;49;00m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmlflow_experiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMLFLOW_EXPERIMENT_NAME\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Успешное завершение run_training_pipeline для \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e_pipeline:\n",
      "Cell \u001b[1;32mIn[616], line 146\u001b[0m, in \u001b[0;36mrun_training_pipeline\u001b[1;34m(audio_config, model_config, train_config, full_train_df, test_df, audio_dir, base_output_dir, char_to_index, index_to_char, blank_idx, pad_idx, num_classes_ctc, device, run_suffix, base_filename_suffix, seed, mlflow_experiment_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Эпоха \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m(): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mФункция train_epoch не определена!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 146\u001b[0m avg_train_loss, avg_train_lev, avg_epoch_lr \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_to_char\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblank_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgradient_clip_norm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatches_per_epoch_run\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidate_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m(): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mФункция validate_epoch не определена!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    148\u001b[0m avg_val_loss, avg_val_lev, _ \u001b[38;5;241m=\u001b[39m validate_epoch( model, val_loader, criterion, device, index_to_char, blank_idx, pad_idx )\n",
      "Cell \u001b[1;32mIn[614], line 34\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, dataloader, criterion, optimizer, scheduler, device, epoch_num, total_epochs, index_to_char_map, blank_idx, pad_idx, grad_clip_norm, batches_per_epoch)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_batches_to_process \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     33\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(iterator, total\u001b[38;5;241m=\u001b[39mnum_batches_to_process, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЭпоха \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [Тренировка]\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     features, targets, feature_lengths, target_lengths \u001b[38;5;241m=\u001b[39m batch_data\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[609], line 116\u001b[0m, in \u001b[0;36mMorseDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    114\u001b[0m original_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 116\u001b[0m     waveform_np, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m waveform_np \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m waveform_np\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): Файл пуст.\u001b[39m\u001b[38;5;124m\"\u001b[39m); \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (file_id \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    118\u001b[0m     original_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(waveform_np)\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\librosa\\core\\audio.py:222\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    219\u001b[0m         frame_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# Load the target number of frames, and transpose to match librosa form\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43msf_desc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_duration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y, sr_native\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\soundfile.py:942\u001b[0m, in \u001b[0;36mSoundFile.read\u001b[1;34m(self, frames, dtype, always_2d, fill_value, out)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frames \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m frames \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(out):\n\u001b[0;32m    941\u001b[0m         frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[1;32m--> 942\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_array_io\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m>\u001b[39m frames:\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\soundfile.py:1394\u001b[0m, in \u001b[0;36mSoundFile._array_io\u001b[1;34m(self, action, array, frames)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mitemsize \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39msizeof(ctype)\n\u001b[0;32m   1393\u001b[0m cdata \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mcast(ctype \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m, array\u001b[38;5;241m.\u001b[39m__array_interface__[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cdata_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vasja\\anaconda3\\envs\\morse_env\\lib\\site-packages\\soundfile.py:1403\u001b[0m, in \u001b[0;36mSoundFile._cdata_io\u001b[1;34m(self, action, data, ctype, frames)\u001b[0m\n\u001b[0;32m   1401\u001b[0m     curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m   1402\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_snd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m action \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m ctype)\n\u001b[1;32m-> 1403\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1404\u001b[0m _error_check(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_errorcode)\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 13: Цикл Запуска Обучения (Тест Double Classifier для лучшей модели 3x512)\n",
    "# =============================================================================\n",
    "print(f\"--- Ячейка 13: Запуск Цикла Обучения (Тест Double Classifier для лучшей модели 3x512) ---\")\n",
    "\n",
    "import time, pandas as pd, numpy as np, json, random, copy, traceback\n",
    "from pathlib import Path; import torch\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Проверка глобальных зависимостей ---\n",
    "# Убедимся, что все нужное есть, включая BASE_FILENAME_SUFFIX_FINAL\n",
    "required_globals_loop = [ 'train_df', 'test_df', 'EXTRACTED_AUDIO_DIR', 'char_to_index', 'index_to_char', 'BLANK_IDX', 'PAD_IDX', 'NUM_CLASSES_CTC', 'device', 'OUTPUT_DIR', 'BASE_FILENAME_SUFFIX_FINAL', 'SEED', 'run_training_pipeline', 'AUDIO_CONFIG', 'MODEL_CONFIG_BASE', 'TRAIN_CONFIG', 'mlflow' ]\n",
    "missing_globals_loop = [v for v in required_globals_loop if v not in globals() or globals().get(v) is None]\n",
    "if missing_globals_loop: raise NameError(f\"Отсутствуют переменные/функции или они None: {missing_globals_loop}\")\n",
    "\n",
    "# ============================================================================\n",
    "# === БЛОК 1: Определение Конфигурации для Теста Double Classifier ===\n",
    "# ============================================================================\n",
    "print(\"\\n1. Определение конфигурации для теста Double Classifier...\")\n",
    "\n",
    "# Используем MODEL_CONFIG_BASE (ЛУЧШУЮ 3x512) как основу\n",
    "configs_to_run = {}\n",
    "audio_configs_to_run = {}\n",
    "\n",
    "# 1. Best Model (3x512) with Double Classifier (Trimming OFF)\n",
    "config_name = \"BestModel_3x512_ClsDouble\"\n",
    "configs_to_run[config_name] = MODEL_CONFIG_BASE.copy()\n",
    "configs_to_run[config_name][\"classifier_type\"] = \"double\" # <--- Ключевое изменение\n",
    "\n",
    "audio_configs_to_run[config_name] = AUDIO_CONFIG.copy()\n",
    "audio_configs_to_run[config_name][\"apply_trimming\"] = False # Trimming выключен\n",
    "\n",
    "print(f\"\\nКонфигурация для запуска ({len(configs_to_run)}):\")\n",
    "m_cfg = configs_to_run[config_name]\n",
    "a_cfg = audio_configs_to_run[config_name]\n",
    "trim_status = f\"Trim ON (db={a_cfg['trim_top_db']})\" if a_cfg['apply_trimming'] else \"Trim OFF\"\n",
    "print(f\"  - {config_name}: RNN={m_cfg['rnn_num_layers']}x{m_cfg['rnn_hidden_size']}, Drop={m_cfg['dropout_rate']}, Cls={m_cfg['classifier_type']}, {trim_status}\")\n",
    "# ============================================================================\n",
    "# === КОНЕЦ БЛОКА 1 ===\n",
    "# ============================================================================\n",
    "\n",
    "# --- 2. Копирование Базовой Конфигурации Обучения ---\n",
    "print(\"\\n2. Копирование базовой конфигурации обучения...\")\n",
    "# Конфиг обучения ФИКСИРОВАН (короткие эпохи)\n",
    "fixed_train_config = TRAIN_CONFIG.copy()\n",
    "\n",
    "# --- 3. Инициализация Списка для Результатов ---\n",
    "all_run_results_list: List[Dict] = []\n",
    "\n",
    "# ============================================================================\n",
    "# === БЛОК 2: Цикл запуска обучения для одной конфигурации ===\n",
    "# ============================================================================\n",
    "print(f\"\\n--- Начало цикла запусков ({len(configs_to_run)} итерация) ---\")\n",
    "overall_start_time = time.time()\n",
    "MLFLOW_EXPERIMENT_NAME = f\"Morse_Final_ClsDouble_Test\" # Новое имя эксперимента\n",
    "print(f\"MLflow эксперимент: '{MLFLOW_EXPERIMENT_NAME}'\")\n",
    "\n",
    "# --- Надежное завершение ЛЮБОГО активного MLflow run перед циклом ---\n",
    "# (Код завершения MLflow run остается таким же)\n",
    "print(\"\\n--- Попытка завершить ЛЮБОЙ активный MLflow run перед циклом ---\")\n",
    "try:\n",
    "    if mlflow.active_run():\n",
    "        active_run_id = mlflow.active_run().info.run_id\n",
    "        print(f\"!!! Обнаружен активный MLflow run ({active_run_id}). Принудительно завершаем... !!!\")\n",
    "        mlflow.end_run(); time.sleep(1)\n",
    "        if mlflow.active_run(): print(\"!!! ПРЕДУПРЕЖДЕНИЕ: MLflow run ВСЕ ЕЩЕ АКТИВЕН! !!!\")\n",
    "        else: print(\"--- Проверка: Активный MLflow run отсутствует. ---\")\n",
    "    else: print(\"--- Активный MLflow run не обнаружен. ---\")\n",
    "except Exception as e_check_run: print(f\"Предупреждение: Ошибка при проверке/завершении активного MLflow run: {e_check_run}\")\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# --- Основной цикл по конфигурациям (теперь только одна) ---\n",
    "for i, config_name in enumerate(configs_to_run.keys()):\n",
    "\n",
    "    current_model_config = configs_to_run[config_name]\n",
    "    current_audio_config = audio_configs_to_run[config_name]\n",
    "\n",
    "    print(f\"\\n{'='*10} Запуск {i+1}/{len(configs_to_run)}: Конфигурация '{config_name}' {'='*10}\")\n",
    "    print(f\"  Аудио параметры: {json.dumps(current_audio_config)}\")\n",
    "    print(f\"  Параметры модели: {json.dumps(current_model_config)}\")\n",
    "    print(f\"{'-'*30}\")\n",
    "\n",
    "    # Формируем суффикс для имен файлов и MLflow run\n",
    "    current_run_suffix = f\"_{config_name.replace(' ', '_')}\"\n",
    "\n",
    "    # === Дополнительная попытка завершить run ПЕРЕД start_run ВНУТРИ цикла ===\n",
    "    # (Код завершения MLflow run остается таким же)\n",
    "    print(f\"--- Проверка/Завершение MLflow run перед итерацией {i+1}... ---\")\n",
    "    try:\n",
    "        if mlflow.active_run():\n",
    "            lingering_run_id = mlflow.active_run().info.run_id\n",
    "            print(f\"!!! ПРЕДУПРЕЖДЕНИЕ: Обнаружен активный run ({lingering_run_id}) ПЕРЕД start_run в итерации {i+1}. Попытка завершения... !!!\")\n",
    "            mlflow.end_run(); time.sleep(0.5)\n",
    "            if mlflow.active_run(): print(f\"!!! ОШИБКА: Run {lingering_run_id} все еще активен! !!!\")\n",
    "            else: print(f\"--- Зависший run {lingering_run_id} успешно завершен внутри цикла. ---\")\n",
    "        else: print(f\"--- Активный run не найден перед итерацией {i+1}. Продолжаем. ---\")\n",
    "    except Exception as e_inner_end: print(f\"Предупреждение: Ошибка при попытке end_run внутри цикла: {e_inner_end}\")\n",
    "    # ======================================================================\n",
    "\n",
    "    # --- Вызов основной функции обучения/инференса ---\n",
    "    try:\n",
    "        print(f\"--- Вызов run_training_pipeline для конфигурации '{config_name}' ---\")\n",
    "        run_result_dict = run_training_pipeline(\n",
    "            audio_config=current_audio_config,\n",
    "            model_config=current_model_config,\n",
    "            train_config=fixed_train_config, # Короткие эпохи\n",
    "            full_train_df=train_df, test_df=test_df, audio_dir=EXTRACTED_AUDIO_DIR, base_output_dir=OUTPUT_DIR,\n",
    "            char_to_index=char_to_index, index_to_char=index_to_char, blank_idx=BLANK_IDX, pad_idx=PAD_IDX, num_classes_ctc=NUM_CLASSES_CTC,\n",
    "            device=device,\n",
    "            run_suffix=current_run_suffix,\n",
    "            base_filename_suffix=BASE_FILENAME_SUFFIX_FINAL, # Используем тот же базовый суффикс\n",
    "            seed=SEED,\n",
    "            mlflow_experiment_name=MLFLOW_EXPERIMENT_NAME\n",
    "        )\n",
    "        print(f\"--- Успешное завершение run_training_pipeline для '{config_name}' ---\")\n",
    "\n",
    "    except Exception as e_pipeline:\n",
    "        print(f\"!!! КРИТИЧЕСКАЯ ОШИБКА ПРИ ВЫЗОВЕ ПАЙПЛАЙНА для '{config_name}' !!!\")\n",
    "        print(f\"Ошибка: {e_pipeline}\"); traceback.print_exc()\n",
    "        run_result_dict = { \"run_suffix\": current_run_suffix, \"status\": \"failed_launch\", \"best_val_lev\": float('inf'),\n",
    "                            \"error\": f\"Pipeline launch error: {e_pipeline}\", \"config_name\": config_name }\n",
    "\n",
    "    run_result_dict['config_name'] = config_name\n",
    "    run_result_dict['trimming_status'] = f\"ON (db={current_audio_config['trim_top_db']})\" if current_audio_config['apply_trimming'] else \"OFF\"\n",
    "    all_run_results_list.append(run_result_dict)\n",
    "\n",
    "    print(f\"--- Завершение обработки Запуска {i+1}/{len(configs_to_run)} ('{config_name}') ---\")\n",
    "\n",
    "# --- Конец цикла запусков ---\n",
    "# ============================================================================\n",
    "# === КОНЕЦ БЛОКА 2 ===\n",
    "# ============================================================================\n",
    "\n",
    "overall_end_time = time.time(); total_duration_hours = (overall_end_time - overall_start_time) / 3600\n",
    "print(f\"\\n--- Цикл запусков завершен за {total_duration_hours:.2f} часов ---\")\n",
    "\n",
    "# ============================================================================\n",
    "# === БЛОК 3: Анализ и вывод итогов ===\n",
    "# ============================================================================\n",
    "print(\"\\n--- Итоги Теста Double Classifier ---\")\n",
    "if not all_run_results_list: print(\"Нет результатов для анализа.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(all_run_results_list)\n",
    "    required_cols = ['config_name', 'trimming_status', 'best_val_lev', 'best_epoch', 'final_train_loss', 'final_val_loss',\n",
    "                     'status', 'train_time_min', 'infer_time_sec', 'error', 'run_suffix', 'mlflow_run_id'] # Убрали пути к файлам для краткости\n",
    "    available_cols = [col for col in required_cols if col in results_df.columns]\n",
    "    results_df = results_df[available_cols]\n",
    "    if 'best_val_lev' in results_df.columns: results_df = results_df.sort_values(by='best_val_lev', ascending=True, na_position='last')\n",
    "    else: print(\"Предупреждение: Колонка 'best_val_lev' отсутствует, сортировка невозможна.\")\n",
    "\n",
    "    pd.set_option('display.max_rows', 100); pd.set_option('display.max_columns', 20);\n",
    "    pd.set_option('display.width', 180); pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "    print(\"\\nСводная таблица результатов:\")\n",
    "    display_cols = ['config_name', 'trimming_status', 'best_val_lev', 'best_epoch', 'status', 'train_time_min', 'error']\n",
    "    display_cols_present = [col for col in display_cols if col in results_df.columns]\n",
    "    display(results_df[display_cols_present].head(len(results_df)))\n",
    "\n",
    "    if 'best_val_lev' in results_df.columns and not results_df.empty:\n",
    "        best_run = results_df.iloc[0]\n",
    "        if pd.notna(best_run['best_val_lev']) and np.isfinite(best_run['best_val_lev']):\n",
    "            print(f\"\\n--- Результат Теста Double Classifier ---\")\n",
    "            best_config_name = best_run.get('config_name', 'N/A')\n",
    "            print(f\"Конфигурация: '{best_config_name}'\")\n",
    "            print(f\"  Best Val Levenshtein: {best_run['best_val_lev']:.4f} (Эпоха {best_run.get('best_epoch', 'N/A')})\")\n",
    "\n",
    "            # Сравнение с предыдущим лучшим результатом (0.726)\n",
    "            previous_best = 0.726\n",
    "            print(f\"\\nСравнение с предыдущим лучшим (Single Classifier, ~{previous_best:.4f}):\")\n",
    "            if best_run['best_val_lev'] < previous_best:\n",
    "                print(f\"  >>> УЛУЧШЕНИЕ! Double Classifier для модели 3x512 работает лучше. <<<\")\n",
    "                print(\"  >>> РЕКОМЕНДАЦИЯ: Использовать эту конфигурацию для финального обучения. <<<\")\n",
    "            elif abs(best_run['best_val_lev'] - previous_best) < 0.005: # Если разница очень мала\n",
    "                 print(f\"  >> Результат очень близок к Single Classifier. Можно выбрать любой вариант или оставить Single для простоты. <<\")\n",
    "            else:\n",
    "                print(f\"  >> Ухудшение. Single Classifier для модели 3x512 остается лучшим вариантом. <<\")\n",
    "                print(\"  >>> РЕКОМЕНДАЦИЯ: Использовать конфигурацию с Single Classifier для финального обучения. <<<\")\n",
    "\n",
    "        else: print(\"\\nНе удалось найти валидный результат.\")\n",
    "    else: print(\"\\nНе удалось определить результат.\")\n",
    "\n",
    "    results_csv_path = OUTPUT_DIR / f\"final_clsdouble_test_results.csv\"\n",
    "    try: results_df.to_csv(results_csv_path, index=False); print(f\"\\nПолные результаты сохранены в CSV: {results_csv_path}\")\n",
    "    except Exception as e: print(f\"\\nНе удалось сохранить результаты в CSV: {e}\")\n",
    "# ============================================================================\n",
    "# === КОНЕЦ БЛОКА 3 ===\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n--- Ячейка 13: Завершена (Тест Double Classifier) ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
