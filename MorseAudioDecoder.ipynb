{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 1: Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 1: Импорты и Базовая Настройка ---\n",
      "\n",
      "--- Статус библиотек ---\n",
      "PyTorch Версия: 2.5.1+cu121\n",
      "LibROSA Версия: 0.11.0\n",
      "SciPy Версия: 1.13.1\n",
      "NumPy Версия: 2.0.2\n",
      "Pandas Версия: 2.2.3\n",
      "Levenshtein Версия: 0.27.1\n",
      "ipywidgets доступен: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 1: Импорты и Базовая Настройка\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 1: Импорты и Базовая Настройка ---\")\n",
    "\n",
    "# --- Базовые библиотеки ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import random\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "import multiprocessing # Оставим на всякий случай\n",
    "\n",
    "# --- Аудио и Сигналы ---\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy\n",
    "import scipy.signal as signal\n",
    "\n",
    "# --- Визуализация и Интерактивность ---\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, Audio, clear_output\n",
    "    IPYWIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Предупреждение: Библиотека ipywidgets не найдена. Интерактивная визуализация (Ячейка 12.4) будет недоступна.\")\n",
    "    IPYWIDGETS_AVAILABLE = False\n",
    "    # Заглушки для работы без ipywidgets\n",
    "    class widgets: VBox = HBox = Dropdown = IntSlider = FloatSlider = Button = Output = Layout = HTML = Label = object\n",
    "    def display(*args, **kwargs): pass\n",
    "    def Audio(*args, **kwargs): pass\n",
    "    def clear_output(*args, **kwargs): pass\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- PyTorch ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# --- Метрики и Утилиты ---\n",
    "import Levenshtein\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Настройка окружения и предупреждений ---\n",
    "# os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0' # Если используется TensorFlow где-то еще\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='TRUE' # Для Matplotlib на некоторых системах\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"The verbose parameter is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"You are using `torch.load` with `weights_only=False`\") # Уберем, т.к. используем True\n",
    "\n",
    "print(\"\\n--- Статус библиотек ---\")\n",
    "print(f\"PyTorch Версия: {torch.__version__}\")\n",
    "print(f\"LibROSA Версия: {librosa.__version__}\")\n",
    "print(f\"SciPy Версия: {scipy.__version__}\")\n",
    "print(f\"NumPy Версия: {np.__version__}\")\n",
    "print(f\"Pandas Версия: {pd.__version__}\")\n",
    "print(f\"Levenshtein Версия: {Levenshtein.__version__}\")\n",
    "print(f\"ipywidgets доступен: {IPYWIDGETS_AVAILABLE}\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 2: Конфигурация и Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 2: Конфигурация и Параметры ---\n",
      "Базовая директория: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\n",
      "Директория для аудио: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\morse_dataset\\morse_dataset\n",
      "Директория для вывода: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\n",
      "\n",
      "Аудио параметры: {\n",
      "  \"sample_rate\": 8000,\n",
      "  \"frame_length_rms\": 384,\n",
      "  \"hop_length_rms\": 96,\n",
      "  \"filter_order\": 5,\n",
      "  \"filter_fmin\": 0,\n",
      "  \"filter_fmax\": 3999,\n",
      "  \"delta_type\": \"standard\",\n",
      "  \"delta_alpha\": 1.0,\n",
      "  \"rms_smoothing_window_size\": 1,\n",
      "  \"delta_ma_smoothing_window_size\": 1\n",
      "}\n",
      "\n",
      "Параметры модели: {\n",
      "  \"input_feature_dim\": 2,\n",
      "  \"cnn_out_channels\": [\n",
      "    64,\n",
      "    128,\n",
      "    128\n",
      "  ],\n",
      "  \"cnn_kernel_size\": 9,\n",
      "  \"cnn_stride\": 1,\n",
      "  \"cnn_padding\": \"same\",\n",
      "  \"cnn_pool_kernel\": 2,\n",
      "  \"rnn_hidden_size\": 256,\n",
      "  \"rnn_num_layers\": 2,\n",
      "  \"dropout_rate\": 0.2,\n",
      "  \"activation_fn\": \"GELU\"\n",
      "}\n",
      "\n",
      "Параметры основного обучения: {\n",
      "  \"batch_size\": 8,\n",
      "  \"num_workers\": 0,\n",
      "  \"num_epochs\": 15,\n",
      "  \"learning_rate\": 0.0003,\n",
      "  \"final_div_factor\": 100,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"optimizer\": \"AdamW\",\n",
      "  \"noise_level\": 0.0,\n",
      "  \"early_stopping_patience\": 7,\n",
      "  \"gradient_clip_norm\": 2.0,\n",
      "  \"validation_split_ratio\": 0.1,\n",
      "  \"base_seed\": 42\n",
      "}\n",
      "\n",
      "Шаблон пути для модели: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04...\n",
      "Финальный путь для модели: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.pth\n",
      "Финальный путь для параметров: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\params_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.json\n",
      "\n",
      "Используемое устройство: cuda\n",
      "  GPU: NVIDIA GeForce GTX 1050 Ti\n",
      "Установлен SEED = 42\n",
      "\n",
      "--- Ячейка 2: Конфигурация завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 2: Конфигурация и Параметры\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 2: Конфигурация и Параметры ---\")\n",
    "\n",
    "SEED = 42 # Фиксируем SEED для воспроизводимости\n",
    "\n",
    "# --- Пути ---\n",
    "BASE_DIR = Path('./').resolve() # Текущая директория ноутбука\n",
    "ZIP_PATH = BASE_DIR / 'morse_dataset.zip' # Путь к архиву\n",
    "AUDIO_DIR_NAME = 'morse_dataset' # Имя папки после распаковки\n",
    "# Путь к папке с аудиофайлами (может отличаться в зависимости от структуры архива)\n",
    "EXTRACTED_AUDIO_DIR = BASE_DIR / AUDIO_DIR_NAME / AUDIO_DIR_NAME\n",
    "TRAIN_CSV_PATH = BASE_DIR / 'train.csv'\n",
    "TEST_CSV_PATH = BASE_DIR / 'test.csv'\n",
    "SAMPLE_SUB_PATH = BASE_DIR / 'sample_submission.csv'\n",
    "OUTPUT_DIR = BASE_DIR / 'output' # Директория для сохранения моделей, параметров, сабмишенов\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True) # Создаем, если не существует\n",
    "\n",
    "print(f\"Базовая директория: {BASE_DIR}\")\n",
    "print(f\"Директория для аудио: {EXTRACTED_AUDIO_DIR}\")\n",
    "print(f\"Директория для вывода: {OUTPUT_DIR}\")\n",
    "\n",
    "# --- Параметры обработки аудио ---\n",
    "AUDIO_CONFIG = {\n",
    "    \"sample_rate\": 8000,        # Частота дискретизации\n",
    "    \"frame_length_rms\": 384,    # Длина окна для RMS (в сэмплах)\n",
    "    \"hop_length_rms\": 96,       # Шаг окна для RMS (в сэмплах)\n",
    "    \"filter_order\": 5,          # Порядок фильтра Баттерворта\n",
    "    \"filter_fmin\": 0,           # Нижняя частота среза (0 = ФНЧ)\n",
    "    \"filter_fmax\": 3999,        # Верхняя частота среза (чуть ниже Найквиста)\n",
    "    \"delta_type\": 'standard',   # Тип расчета дельты (производной)\n",
    "    \"delta_alpha\": 1.0,         # Коэффициент для нелинейных дельт (здесь не используется)\n",
    "    # СГЛАЖИВАНИЕ ОТКЛЮЧЕНО\n",
    "    \"rms_smoothing_window_size\": 1,   # Окно для сглаживания RMS (1 = выкл)\n",
    "    \"delta_ma_smoothing_window_size\": 1, # Окно для сглаживания Дельты (1 = выкл)\n",
    "}\n",
    "# Проверка и корректировка fmax (на всякий случай)\n",
    "nyquist_freq = AUDIO_CONFIG['sample_rate'] / 2.0\n",
    "if AUDIO_CONFIG['filter_fmax'] >= nyquist_freq:\n",
    "    AUDIO_CONFIG['filter_fmax'] = nyquist_freq * 0.999 # Чуть меньше Найквиста\n",
    "    print(f\"Предупреждение: filter_fmax скорректирован до {AUDIO_CONFIG['filter_fmax']:.1f} Гц\")\n",
    "print(f\"\\nАудио параметры: {json.dumps(AUDIO_CONFIG, indent=2)}\")\n",
    "\n",
    "# --- Параметры Модели (CNN + BiGRU) ---\n",
    "MODEL_CONFIG = {\n",
    "    \"input_feature_dim\": 2,             # Входные признаки: RMS + Delta\n",
    "    \"cnn_out_channels\": [64, 128, 128], # Каналы в сверточных слоях\n",
    "    \"cnn_kernel_size\": 9,               # Размер ядра свертки\n",
    "    \"cnn_stride\": 1,                    # Шаг свертки\n",
    "    \"cnn_padding\": 'same',              # Дополнение ('same' сохраняет длину)\n",
    "    \"cnn_pool_kernel\": 2,               # Размер окна Max Pooling (уменьшает время)\n",
    "    \"rnn_hidden_size\": 256,             # Размер скрытого состояния GRU\n",
    "    \"rnn_num_layers\": 2,                # Количество слоев GRU\n",
    "    \"dropout_rate\": 0.2,                # Коэффициент Dropout\n",
    "    \"activation_fn\": \"GELU\"             # Функция активации (GELU или ReLU)\n",
    "}\n",
    "print(f\"\\nПараметры модели: {json.dumps(MODEL_CONFIG, indent=2)}\")\n",
    "\n",
    "# --- Параметры Обучения ---\n",
    "TRAIN_CONFIG = {\n",
    "    \"batch_size\": 8,                    # Размер батча\n",
    "    \"num_workers\": 0,                   # Кол-во потоков для загрузки данных (0 = в осн. потоке)\n",
    "    \"num_epochs\": 15,                   # Максимальное кол-во эпох\n",
    "    \"learning_rate\": 3e-4,              # Макс. LR для OneCycleLR (0.0003)\n",
    "    \"final_div_factor\": 100,  \n",
    "    \"weight_decay\": 1e-4,               # L2 регуляризация (AdamW)\n",
    "    \"optimizer\": \"AdamW\",               # Оптимизатор (AdamW или Adam)\n",
    "    \"noise_level\": 0.0,                 # Уровень шума для аугментации (0.0 = ОТКЛЮЧЕН)\n",
    "    \"early_stopping_patience\": 7,       # Кол-во эпох без улучшения для остановки\n",
    "    \"gradient_clip_norm\": 2.0,          # Макс. норма градиента для клиппинга\n",
    "    \"validation_split_ratio\": 0.1,      # Доля данных для валидации\n",
    "    \"base_seed\": SEED                   # Базовый SEED для воспроизводимости\n",
    "}\n",
    "print(f\"\\nПараметры основного обучения: {json.dumps(TRAIN_CONFIG, indent=2)}\")\n",
    "\n",
    "# --- Калибровки (Отключены) ---\n",
    "CALIBRATION_CONFIG = { \"enabled\": False }; BAND_CALIBRATION_CONFIG = { \"enabled\": False }\n",
    "\n",
    "# --- Специальные Токены и Глобальные Переменные ---\n",
    "PAD_TOKEN = '<pad>'   # Токен для дополнения последовательностей\n",
    "BLANK_TOKEN = '_'     # CTC Blank токен\n",
    "PAD_IDX = -1          # Индекс PAD (будет определен в Ячейке 4)\n",
    "BLANK_IDX = -1        # Индекс BLANK (будет определен в Ячейке 4)\n",
    "NUM_CLASSES_CTC = -1  # Количество классов для CTC (вкл. BLANK, будет определено в Ячейке 4)\n",
    "char_to_index = {}    # Словарь: символ -> индекс\n",
    "index_to_char = {}    # Словарь: индекс -> символ\n",
    "\n",
    "# --- Формирование Имен Файлов для Сохранения ---\n",
    "# !!! ВАЖНО: Пересчитаем пути, т.к. LR в конфиге изменился !!!\n",
    "rms_w = AUDIO_CONFIG.get('rms_smoothing_window_size', 1)\n",
    "delta_w = AUDIO_CONFIG.get('delta_ma_smoothing_window_size', 1)\n",
    "rms_smooth_suffix = f\"_SmoothRMSMA{rms_w}\" if rms_w > 1 else \"\"\n",
    "delta_smooth_suffix = f\"_SmoothDeltaMA{delta_w}\" if delta_w > 1 else \"\"\n",
    "delta_type_suffix = f\"_Delta{AUDIO_CONFIG['delta_type']}\"\n",
    "\n",
    "# Основной суффикс, описывающий конфигурацию\n",
    "BASE_FILENAME_SUFFIX_FINAL = f\"Filt{int(AUDIO_CONFIG['filter_fmin'])}-{int(AUDIO_CONFIG['filter_fmax'])}Hz_\" \\\n",
    "                             f\"RMS{AUDIO_CONFIG['frame_length_rms']}h{AUDIO_CONFIG['hop_length_rms']}_\" \\\n",
    "                             f\"CNNk{MODEL_CONFIG['cnn_kernel_size']}p{MODEL_CONFIG['cnn_pool_kernel']}_\" \\\n",
    "                             f\"RNN{MODEL_CONFIG['rnn_hidden_size']}x{MODEL_CONFIG['rnn_num_layers']}_\" \\\n",
    "                             f\"Feat{MODEL_CONFIG['input_feature_dim']}_\" \\\n",
    "                             f\"LR{TRAIN_CONFIG['learning_rate']:.0e}_\" \\\n",
    "                             f\"WD{TRAIN_CONFIG['weight_decay']:.0e}\"\n",
    "\n",
    "# Собираем финальное имя\n",
    "FINAL_SUFFIX = f\"{delta_type_suffix}{rms_smooth_suffix}{delta_smooth_suffix}\" # Суффиксы сглаживания пустые\n",
    "MODEL_SAVE_PATH_TEMPLATE_FINAL = str(OUTPUT_DIR / f\"model_{BASE_FILENAME_SUFFIX_FINAL}\")\n",
    "PARAMS_SAVE_PATH_TEMPLATE_FINAL = str(OUTPUT_DIR / f\"params_{BASE_FILENAME_SUFFIX_FINAL}\")\n",
    "\n",
    "BEST_MODEL_PATH = Path(f\"{MODEL_SAVE_PATH_TEMPLATE_FINAL}{FINAL_SUFFIX}.pth\")\n",
    "PARAMS_PATH = Path(f\"{PARAMS_SAVE_PATH_TEMPLATE_FINAL}{FINAL_SUFFIX}.json\")\n",
    "\n",
    "print(f\"\\nШаблон пути для модели: {MODEL_SAVE_PATH_TEMPLATE_FINAL}...\")\n",
    "print(f\"Финальный путь для модели: {BEST_MODEL_PATH}\")\n",
    "print(f\"Финальный путь для параметров: {PARAMS_PATH}\")\n",
    "\n",
    "# --- Выбор устройства ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nИспользуемое устройство: {device}\")\n",
    "if device.type == 'cuda': print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# --- Установка SEED ---\n",
    "def set_seed(seed_value):\n",
    "    \"\"\"Устанавливает SEED для всех необходимых библиотек.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        # Дополнительные настройки для детерминизма CUDA (могут замедлить)\n",
    "        # torch.backends.cudnn.deterministic = True\n",
    "        # torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Установлен SEED = {seed_value}\")\n",
    "\n",
    "set_seed(TRAIN_CONFIG['base_seed'])\n",
    "\n",
    "print(\"\\n--- Ячейка 2: Конфигурация завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 3: Загрузка данных и распаковка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 3: Загрузка метаданных и распаковка аудио ---\n",
      "Папка с аудио C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\morse_dataset\\morse_dataset уже существует, распаковка пропущена.\n",
      "\n",
      "Загрузка CSV файлов...\n",
      "  Train DataFrame: Загружено 30000 записей.\n",
      "  Test DataFrame: Загружено 5000 записей.\n",
      "  Sample Submission DataFrame: Загружено 5000 записей.\n",
      "\n",
      "Выборочная проверка наличия аудиофайлов...\n",
      "  Пример файла (1.opus) найден: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\morse_dataset\\morse_dataset\\1.opus\n",
      "\n",
      "--- Ячейка 3: Загрузка данных завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 3: Загрузка Данных и Распаковка\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 3: Загрузка метаданных и распаковка аудио ---\")\n",
    "\n",
    "# --- Проверка и Распаковка Архива ---\n",
    "if not EXTRACTED_AUDIO_DIR.exists():\n",
    "    print(f\"Папка с аудио ({EXTRACTED_AUDIO_DIR}) не найдена.\")\n",
    "    if ZIP_PATH.is_file():\n",
    "        print(f\"Распаковка архива {ZIP_PATH.name} в {BASE_DIR}...\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "                zip_ref.extractall(BASE_DIR)\n",
    "            print(\"Архив успешно распакован.\")\n",
    "            # Дополнительная проверка, если структура архива отличается\n",
    "            if not EXTRACTED_AUDIO_DIR.is_dir():\n",
    "                 possible_audio_dir = BASE_DIR / ZIP_PATH.stem # Имя архива без .zip\n",
    "                 if possible_audio_dir.is_dir():\n",
    "                     print(f\"Предупреждение: Ожидаемая папка {EXTRACTED_AUDIO_DIR} не найдена, но найдена {possible_audio_dir}. Используем ее.\")\n",
    "                     EXTRACTED_AUDIO_DIR = possible_audio_dir\n",
    "                 else:\n",
    "                     raise FileNotFoundError(f\"Не удалось найти папку с аудио ({EXTRACTED_AUDIO_DIR} или {possible_audio_dir}) после распаковки.\")\n",
    "            else:\n",
    "                print(f\"Найдена папка с аудио: {EXTRACTED_AUDIO_DIR}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Критическая ошибка при распаковке: {e}\")\n",
    "            raise SystemExit(\"Остановка: Ошибка распаковки.\")\n",
    "    else:\n",
    "        print(f\"Критическая ошибка: Архив {ZIP_PATH} не найден и папка {EXTRACTED_AUDIO_DIR} отсутствует.\")\n",
    "        raise SystemExit(\"Остановка: Нет исходных данных.\")\n",
    "else:\n",
    "    print(f\"Папка с аудио {EXTRACTED_AUDIO_DIR} уже существует, распаковка пропущена.\")\n",
    "\n",
    "# --- Загрузка CSV Файлов ---\n",
    "print(\"\\nЗагрузка CSV файлов...\")\n",
    "train_df = None; test_df = None; sample_sub_df = None # Инициализация\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    print(f\"  Train DataFrame: Загружено {len(train_df)} записей.\")\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "    print(f\"  Test DataFrame: Загружено {len(test_df)} записей.\")\n",
    "    try:\n",
    "        sample_sub_df = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "        print(f\"  Sample Submission DataFrame: Загружено {len(sample_sub_df)} записей.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  Предупреждение: Файл {SAMPLE_SUB_PATH.name} не найден.\")\n",
    "        sample_sub_df = None # Продолжаем без него\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Критическая ошибка: Не найден CSV файл: {e}. Проверьте пути.\")\n",
    "    raise SystemExit(\"Остановка: Ошибка загрузки CSV.\")\n",
    "except Exception as e:\n",
    "    print(f\"Критическая ошибка при чтении CSV: {e}\")\n",
    "    raise SystemExit(\"Остановка: Ошибка загрузки CSV.\")\n",
    "\n",
    "# --- Выборочная проверка наличия аудиофайлов ---\n",
    "print(\"\\nВыборочная проверка наличия аудиофайлов...\")\n",
    "if train_df is not None and not train_df.empty and EXTRACTED_AUDIO_DIR.is_dir():\n",
    "    example_file_id = train_df['id'].iloc[0]\n",
    "    example_file_path = EXTRACTED_AUDIO_DIR / example_file_id\n",
    "    if example_file_path.is_file():\n",
    "        print(f\"  Пример файла ({example_file_id}) найден: {example_file_path}\")\n",
    "    else:\n",
    "        print(f\"  !!! ПРЕДУПРЕЖДЕНИЕ: Пример файла ({example_file_id}) НЕ найден: {example_file_path} !!!\")\n",
    "        # Пробуем без вложенной папки\n",
    "        example_file_path_alt = BASE_DIR / AUDIO_DIR_NAME / example_file_id\n",
    "        if example_file_path_alt.is_file():\n",
    "             print(f\"  Найден альтернативный путь: {example_file_path_alt}. Обновляем EXTRACTED_AUDIO_DIR.\")\n",
    "             EXTRACTED_AUDIO_DIR = BASE_DIR / AUDIO_DIR_NAME\n",
    "        else:\n",
    "             print(\"  Альтернативный путь тоже не найден. Проверьте структуру папок.\")\n",
    "\n",
    "elif not EXTRACTED_AUDIO_DIR.is_dir():\n",
    "     print(f\"  Проверка аудиофайлов невозможна: Папка {EXTRACTED_AUDIO_DIR} не существует.\")\n",
    "else: print(\"  Проверка аудиофайлов невозможна (train_df пуст?).\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Ячейка 3: Загрузка данных завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 4: Создание словаря символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 4: Создание словаря символов ---\n",
      "Найдено уникальных символов: 44\n",
      "Размер словаря (вкл. BLANK, PAD): 46\n",
      "Индекс BLANK ('_'): 44\n",
      "Индекс PAD ('<pad>'): 45\n",
      "Количество классов для CTC Loss: 45\n",
      "\n",
      "--- Ячейка 4: Создание словаря завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 4: Создание Словаря Символов\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 4: Создание словаря символов ---\")\n",
    "\n",
    "if train_df is None or 'message' not in train_df.columns:\n",
    "    raise SystemExit(\"Остановка: train_df не загружен или нет колонки 'message'.\")\n",
    "\n",
    "try:\n",
    "    # Собираем все уникальные символы из обучающей выборки\n",
    "    all_texts = train_df['message'].fillna('').astype(str)\n",
    "    unique_chars = sorted(list(set(char for text in all_texts for char in text)))\n",
    "\n",
    "    # Создаем словари\n",
    "    char_to_index = {char: i for i, char in enumerate(unique_chars)}\n",
    "    index_to_char = {i: char for char, i in char_to_index.items()}\n",
    "\n",
    "    # Добавляем специальные токены BLANK и PAD\n",
    "    BLANK_IDX = len(char_to_index) # BLANK идет следующим после символов\n",
    "    PAD_IDX = len(char_to_index) + 1 # PAD идет после BLANK\n",
    "    char_to_index[BLANK_TOKEN] = BLANK_IDX\n",
    "    char_to_index[PAD_TOKEN] = PAD_IDX\n",
    "    index_to_char[BLANK_IDX] = BLANK_TOKEN\n",
    "    index_to_char[PAD_IDX] = PAD_TOKEN\n",
    "\n",
    "    # Количество классов для выхода модели (включая BLANK)\n",
    "    NUM_CLASSES_CTC = BLANK_IDX + 1\n",
    "\n",
    "    print(f\"Найдено уникальных символов: {len(unique_chars)}\")\n",
    "    print(f\"Размер словаря (вкл. BLANK, PAD): {len(char_to_index)}\")\n",
    "    print(f\"Индекс BLANK ('{BLANK_TOKEN}'): {BLANK_IDX}\")\n",
    "    print(f\"Индекс PAD ('{PAD_TOKEN}'): {PAD_IDX}\")\n",
    "    print(f\"Количество классов для CTC Loss: {NUM_CLASSES_CTC}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Критическая ошибка при создании словаря: {e}\")\n",
    "    traceback.print_exc()\n",
    "    raise SystemExit(\"Остановка: Ошибка создания словаря.\")\n",
    "\n",
    "# Проверка корректности создания\n",
    "if not char_to_index or not index_to_char or BLANK_IDX == -1 or PAD_IDX == -1 or NUM_CLASSES_CTC <= 0:\n",
    "    raise SystemExit(\"Остановка: Ошибка инициализации словаря.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 4: Создание словаря завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 5: Класс MorseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 5: Определение класса MorseDataset ---\n",
      "\n",
      "--- Ячейка 5: Определение MorseDataset завершено (аннотация типов исправлена) ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 5: Класс MorseDataset (ИСПРАВЛЕННАЯ АННОТАЦИЯ ТИПОВ)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 5: Определение класса MorseDataset ---\")\n",
    "\n",
    "# Импорты...\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import scipy.signal as signal\n",
    "import traceback\n",
    "# !!! ДОБАВЛЕН ИМПОРТ Union !!!\n",
    "from typing import Union\n",
    "\n",
    "# Проверка глобальных переменных\n",
    "if 'BLANK_IDX' not in globals() or BLANK_IDX == -1 or 'PAD_IDX' not in globals() or PAD_IDX == -1:\n",
    "     raise ValueError(\"Глобальные переменные BLANK_IDX или PAD_IDX не инициализированы.\")\n",
    "if 'AUDIO_CONFIG' not in globals() or not AUDIO_CONFIG:\n",
    "     raise ValueError(\"Глобальная переменная AUDIO_CONFIG не определена.\")\n",
    "if 'TRAIN_CONFIG' not in globals() or not TRAIN_CONFIG:\n",
    "     raise ValueError(\"Глобальная переменная TRAIN_CONFIG не определена.\")\n",
    "if 'MODEL_CONFIG' not in globals() or not MODEL_CONFIG: # Добавим проверку, т.к. нужен input_feature_dim\n",
    "     raise ValueError(\"Глобальная переменная MODEL_CONFIG не определена.\")\n",
    "\n",
    "class MorseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет для азбуки Морзе. Обработка: Фильтр -> RMS -> Delta.\n",
    "    Сглаживание и зашумление отключены. Исправлена аннотация типов.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe: pd.DataFrame, audio_dir: Path, char_to_index: dict,\n",
    "                 audio_config: dict, model_input_feature_dim: int,\n",
    "                 train_config: dict, is_train: bool = True):\n",
    "\n",
    "        if not isinstance(dataframe, pd.DataFrame): raise TypeError(\"df\")\n",
    "        if not isinstance(audio_dir, Path): raise TypeError(\"audio_dir\")\n",
    "        if not isinstance(char_to_index, dict): raise TypeError(\"char_to_index\")\n",
    "        if not isinstance(audio_config, dict): raise TypeError(\"audio_config\")\n",
    "        if not isinstance(train_config, dict): raise TypeError(\"train_config\")\n",
    "\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.audio_dir = audio_dir; self.char_to_index = char_to_index; self.is_train = is_train\n",
    "        self.audio_config = audio_config; self.train_config = train_config\n",
    "        self.expected_feature_dim = model_input_feature_dim\n",
    "\n",
    "        # Параметры аудио\n",
    "        self.sample_rate = self.audio_config['sample_rate']\n",
    "        self.frame_length_rms = self.audio_config['frame_length_rms']; self.hop_length_rms = self.audio_config['hop_length_rms']\n",
    "        self.filter_order = self.audio_config['filter_order']; self.filter_fmin = self.audio_config['filter_fmin']; self.filter_fmax = self.audio_config['filter_fmax']\n",
    "        self.delta_type = self.audio_config.get('delta_type', 'standard'); self.delta_alpha = self.audio_config.get('delta_alpha', 1.0)\n",
    "        self.rms_smoothing_window = self.audio_config.get('rms_smoothing_window_size', 1)\n",
    "        self.delta_ma_smoothing_window = self.audio_config.get('delta_ma_smoothing_window_size', 1)\n",
    "        self.noise_level = self.train_config.get('noise_level', 0) if self.is_train else 0\n",
    "\n",
    "        # Проверки\n",
    "        self.nyquist = self.sample_rate / 2.0\n",
    "        if self.filter_fmax >= self.nyquist: self.filter_fmax = self.nyquist * 0.999\n",
    "        if 'id' not in self.dataframe.columns: raise ValueError(\"Нет колонки 'id'.\")\n",
    "        if self.is_train and 'message' not in self.dataframe.columns: raise ValueError(\"Нет колонки 'message'.\")\n",
    "\n",
    "        rms_smooth_status = \"Отключено\" if self.rms_smoothing_window <= 1 else f\"Среднее(vp {self.rms_smoothing_window})\"\n",
    "        delta_smooth_status = \"Отключено\" if self.delta_ma_smoothing_window <= 1 else f\"Среднее(vp {self.delta_ma_smoothing_window})\"\n",
    "        noise_status = \"Отключен\" if self.noise_level == 0 else f\"Включен ({self.noise_level:.3f})\"\n",
    "        print(f\"MorseDataset создан: is_train={self.is_train}, delta_type='{self.delta_type}', \"\n",
    "              f\"rms_smooth={rms_smooth_status}, delta_smooth={delta_smooth_status}, \"\n",
    "              f\"noise_level={noise_status}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def _apply_filter(self, waveform_np: np.ndarray) -> np.ndarray:\n",
    "        # (Код без изменений)\n",
    "        if not isinstance(waveform_np, np.ndarray) or waveform_np.ndim != 1: return waveform_np\n",
    "        f_min = self.filter_fmin\n",
    "        f_max = min(self.filter_fmax, self.nyquist * 0.999)\n",
    "        is_lowcut_needed = f_min > 1e-3; is_highcut_needed = f_max < (self.nyquist * 0.995)\n",
    "        if not is_lowcut_needed and not is_highcut_needed: return waveform_np.astype(np.float32)\n",
    "        try:\n",
    "            if is_lowcut_needed and is_highcut_needed: ftype, freqs = 'bandpass', [f_min, f_max]\n",
    "            elif is_lowcut_needed: ftype, freqs = 'highpass', f_min\n",
    "            else: ftype, freqs = 'lowpass', f_max\n",
    "            if isinstance(freqs, list) and freqs[0] >= freqs[1]: return waveform_np.astype(np.float32)\n",
    "            sos = signal.butter(self.filter_order, freqs, btype=ftype, fs=self.sample_rate, output='sos')\n",
    "            return signal.sosfiltfilt(sos, waveform_np).astype(np.float32)\n",
    "        except ValueError as ve: print(f\"WARNING: Ошибка ValueError при фильтрации: {ve}.\"); return waveform_np.astype(np.float32)\n",
    "        except Exception as e: print(f\"WARNING: Неизвестная ошибка фильтрации: {e}.\"); traceback.print_exc(limit=1); return waveform_np.astype(np.float32)\n",
    "\n",
    "    def _normalize_feature(self, feature_array: np.ndarray) -> np.ndarray:\n",
    "        # (Код без изменений)\n",
    "        epsilon = 1e-6; mean = np.mean(feature_array); std = np.std(feature_array)\n",
    "        return (feature_array - mean) / (std + epsilon)\n",
    "\n",
    "    # !!! ИЗМЕНЕНА АННОТАЦИЯ ТИПА ВОЗВРАТА !!!\n",
    "    def _calculate_features(self, waveform_np: np.ndarray, file_id_for_log: str = \"N/A\") -> Union[torch.Tensor, None]:\n",
    "        \"\"\"\n",
    "        Вычисляет признаки: Фильтр -> RMS -> Delta -> Норм.\n",
    "        Сглаживание отключено. Возвращает None при критической ошибке.\n",
    "        \"\"\"\n",
    "        empty_tensor = torch.empty((self.expected_feature_dim, 0), dtype=torch.float32)\n",
    "        if not isinstance(waveform_np, np.ndarray) or waveform_np.size == 0:\n",
    "            return empty_tensor\n",
    "\n",
    "        try:\n",
    "            # 1. Фильтрация\n",
    "            filtered_waveform = self._apply_filter(waveform_np)\n",
    "            if filtered_waveform.size == 0: return empty_tensor\n",
    "\n",
    "            # 2. Расчет RMS\n",
    "            rms_envelope_raw = librosa.feature.rms(y=filtered_waveform, frame_length=self.frame_length_rms, hop_length=self.hop_length_rms, center=True, pad_mode='reflect')[0]\n",
    "            if rms_envelope_raw.size < 2: return empty_tensor\n",
    "\n",
    "            # 3. Сглаживание RMS - ПРОПУСКАЕТСЯ\n",
    "            rms_envelope_processed = rms_envelope_raw\n",
    "\n",
    "            # 4. Расчет Дельты\n",
    "            delta_standard = np.diff(rms_envelope_processed, n=1, prepend=rms_envelope_processed[0])\n",
    "            delta_raw = delta_standard\n",
    "            if self.delta_type == 'cubed': delta_raw = np.power(self.delta_alpha * delta_standard, 3)\n",
    "            elif self.delta_type == 'quadratic_signed': delta_raw = delta_standard * np.abs(delta_standard)\n",
    "\n",
    "            # 5. Сглаживание Дельты - ПРОПУСКАЕТСЯ\n",
    "            delta_processed = delta_raw\n",
    "\n",
    "            # 6. Нормализация и Формирование Выхода\n",
    "            features_to_stack = []\n",
    "            rms_final_norm = self._normalize_feature(rms_envelope_processed)\n",
    "            features_to_stack.append(rms_final_norm)\n",
    "            delta_final_norm = self._normalize_feature(delta_processed)\n",
    "            features_to_stack.append(delta_final_norm)\n",
    "            features_np = np.vstack(features_to_stack).astype(np.float32)\n",
    "            features_tensor = torch.from_numpy(features_np)\n",
    "\n",
    "            if features_tensor.shape[0] != self.expected_feature_dim:\n",
    "                 print(f\"ERROR ({file_id_for_log}): Неожиданная размерность признаков: {features_tensor.shape[0]}\")\n",
    "                 return None # Ошибка -> None\n",
    "\n",
    "            return features_tensor\n",
    "\n",
    "        except Exception as e:\n",
    "             print(f\"КРИТИЧЕСКАЯ ОШИБКА в _calculate_features (Файл ~{file_id_for_log}): {e}\")\n",
    "             traceback.print_exc(limit=1)\n",
    "             return None # Ошибка -> None\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # (Код без изменений по сравнению с предыдущей версией)\n",
    "        if not (0 <= index < len(self.dataframe)): return None, (None if self.is_train else f\"InvalidIndex_{index}\")\n",
    "        try: row = self.dataframe.iloc[index]; file_id = row['id']; audio_path = self.audio_dir / file_id\n",
    "        except Exception as e: return None, (None if self.is_train else f\"DataAccessError_{index}_{e}\")\n",
    "        # 1. Загрузка/Ресэмплинг\n",
    "        try:\n",
    "            waveform_np, sr_original = librosa.load(audio_path, sr=self.sample_rate, mono=True)\n",
    "            if waveform_np.size == 0: return None, (file_id if not self.is_train else None)\n",
    "        except FileNotFoundError: print(f\"ERROR ({file_id}): File not found at {audio_path}\"); return None, (file_id if not self.is_train else None)\n",
    "        except Exception as e: print(f\"ERROR ({file_id}): Load/resample error: {e}\"); traceback.print_exc(limit=1); return None, (file_id if not self.is_train else None)\n",
    "        # 2. Зашумление - ПРОПУСКАЕТСЯ\n",
    "        waveform_for_features = waveform_np\n",
    "        # 3. Вычисление Признаков\n",
    "        features = self._calculate_features(waveform_for_features, file_id_for_log=file_id)\n",
    "        # Проверка результата\n",
    "        if features is None: return None, (file_id if not self.is_train else None)\n",
    "        if features.shape[1] == 0: return None, (file_id if not self.is_train else None)\n",
    "        # 4. Таргет / ID\n",
    "        if self.is_train:\n",
    "            message_text = str(row.get('message', '')); target_indices = [self.char_to_index.get(c, BLANK_IDX) for c in message_text]\n",
    "            if not target_indices or all(idx == BLANK_IDX for idx in target_indices): return None, None\n",
    "            target_tensor = torch.tensor(target_indices, dtype=torch.long)\n",
    "            return features, target_tensor\n",
    "        else: return features, file_id\n",
    "\n",
    "print(\"\\n--- Ячейка 5: Определение MorseDataset завершено (аннотация типов исправлена) ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 6: Функция collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 6: Определение функции collate_fn ---\n",
      "Функция collate_fn определена.\n",
      "\n",
      "--- Ячейка 6: Определение collate_fn завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 6: Функция collate_fn (Сборка Батчей)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 6: Определение функции collate_fn ---\")\n",
    "\n",
    "if 'PAD_IDX' not in globals() or PAD_IDX == -1:\n",
    "    raise ValueError(\"Глобальная переменная PAD_IDX не инициализирована!\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Собирает батч из отдельных примеров (признаки, таргеты/ID).\n",
    "    Фильтрует некорректные примеры (None).\n",
    "    Выполняет паддинг признаков и таргетов.\n",
    "    \"\"\"\n",
    "    # Фильтруем None значения, которые могли вернуться из __getitem__ при ошибках\n",
    "    original_batch_size = len(batch)\n",
    "    valid_batch = [(f, t) for f, t in batch if f is not None and t is not None and f.shape[1] > 0]\n",
    "    filtered_batch_size = len(valid_batch)\n",
    "\n",
    "    # Если весь батч отфильтрован, возвращаем None\n",
    "    if filtered_batch_size == 0:\n",
    "        # print(f\"Warning: Full batch filtered out (original size {original_batch_size}). Returning None.\")\n",
    "        return None\n",
    "\n",
    "    # Определяем, трейн это или тест, по типу второго элемента (таргет Tensor или ID строки)\n",
    "    is_train_batch = isinstance(valid_batch[0][1], torch.Tensor)\n",
    "\n",
    "    # Собираем признаки, транспонируя для pad_sequence (Batch, Time, Feat -> Time, Batch, Feat)\n",
    "    # Мы ожидаем признаки формы (Features, Time) от Dataset\n",
    "    features_list = [item[0].permute(1, 0) for item in valid_batch] # (Time, Features)\n",
    "    # Собираем таргеты или ID\n",
    "    targets_or_ids_list = [item[1] for item in valid_batch]\n",
    "\n",
    "    # Паддинг признаков (возвращает Batch, MaxTime, Features)\n",
    "    features_padded_permuted = pad_sequence(features_list, batch_first=True, padding_value=0.0)\n",
    "    # Возвращаем к формату (Batch, Features, MaxTime) для модели\n",
    "    features_padded = features_padded_permuted.permute(0, 2, 1)\n",
    "\n",
    "    # Собираем реальные длины признаков (до паддинга)\n",
    "    feature_lengths = torch.tensor([f[0].shape[1] for f in valid_batch], dtype=torch.long)\n",
    "\n",
    "    if is_train_batch:\n",
    "        # Обработка таргетов для обучающего батча\n",
    "        targets_list = targets_or_ids_list\n",
    "        # Паддинг таргетов\n",
    "        targets_padded = pad_sequence(targets_list, batch_first=True, padding_value=PAD_IDX)\n",
    "        # Собираем реальные длины таргетов\n",
    "        target_lengths = torch.tensor([len(t) for t in targets_list], dtype=torch.long)\n",
    "        return features_padded, targets_padded, feature_lengths, target_lengths\n",
    "    else:\n",
    "        # Для тестового батча возвращаем признаки, ID и длины признаков\n",
    "        file_ids = targets_or_ids_list\n",
    "        return features_padded, file_ids, feature_lengths, None # target_lengths не нужен\n",
    "\n",
    "print(\"Функция collate_fn определена.\")\n",
    "print(\"\\n--- Ячейка 6: Определение collate_fn завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 7: Модель MorseRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 7: Определение модели MorseRecognizer ---\n",
      "\n",
      "Создание экземпляра модели...\n",
      "Используется функция активации: GELU\n",
      "Архитектура MorseRecognizer инициализирована.\n",
      "Модель 'MorseRecognizer' успешно создана на устройстве 'cuda'.\n",
      "Общее количество обучаемых параметров: 2,021,997\n",
      "\n",
      "Проверка forward pass...\n",
      "  Размер входа: torch.Size([2, 2, 500])\n",
      "  Размер выхода: torch.Size([62, 2, 45])\n",
      "  Размерности выхода корректны.\n",
      "\n",
      "--- Ячейка 7: Определение и проверка модели завершены ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 7: Модель MorseRecognizer (CNN + BiGRU)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 7: Определение модели MorseRecognizer ---\")\n",
    "\n",
    "# Проверка наличия необходимых конфигураций\n",
    "if 'MODEL_CONFIG' not in globals() or not MODEL_CONFIG:\n",
    "    raise ValueError(\"Глобальная переменная MODEL_CONFIG не определена!\")\n",
    "if 'NUM_CLASSES_CTC' not in globals() or NUM_CLASSES_CTC <= 0:\n",
    "    raise ValueError(\"Глобальная переменная NUM_CLASSES_CTC не инициализирована!\")\n",
    "\n",
    "class MorseRecognizer(nn.Module):\n",
    "    \"\"\" Модель распознавания Морзе: Сверточные слои + Двунаправленный GRU + Классификатор \"\"\"\n",
    "    def __init__(self, num_classes_ctc: int, input_feature_dim: int, cnn_out_channels: list,\n",
    "                 cnn_kernel_size: int, cnn_stride: int, cnn_padding, cnn_pool_kernel: int,\n",
    "                 rnn_hidden_size: int, rnn_num_layers: int, dropout_rate: float, activation_fn: str = \"GELU\"):\n",
    "        super().__init__()\n",
    "        self.input_feature_dim = input_feature_dim\n",
    "        self._time_reduction_factor = 1.0 # Фактор уменьшения времени после CNN/Pooling\n",
    "\n",
    "        # --- Сверточный Блок (CNN Extractor) ---\n",
    "        cnn_layers = []\n",
    "        in_channels = input_feature_dim\n",
    "        try:\n",
    "            ActivationLayer = getattr(nn, activation_fn)\n",
    "            print(f\"Используется функция активации: {activation_fn}\")\n",
    "        except AttributeError:\n",
    "            print(f\"Warning: Активация '{activation_fn}' не найдена в nn. Используется GELU.\")\n",
    "            ActivationLayer = nn.GELU\n",
    "\n",
    "        for i, out_channels in enumerate(cnn_out_channels):\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv1d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=cnn_kernel_size,\n",
    "                    stride=cnn_stride,\n",
    "                    padding=cnn_padding # 'same' или число\n",
    "                ),\n",
    "                nn.BatchNorm1d(num_features=out_channels),\n",
    "                ActivationLayer(),\n",
    "                nn.MaxPool1d(kernel_size=cnn_pool_kernel),\n",
    "                nn.Dropout(p=dropout_rate)\n",
    "            )\n",
    "            cnn_layers.append(layer)\n",
    "            in_channels = out_channels # Выходные каналы становятся входными для след. слоя\n",
    "            self._time_reduction_factor *= cnn_pool_kernel # Учитываем уменьшение времени\n",
    "        self.cnn_extractor = nn.Sequential(*cnn_layers)\n",
    "        self.cnn_output_dim = in_channels # Размерность выхода CNN\n",
    "\n",
    "        # --- Рекуррентный Блок (BiGRU) ---\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.cnn_output_dim,\n",
    "            hidden_size=rnn_hidden_size,\n",
    "            num_layers=rnn_num_layers,\n",
    "            batch_first=True,       # Вход: (Batch, Time, Feat)\n",
    "            bidirectional=True,     # Двунаправленный GRU\n",
    "            dropout=dropout_rate if rnn_num_layers > 1 else 0 # Dropout между слоями GRU\n",
    "        )\n",
    "\n",
    "        # --- Классификатор ---\n",
    "        # Выход BiGRU имеет размер hidden_size * 2\n",
    "        self.classifier = nn.Linear(\n",
    "            in_features=rnn_hidden_size * 2,\n",
    "            out_features=num_classes_ctc # Количество классов для CTC\n",
    "        )\n",
    "        print(\"Архитектура MorseRecognizer инициализирована.\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Прямой проход модели. x: (Batch, Features, Time) \"\"\"\n",
    "        # Проверка входной размерности\n",
    "        if x.shape[1] != self.input_feature_dim:\n",
    "            raise ValueError(f\"Неверное количество входных признаков! Ожидалось {self.input_feature_dim}, получено {x.shape[1]}\")\n",
    "\n",
    "        # 1. Пропускаем через CNN\n",
    "        x = self.cnn_extractor(x) # Выход CNN: (Batch, CNN_Features, Reduced_Time)\n",
    "\n",
    "        # 2. Меняем оси для RNN: (Batch, Reduced_Time, CNN_Features)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 3. Пропускаем через RNN\n",
    "        x_rnn, _ = self.rnn(x) # Выход RNN: (Batch, Reduced_Time, RNN_Hidden * 2)\n",
    "\n",
    "        # 4. Пропускаем через классификатор\n",
    "        logits = self.classifier(x_rnn) # Выход: (Batch, Reduced_Time, Num_Classes_CTC)\n",
    "\n",
    "        # 5. Меняем оси для CTC Loss: (Reduced_Time, Batch, Num_Classes_CTC)\n",
    "        return logits.permute(1, 0, 2)\n",
    "\n",
    "    def get_time_reduction_factor(self) -> float:\n",
    "        \"\"\" Возвращает фактор, на который CNN уменьшает временную размерность \"\"\"\n",
    "        return self._time_reduction_factor\n",
    "\n",
    "# --- Создание и Проверка Модели ---\n",
    "model_created_successfully = False\n",
    "model = None\n",
    "try:\n",
    "    print(\"\\nСоздание экземпляра модели...\")\n",
    "    model = MorseRecognizer(\n",
    "        num_classes_ctc=NUM_CLASSES_CTC,\n",
    "        **MODEL_CONFIG # Передаем параметры из словаря\n",
    "    ).to(device)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Модель '{type(model).__name__}' успешно создана на устройстве '{device}'.\")\n",
    "    print(f\"Общее количество обучаемых параметров: {total_params:,}\")\n",
    "\n",
    "    # --- Проверка forward pass на dummy данных ---\n",
    "    print(\"\\nПроверка forward pass...\")\n",
    "    model.eval() # Переводим в режим оценки для проверки\n",
    "    # Создаем батч из 2х примеров с 500 временными шагами\n",
    "    dummy_input = torch.randn(2, MODEL_CONFIG['input_feature_dim'], 500).to(device)\n",
    "    with torch.no_grad():\n",
    "        dummy_output = model(dummy_input)\n",
    "\n",
    "    print(f\"  Размер входа: {dummy_input.shape}\")\n",
    "    print(f\"  Размер выхода: {dummy_output.shape}\")\n",
    "\n",
    "    # Проверка размерностей выхода\n",
    "    expected_time_dim = int(dummy_input.shape[2] / model.get_time_reduction_factor())\n",
    "    # Допускаем небольшое расхождение из-за округлений/паддинга\n",
    "    if abs(dummy_output.shape[0] - expected_time_dim) > 2:\n",
    "         print(f\"  ПРЕДУПРЕЖДЕНИЕ: Неожиданная длина выхода по времени! Ожидалось ~{expected_time_dim}, получено {dummy_output.shape[0]}.\")\n",
    "    assert dummy_output.shape[1] == dummy_input.shape[0], \"Размер батча выхода не совпадает с входом!\"\n",
    "    assert dummy_output.shape[2] == NUM_CLASSES_CTC, \"Количество классов на выходе не совпадает с NUM_CLASSES_CTC!\"\n",
    "    print(\"  Размерности выхода корректны.\")\n",
    "    model_created_successfully = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n!!! Ошибка при создании или проверке модели: {e} !!!\")\n",
    "    traceback.print_exc()\n",
    "    model = None # Сбрасываем модель в случае ошибки\n",
    "\n",
    "if not model_created_successfully:\n",
    "    raise SystemExit(\"Остановка: Не удалось создать или проверить модель.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 7: Определение и проверка модели завершены ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 8: Loss, Optimizer, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 8: Настройка Loss и Optimizer ---\n",
      "Функция потерь: CTCLoss (blank=44, reduction='mean', zero_infinity=True)\n",
      "\n",
      "Выбор оптимизатора: ADAMW\n",
      "Оптимизатор: AdamW (lr=3.0e-04, weight_decay=1.0e-04)\n",
      "Планировщик: OneCycleLR (будет инициализирован перед циклом обучения)\n",
      "\n",
      "--- Ячейка 8: Настройка Loss и Optimizer завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 8: Функция Потерь (Loss) и Оптимизатор\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 8: Настройка Loss и Optimizer ---\")\n",
    "\n",
    "# Проверка, что модель создана успешно\n",
    "if not model_created_successfully or model is None:\n",
    "    raise SystemExit(\"Остановка: Модель не была успешно создана в предыдущей ячейке.\")\n",
    "if BLANK_IDX == -1:\n",
    "    raise ValueError(\"Глобальная переменная BLANK_IDX не инициализирована!\")\n",
    "\n",
    "# 1. Функция Потерь (Criterion) - CTC Loss\n",
    "#    reduction='mean': усредняет потери по батчу\n",
    "#    zero_infinity=True: обнуляет бесконечные потери (полезно при очень плохих предсказаниях)\n",
    "criterion = nn.CTCLoss(blank=BLANK_IDX, reduction='mean', zero_infinity=True).to(device)\n",
    "print(f\"Функция потерь: CTCLoss (blank={BLANK_IDX}, reduction='mean', zero_infinity=True)\")\n",
    "\n",
    "# 2. Оптимизатор (Optimizer)\n",
    "optimizer_name = TRAIN_CONFIG.get('optimizer', 'AdamW').lower()\n",
    "lr = TRAIN_CONFIG['learning_rate'] # Это будет max_lr для OneCycleLR\n",
    "wd = TRAIN_CONFIG['weight_decay']\n",
    "optimizer = None\n",
    "\n",
    "print(f\"\\nВыбор оптимизатора: {optimizer_name.upper()}\")\n",
    "if optimizer_name == 'adamw':\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "elif optimizer_name == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "else:\n",
    "    print(f\"Предупреждение: Неизвестный оптимизатор '{optimizer_name}'. Используется AdamW.\")\n",
    "    optimizer_name = 'adamw'\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "print(f\"Оптимизатор: {type(optimizer).__name__} (lr={lr:.1e}, weight_decay={wd:.1e})\")\n",
    "\n",
    "# 3. Планировщик (Scheduler) - Инициализируется в Ячейке 13\n",
    "#    Будет использоваться OneCycleLR\n",
    "scheduler = None\n",
    "print(\"Планировщик: OneCycleLR (будет инициализирован перед циклом обучения)\")\n",
    "\n",
    "print(\"\\n--- Ячейка 8: Настройка Loss и Optimizer завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 9: Функции Декодирования и Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 9: Определение функций декодирования (Greedy) и метрики ---\n",
      "Функции ctc_greedy_decode и calculate_levenshtein определены.\n",
      "\n",
      "--- Ячейка 9: Определение функций декодирования и метрики завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 9: Функции Декодирования (Greedy) и Метрики (Levenshtein)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 9: Определение функций декодирования (Greedy) и метрики ---\")\n",
    "\n",
    "# Проверки необходимых глобальных переменных\n",
    "if 'index_to_char' not in globals() or not index_to_char \\\n",
    "   or 'BLANK_IDX' not in globals() or BLANK_IDX == -1 \\\n",
    "   or 'PAD_IDX' not in globals() or PAD_IDX == -1:\n",
    "     raise ValueError(\"Словарь index_to_char или индексы BLANK/PAD не определены! Запустите Ячейку 4.\")\n",
    "\n",
    "# --- Функция Жадного CTC Декодирования (Greedy / Best Path Decoding) ---\n",
    "def ctc_greedy_decode(logits: torch.Tensor, index_to_char_map: dict, blank_idx: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Выполняет простое жадное (best path) декодирование выхода CTC модели.\n",
    "    Убирает повторы и BLANK символы.\n",
    "    \"\"\"\n",
    "    decoded_batch = []\n",
    "    # Находим индекс с максимальным логитом на каждом временном шаге: (Time, Batch)\n",
    "    best_path = torch.argmax(logits, dim=2)\n",
    "    best_path_np = best_path.cpu().numpy()\n",
    "\n",
    "    # Итерируем по каждому элементу в батче\n",
    "    for i in range(best_path_np.shape[1]): # Итерация по оси Batch\n",
    "        sequence_indices = best_path_np[:, i] # Получаем последовательность индексов для одного примера\n",
    "\n",
    "        # 1. Схлопывание повторов: оставляем только первый из серии одинаковых индексов\n",
    "        collapsed_indices = [idx for j, idx in enumerate(sequence_indices) if j == 0 or idx != sequence_indices[j-1]]\n",
    "\n",
    "        # 2. Удаление BLANK символов\n",
    "        final_indices = [idx for idx in collapsed_indices if idx != blank_idx]\n",
    "\n",
    "        # 3. Преобразование индексов в строку\n",
    "        decoded_string = \"\".join([index_to_char_map.get(idx, '?') for idx in final_indices]) # '?' для неизвестных индексов\n",
    "        decoded_batch.append(decoded_string)\n",
    "\n",
    "    return decoded_batch\n",
    "\n",
    "# --- Функция Расчета Расстояния Левенштейна ---\n",
    "def calculate_levenshtein(predictions: list[str],\n",
    "                          targets_padded: torch.Tensor,\n",
    "                          target_lengths: torch.Tensor,\n",
    "                          index_to_char_map: dict,\n",
    "                          pad_idx: int) -> tuple[float, list[tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Рассчитывает среднее НЕнормализованное расстояние Левенштейна для батча.\n",
    "    Возвращает среднее расстояние и список пар (предсказание, реальный текст).\n",
    "    \"\"\"\n",
    "    total_distance = 0.0\n",
    "    num_valid_pairs = 0\n",
    "    decoded_pairs_for_analysis = []\n",
    "    batch_size = targets_padded.shape[0]\n",
    "    targets_np = targets_padded.cpu().numpy()\n",
    "    target_lengths_np = target_lengths.cpu().numpy()\n",
    "\n",
    "    if len(predictions) != batch_size:\n",
    "        print(f\"Предупреждение: Размер predictions ({len(predictions)}) != batch_size ({batch_size}) в calculate_levenshtein\")\n",
    "        return float('inf'), [] # Возвращаем бесконечность, если размеры не совпадают\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        real_len = target_lengths_np[i] # Реальная длина таргетной последовательности\n",
    "        prediction_string = predictions[i] # Предсказанная строка\n",
    "\n",
    "        if real_len <= 0: # Если таргет пустой (маловероятно, но возможно)\n",
    "            target_string = \"\"\n",
    "            distance = len(prediction_string) # Расстояние = длина предсказания\n",
    "        else:\n",
    "            # Получаем индексы таргетной последовательности\n",
    "            target_indices = targets_np[i, :real_len]\n",
    "            # Преобразуем индексы в строку, игнорируя PAD\n",
    "            target_string = \"\".join([index_to_char_map.get(idx, '?') for idx in target_indices if idx != pad_idx])\n",
    "\n",
    "            # Считаем расстояние Левенштейна\n",
    "            try:\n",
    "                distance = Levenshtein.distance(prediction_string, target_string)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при расчете Levenshtein для: pred='{prediction_string}', target='{target_string}'. E: {e}\")\n",
    "                # В случае ошибки берем максимальную длину как оценку расстояния\n",
    "                distance = max(len(prediction_string), len(target_string))\n",
    "\n",
    "        total_distance += distance\n",
    "        num_valid_pairs += 1\n",
    "        decoded_pairs_for_analysis.append((prediction_string, target_string))\n",
    "\n",
    "    # Рассчитываем среднее расстояние\n",
    "    mean_levenshtein = total_distance / num_valid_pairs if num_valid_pairs > 0 else float('inf')\n",
    "\n",
    "    return mean_levenshtein, decoded_pairs_for_analysis\n",
    "\n",
    "print(\"Функции ctc_greedy_decode и calculate_levenshtein определены.\")\n",
    "print(\"\\n--- Ячейка 9: Определение функций декодирования и метрики завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 10: Функции Обучения и Валидации Эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 10: Определение функций обучения и валидации эпохи ---\n",
      "Функции train_epoch и validate_epoch определены.\n",
      "\n",
      "--- Ячейка 10: Определение функций обучения и валидации завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 10: Функции Обучения и Валидации Эпохи\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 10: Определение функций обучения и валидации эпохи ---\")\n",
    "\n",
    "# Проверки необходимых компонентов\n",
    "if 'ctc_greedy_decode' not in globals() or 'calculate_levenshtein' not in globals():\n",
    "    raise NameError(\"Функции декодирования/метрики не определены! Запустите Ячейку 9.\")\n",
    "if 'BLANK_IDX' not in globals() or BLANK_IDX == -1 or 'PAD_IDX' not in globals() or PAD_IDX == -1:\n",
    "    raise ValueError(\"Индексы BLANK_IDX или PAD_IDX не определены!\")\n",
    "if 'model' not in globals() or model is None: raise NameError(\"Модель 'model' не определена!\")\n",
    "if 'device' not in globals(): raise NameError(\"Переменная 'device' не определена!\")\n",
    "if 'index_to_char' not in globals() or not index_to_char: raise NameError(\"Словарь 'index_to_char' не определен!\")\n",
    "\n",
    "# --- Функция Обучения Одной Эпохи ---\n",
    "def train_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.CTCLoss,\n",
    "                optimizer: optim.Optimizer, scheduler: optim.lr_scheduler._LRScheduler,\n",
    "                device: torch.device, epoch_num: int, total_epochs: int,\n",
    "                index_to_char_map: dict, blank_idx: int, pad_idx: int,\n",
    "                grad_clip_norm: float) -> tuple[float, float, float]:\n",
    "    \"\"\" Выполняет одну эпоху обучения. Возвращает средние loss, lev, lr. \"\"\"\n",
    "    model.train() # Переводим модель в режим обучения\n",
    "    running_loss = 0.0; total_lev_dist = 0.0; total_lr = 0.0; num_batches = 0\n",
    "    total_samples_processed = 0\n",
    "\n",
    "    # Получаем фактор редукции времени из модели для расчета длины входа CTC\n",
    "    try: time_factor = model.get_time_reduction_factor()\n",
    "    except AttributeError: time_factor = 1.0\n",
    "    time_factor = max(time_factor, 1.0)\n",
    "\n",
    "    # Прогресс-бар с заданной шириной\n",
    "    pbar = tqdm(dataloader, desc=f\"Эпоха {epoch_num}/{total_epochs} [Тренировка]\", leave=False, ncols=1000)\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(pbar):\n",
    "        if batch_data is None: continue # Пропуск батча, если collate_fn вернул None\n",
    "        features, targets, feature_lengths, target_lengths = batch_data\n",
    "        if features is None or targets is None: continue # Доп. проверка\n",
    "        batch_size = features.size(0);\n",
    "        if batch_size == 0: continue\n",
    "\n",
    "        # Перенос на устройство\n",
    "        features = features.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        feature_lengths_cpu = feature_lengths.cpu(); target_lengths_cpu = target_lengths.cpu()\n",
    "        # Расчет длины входа для CTC Loss (округление вниз)\n",
    "        input_lengths_ctc = torch.floor(feature_lengths_cpu.float() / time_factor + 1e-9).long().clamp(min=1)\n",
    "\n",
    "        loss_value = float('inf'); lev_dist_batch_avg = float('inf')\n",
    "        current_lr = optimizer.param_groups[0]['lr'] # Получаем LR *перед* шагом\n",
    "        total_lr += current_lr\n",
    "        num_batches += 1\n",
    "\n",
    "        try:\n",
    "            # --- Forward Pass ---\n",
    "            optimizer.zero_grad() # Очищаем градиенты с предыдущего шага\n",
    "            logits = model(features) # (Time, Batch, Classes)\n",
    "            output_length = logits.shape[0] # Длина выхода модели по времени\n",
    "            if logits.shape[1] != batch_size: continue # Проверка консистентности\n",
    "\n",
    "            # --- Расчет Loss ---\n",
    "            log_probs = F.log_softmax(logits, dim=2) # Log Softmax для CTC\n",
    "            # Убедимся, что длины для CTC не превышают реальные длины выхода/таргета\n",
    "            input_lengths_ctc_clamped = input_lengths_ctc.clamp(max=output_length)\n",
    "            target_lengths_clamped = target_lengths_cpu.clamp(max=targets.shape[1])\n",
    "            loss = criterion(log_probs, targets, input_lengths_ctc_clamped, target_lengths_clamped)\n",
    "\n",
    "            if not torch.isfinite(loss): # Проверка на NaN/Inf\n",
    "                print(f\"Warning: NaN/Inf loss detected in batch {batch_idx}. Skipping optimizer step.\")\n",
    "                optimizer.zero_grad()\n",
    "                continue\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "            # --- Backward Pass & Оптимизация ---\n",
    "            loss.backward() # Расчет градиентов\n",
    "            if grad_clip_norm > 0: # Клиппинг градиентов\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_norm)\n",
    "            optimizer.step() # Обновление весов\n",
    "\n",
    "            # --- Шаг Планировщика ---\n",
    "            if scheduler: # OneCycleLR шаг после каждого батча\n",
    "                scheduler.step()\n",
    "\n",
    "            # --- Расчет Levenshtein (Greedy) для лога (не влияет на градиенты) ---\n",
    "            with torch.no_grad():\n",
    "                decoded_preds = ctc_greedy_decode(logits, index_to_char_map, blank_idx)\n",
    "                lev_dist_batch_avg, _ = calculate_levenshtein(decoded_preds, targets.cpu(), target_lengths_cpu, index_to_char_map, pad_idx)\n",
    "\n",
    "        except RuntimeError as e:\n",
    "             if \"CUDA out of memory\" in str(e):\n",
    "                 print(\"\\n!!! Критическая ошибка: CUDA out of memory! Уменьшите batch_size. !!!\")\n",
    "                 raise e # Прерываем выполнение\n",
    "             else: print(f\"\\nRuntimeError в батче {batch_idx}: {e}\"); traceback.print_exc(); loss_value=30.0; lev_dist_batch_avg=float('inf')\n",
    "        except Exception as e: print(f\"\\nОшибка в train_epoch, батч {batch_idx}: {e}\"); traceback.print_exc(); loss_value=30.0; lev_dist_batch_avg=float('inf')\n",
    "\n",
    "        # --- Обновление статистики ---\n",
    "        if np.isfinite(loss_value): running_loss += loss_value * batch_size\n",
    "        else: running_loss += 30.0 * batch_size # Штраф за NaN/Inf\n",
    "        # Приблизительная оценка Levenshtein в случае ошибки расчета\n",
    "        lev_to_add = lev_dist_batch_avg if np.isfinite(lev_dist_batch_avg) else (features.shape[2] / 10.0) # Штраф пропорционально длине\n",
    "        total_lev_dist += lev_to_add * batch_size\n",
    "        total_samples_processed += batch_size\n",
    "        pbar.set_postfix(loss=f'{loss_value:.4f}', lev=f'{lev_dist_batch_avg:.4f}', lr=f'{current_lr:.2e}')\n",
    "\n",
    "    pbar.close()\n",
    "    # Расчет средних значений за эпоху\n",
    "    avg_epoch_loss = running_loss / total_samples_processed if total_samples_processed > 0 else float('inf')\n",
    "    avg_epoch_lev = total_lev_dist / total_samples_processed if total_samples_processed > 0 else float('inf')\n",
    "    avg_epoch_lr = total_lr / num_batches if num_batches > 0 else 0.0\n",
    "\n",
    "    return avg_epoch_loss, avg_epoch_lev, avg_epoch_lr\n",
    "\n",
    "# --- Функция Валидации Одной Эпохи ---\n",
    "def validate_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.CTCLoss,\n",
    "                   device: torch.device, index_to_char_map: dict,\n",
    "                   blank_idx: int, pad_idx: int) -> tuple[float, float, list[tuple[str, str]]]:\n",
    "    \"\"\" Выполняет одну эпоху валидации. Возвращает средние loss, lev и примеры декодирования. \"\"\"\n",
    "    model.eval() # Перевод модели в режим оценки\n",
    "    running_loss = 0.0; total_lev_dist = 0.0; total_samples_processed = 0\n",
    "    all_decoded_pairs = [] # Для вывода примеров\n",
    "\n",
    "    try: time_factor = model.get_time_reduction_factor()\n",
    "    except AttributeError: time_factor = 1.0\n",
    "    time_factor = max(time_factor, 1.0)\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=\"   [Валидация]\", leave=False, ncols=1000)\n",
    "\n",
    "    with torch.no_grad(): # Отключаем расчет градиентов для валидации\n",
    "        for batch_data in pbar:\n",
    "            if batch_data is None: continue\n",
    "            features, targets, feature_lengths, target_lengths = batch_data\n",
    "            if features is None or targets is None: continue\n",
    "            batch_size = features.size(0);\n",
    "            if batch_size == 0: continue\n",
    "\n",
    "            features = features.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            feature_lengths_cpu = feature_lengths.cpu(); target_lengths_cpu = target_lengths.cpu()\n",
    "            input_lengths_ctc = torch.floor(feature_lengths_cpu.float() / time_factor + 1e-9).long().clamp(min=1)\n",
    "\n",
    "            loss_value = float('inf'); lev_dist_batch_avg = float('inf'); decoded_pairs_batch = []\n",
    "\n",
    "            try:\n",
    "                # --- Forward Pass ---\n",
    "                logits = model(features)\n",
    "                output_length = logits.shape[0]\n",
    "                if logits.shape[1] != batch_size: continue\n",
    "\n",
    "                # --- Расчет Loss ---\n",
    "                log_probs = F.log_softmax(logits, dim=2)\n",
    "                input_lengths_ctc_clamped = input_lengths_ctc.clamp(max=output_length)\n",
    "                target_lengths_clamped = target_lengths_cpu.clamp(max=targets.shape[1])\n",
    "                loss = criterion(log_probs, targets, input_lengths_ctc_clamped, target_lengths_clamped)\n",
    "                if torch.isfinite(loss): loss_value = loss.item()\n",
    "\n",
    "                # --- Декодирование (ТОЛЬКО Greedy) ---\n",
    "                decoded_preds = ctc_greedy_decode(logits, index_to_char_map, blank_idx)\n",
    "\n",
    "                # --- Расчет Levenshtein ---\n",
    "                lev_dist_batch_avg, decoded_pairs_batch = calculate_levenshtein(\n",
    "                    decoded_preds, targets.cpu(), target_lengths_cpu, index_to_char_map, pad_idx\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nОшибка в validate_epoch: {e}\"); traceback.print_exc(limit=1)\n",
    "                loss_value=float('inf'); lev_dist_batch_avg=float('inf')\n",
    "                decoded_pairs_batch = [(f\"ERROR_VAL\", \"\")] * batch_size\n",
    "\n",
    "            # --- Обновление статистики ---\n",
    "            if np.isfinite(loss_value): running_loss += loss_value * batch_size\n",
    "            lev_to_add = lev_dist_batch_avg if np.isfinite(lev_dist_batch_avg) else (features.shape[2] / 10.0)\n",
    "            total_lev_dist += lev_to_add * batch_size; total_samples_processed += batch_size\n",
    "            # Сохраняем первые несколько примеров для вывода в лог\n",
    "            if len(all_decoded_pairs) < 15: # Ограничиваем количество сохраняемых пар\n",
    "                 all_decoded_pairs.extend(decoded_pairs_batch)\n",
    "            pbar.set_postfix(loss=f'{loss_value:.4f}', lev=f'{lev_dist_batch_avg:.4f}')\n",
    "\n",
    "    pbar.close()\n",
    "    # Расчет средних значений за эпоху\n",
    "    avg_epoch_loss = running_loss / total_samples_processed if total_samples_processed > 0 else float('inf')\n",
    "    avg_epoch_lev = total_lev_dist / total_samples_processed if total_samples_processed > 0 else float('inf')\n",
    "\n",
    "    return avg_epoch_loss, avg_epoch_lev, all_decoded_pairs\n",
    "\n",
    "print(\"Функции train_epoch и validate_epoch определены.\")\n",
    "print(\"\\n--- Ячейка 10: Определение функций обучения и валидации завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 11.1 Конфигурация Калибровки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================================================================\n",
    "# # Ячейка 11.1: Калибровка Сглаживания RMS (с Полным Обучением)\n",
    "# # =============================================================================\n",
    "# print(\"--- Ячейка 11.1: Калибровка Сглаживания RMS (с Полным Обучением) ---\")\n",
    "\n",
    "# # --- Конфигурация Калибровки ---\n",
    "# CALIBRATION_CONFIG = {\n",
    "#     \"enabled\": True,\n",
    "#     \"parameter\": 'rms_smoothing_window_size',\n",
    "#     \"values_to_try\": [1, 2, 3, 4, 5, 7, 9], # Окна для проверки\n",
    "#     \"calibration_epochs\": 2,               # !!! Количество эпох для КАЖДОГО значения !!!\n",
    "#     \"metric\": 'Val Levenshtein'\n",
    "# }\n",
    "# print(f\"Калибровка '{CALIBRATION_CONFIG['parameter']}' включена.\")\n",
    "# print(f\"Значения для проверки: {CALIBRATION_CONFIG['values_to_try']}\")\n",
    "# print(f\"Количество эпох на каждое значение: {CALIBRATION_CONFIG['calibration_epochs']}\")\n",
    "# print(f\"ПРЕДУПРЕЖДЕНИЕ: Этот процесс может занять много времени!\")\n",
    "\n",
    "# # --- Проверки готовности (базовые компоненты) ---\n",
    "# required_calib_vars = [\n",
    "#     'criterion', 'train_df', 'index_to_char', 'char_to_index',\n",
    "#     'AUDIO_CONFIG', 'MODEL_CONFIG', 'TRAIN_CONFIG', 'device', 'collate_fn',\n",
    "#     'MorseDataset', 'train_epoch', 'validate_epoch', 'EXTRACTED_AUDIO_DIR',\n",
    "#     'BLANK_IDX', 'PAD_IDX', 'MorseRecognizer', 'optim', 'OneCycleLR', 'F' # Добавили недостающие\n",
    "# ]\n",
    "# missing_calib_vars = [v for v in required_calib_vars if v not in globals() or globals()[v] is None]\n",
    "\n",
    "# if missing_calib_vars:\n",
    "#      print(f\"!!! Ошибка: Отсутствуют компоненты для калибровки: {missing_calib_vars} !!!\")\n",
    "#      CALIBRATION_CONFIG['enabled'] = False\n",
    "\n",
    "# # --- Калибровочный цикл ---\n",
    "# calibration_results_rms = {}\n",
    "# best_rms_window = 1 # По умолчанию 1\n",
    "# best_rms_lev = float('inf')\n",
    "\n",
    "# if CALIBRATION_CONFIG['enabled']:\n",
    "#     # --- Подготовка индексов валидации (один раз) ---\n",
    "#     print(\"\\nПодготовка индексов валидации...\")\n",
    "#     try:\n",
    "#         dataset_size_calib = len(train_df)\n",
    "#         val_split_ratio_calib = TRAIN_CONFIG['validation_split_ratio']\n",
    "#         val_size_calib = int(np.floor(val_split_ratio_calib * dataset_size_calib))\n",
    "#         train_size_calib = dataset_size_calib - val_size_calib\n",
    "#         # Используем временный Dataset только для получения индексов\n",
    "#         temp_full_ds = MorseDataset(dataframe=train_df, audio_dir=EXTRACTED_AUDIO_DIR, char_to_index=char_to_index,\n",
    "#                                     audio_config=AUDIO_CONFIG, model_input_feature_dim=MODEL_CONFIG['input_feature_dim'],\n",
    "#                                     train_config=TRAIN_CONFIG, is_train=True) # is_train не важен здесь\n",
    "#         train_subset_indices_calib, val_subset_indices_calib = random_split(\n",
    "#             range(len(temp_full_ds)), [train_size_calib, val_size_calib], # Делим индексы\n",
    "#             generator=torch.Generator().manual_seed(TRAIN_CONFIG['base_seed'])\n",
    "#         )\n",
    "#         train_indices_calib = train_subset_indices_calib.indices\n",
    "#         val_indices_calib = val_subset_indices_calib.indices\n",
    "#         print(f\"Индексы подготовлены: Train={len(train_indices_calib)}, Val={len(val_indices_calib)}\")\n",
    "#         del temp_full_ds # Освобождаем память\n",
    "#     except Exception as e:\n",
    "#         print(f\"!!! Ошибка подготовки индексов: {e}. Калибровка остановлена.\")\n",
    "#         traceback.print_exc()\n",
    "#         CALIBRATION_CONFIG['enabled'] = False\n",
    "\n",
    "# if CALIBRATION_CONFIG['enabled']:\n",
    "#     param_to_tune = CALIBRATION_CONFIG['parameter']\n",
    "#     n_calib_epochs = CALIBRATION_CONFIG['calibration_epochs']\n",
    "#     CALIBRATION_LR = 7e-4\n",
    "#     print(f\"!!! Используется LR = {CALIBRATION_LR:.0e} для калибровочных запусков !!!\")\n",
    "\n",
    "#     for window_size in CALIBRATION_CONFIG['values_to_try']:\n",
    "#         print(f\"\\n-- Тестирование {param_to_tune} = {window_size} --\")\n",
    "#         start_calib_time = time.time()\n",
    "#         current_best_lev_for_window = float('inf') # Лучший результат за n_calib_epochs\n",
    "\n",
    "#         # 1. Создаем ВРЕМЕННУЮ конфигурацию аудио\n",
    "#         temp_audio_config = AUDIO_CONFIG.copy()\n",
    "#         temp_audio_config[param_to_tune] = window_size\n",
    "\n",
    "#         # 2. Создаем ВРЕМЕННЫЕ Dataset и DataLoader\n",
    "#         temp_model = None; temp_optimizer = None; temp_scheduler = None\n",
    "#         temp_train_loader = None; temp_val_loader = None\n",
    "#         try:\n",
    "#             # Создаем полные датасеты с текущей конфигурацией\n",
    "#             temp_train_dataset = MorseDataset(\n",
    "#                 dataframe=train_df.iloc[train_indices_calib].reset_index(drop=True), # Только нужные данные\n",
    "#                 audio_dir=EXTRACTED_AUDIO_DIR, char_to_index=char_to_index,\n",
    "#                 audio_config=temp_audio_config, # ВРЕМЕННАЯ КОНФИГУРАЦИЯ\n",
    "#                 model_input_feature_dim=MODEL_CONFIG['input_feature_dim'],\n",
    "#                 train_config=TRAIN_CONFIG, is_train=True\n",
    "#             )\n",
    "#             temp_val_dataset = MorseDataset(\n",
    "#                 dataframe=train_df.iloc[val_indices_calib].reset_index(drop=True), # Только нужные данные\n",
    "#                 audio_dir=EXTRACTED_AUDIO_DIR, char_to_index=char_to_index,\n",
    "#                 audio_config=temp_audio_config, # ВРЕМЕННАЯ КОНФИГУРАЦИЯ\n",
    "#                 model_input_feature_dim=MODEL_CONFIG['input_feature_dim'],\n",
    "#                 train_config=TRAIN_CONFIG, is_train=True # is_train=True для таргетов\n",
    "#             )\n",
    "#             if len(temp_train_dataset) == 0 or len(temp_val_dataset) == 0:\n",
    "#                 print(\"!!! Ошибка: Временный калибровочный датасет пуст! Пропуск шага.\")\n",
    "#                 continue\n",
    "\n",
    "#             # Создаем лоадеры\n",
    "#             bs = TRAIN_CONFIG['batch_size']; nw = TRAIN_CONFIG['num_workers']; pm = (device.type == 'cuda')\n",
    "#             temp_train_loader = DataLoader(temp_train_dataset, batch_size=bs, shuffle=True, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "#             temp_val_loader = DataLoader(temp_val_dataset, batch_size=bs*2, shuffle=False, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "#             print(f\"  Временные лоадеры созданы: Train={len(temp_train_loader)} батчей, Val={len(temp_val_loader)} батчей\")\n",
    "\n",
    "#             # 3. Создаем НОВУЮ МОДЕЛЬ с нуля\n",
    "#             temp_model = MorseRecognizer(num_classes_ctc=NUM_CLASSES_CTC, **MODEL_CONFIG).to(device)\n",
    "\n",
    "#             # 4. Создаем НОВЫЙ ОПТИМИЗАТОР (используем WD из основного конфига)\n",
    "#             wd_calib = TRAIN_CONFIG['weight_decay']\n",
    "#             if TRAIN_CONFIG['optimizer'].lower() == 'adam':\n",
    "#                  temp_optimizer = optim.Adam(temp_model.parameters(), lr=CALIBRATION_LR, weight_decay=wd_calib)\n",
    "#             else: temp_optimizer = optim.AdamW(temp_model.parameters(), lr=CALIBRATION_LR, weight_decay=wd_calib)\n",
    "\n",
    "#             # 5. Создаем НОВЫЙ ПЛАНИРОВЩИК (!!! используем CALIBRATION_LR !!!)\n",
    "#             steps_per_epoch_calib = len(temp_train_loader)\n",
    "#             if steps_per_epoch_calib == 0: raise ValueError(\"Калибровочный train loader пуст!\")\n",
    "#             total_steps_calib = n_calib_epochs * steps_per_epoch_calib\n",
    "#             final_div_calib = TRAIN_CONFIG.get('final_div_factor', 1e4) # Берем из основного\n",
    "#             temp_scheduler = OneCycleLR(\n",
    "#                 temp_optimizer,\n",
    "#                 max_lr=CALIBRATION_LR, # !!! Явно указываем LR калибровки !!!\n",
    "#                 total_steps=total_steps_calib,\n",
    "#                 final_div_factor=final_div_calib\n",
    "#             )\n",
    "#             print(f\"  Новая модель, оптимизатор и планировщик (LR={CALIBRATION_LR:.0e}, Total Steps: {total_steps_calib}, final_div={final_div_calib:.0f}) созданы.\")\n",
    "            \n",
    "#             # 6. Запускаем Цикл Обучения на n_calib_epochs\n",
    "#             print(f\"  Запуск обучения на {n_calib_epochs} эпох...\")\n",
    "#             for epoch_calib in range(1, n_calib_epochs + 1):\n",
    "#                 # Тренировка\n",
    "#                 train_loss_c, train_lev_c, _ = train_epoch(\n",
    "#                     model=temp_model, dataloader=temp_train_loader, criterion=criterion,\n",
    "#                     optimizer=temp_optimizer, scheduler=temp_scheduler, device=device,\n",
    "#                     epoch_num=epoch_calib, total_epochs=n_calib_epochs, # Передаем калибровочные числа\n",
    "#                     index_to_char_map=index_to_char, blank_idx=BLANK_IDX, pad_idx=PAD_IDX,\n",
    "#                     grad_clip_norm=TRAIN_CONFIG['gradient_clip_norm']\n",
    "#                 )\n",
    "#                 # Валидация\n",
    "#                 val_loss_c, val_lev_c, _ = validate_epoch(\n",
    "#                     model=temp_model, dataloader=temp_val_loader, criterion=criterion, device=device,\n",
    "#                     index_to_char_map=index_to_char, blank_idx=BLANK_IDX, pad_idx=PAD_IDX\n",
    "#                 )\n",
    "#                 print(f\"    Эпоха {epoch_calib}/{n_calib_epochs} -> Train Loss: {train_loss_c:.4f}, Val Loss: {val_loss_c:.4f}, Val Lev: {val_lev_c:.4f}\")\n",
    "#                 # Обновляем лучший результат *для текущего окна*\n",
    "#                 if np.isfinite(val_lev_c):\n",
    "#                     current_best_lev_for_window = min(current_best_lev_for_window, val_lev_c)\n",
    "\n",
    "#             # 7. Сохраняем лучший (или последний) результат для этого окна\n",
    "#             final_lev_for_window = current_best_lev_for_window\n",
    "#             calibration_results_rms[window_size] = final_lev_for_window\n",
    "#             duration = time.time() - start_calib_time\n",
    "#             print(f\"  Результат для окна {window_size}: Лучший Val Levenshtein = {final_lev_for_window:.4f} (Общее время: {duration:.2f} сек)\")\n",
    "\n",
    "#             # 8. Обновляем глобальный лучший результат\n",
    "#             if np.isfinite(final_lev_for_window) and final_lev_for_window < best_rms_lev:\n",
    "#                 best_rms_lev = final_lev_for_window\n",
    "#                 best_rms_window = window_size\n",
    "#                 print(f\"  ✨ Новый лучший глобальный результат!\")\n",
    "\n",
    "#         except Exception as calib_err:\n",
    "#             print(f\"!!! Ошибка при калибровке для window={window_size}: {calib_err} !!!\")\n",
    "#             traceback.print_exc(limit=1)\n",
    "#             calibration_results_rms[window_size] = float('inf') # Плохой результат при ошибке\n",
    "#         finally:\n",
    "#             # 9. ОЧИСТКА ПАМЯТИ после каждой итерации окна\n",
    "#             del temp_model, temp_optimizer, temp_scheduler, temp_train_loader, temp_val_loader\n",
    "#             del temp_train_dataset, temp_val_dataset\n",
    "#             torch.cuda.empty_cache() if device.type == 'cuda' else None\n",
    "#             print(f\"  Очистка памяти после окна {window_size} завершена.\")\n",
    "\n",
    "# # --- Вывод результатов калибровки ---\n",
    "# if calibration_results_rms: # Если словарь не пуст\n",
    "#     print(\"\\n--- Результаты калибровки сглаживания RMS ---\")\n",
    "#     print(f\"{'Окно RMS':<10} | {'Лучший Val Lev':<18}\")\n",
    "#     print(\"-\" * 31)\n",
    "#     for window, lev in sorted(calibration_results_rms.items()):\n",
    "#         lev_str = f\"{lev:.4f}\" if np.isfinite(lev) else \"Error/Inf\"\n",
    "#         best_marker = \"<- Лучший\" if window == best_rms_window else \"\"\n",
    "#         print(f\"{window:<10} | {lev_str:<18} {best_marker}\")\n",
    "#     print(\"-\" * 31)\n",
    "#     print(f\"Выбрано оптимальное окно для RMS: {best_rms_window} (Lev: {best_rms_lev:.4f})\")\n",
    "#     # !!! ОБНОВЛЯЕМ ОСНОВНУЮ КОНФИГУРАЦИЮ !!!\n",
    "#     print(f\"\\nОбновление AUDIO_CONFIG['{CALIBRATION_CONFIG['parameter']}'] = {best_rms_window}\")\n",
    "#     AUDIO_CONFIG[CALIBRATION_CONFIG['parameter']] = best_rms_window\n",
    "# else:\n",
    "#     print(\"\\nКалибровка RMS не проводилась или не дала результатов.\")\n",
    "#     best_rms_window = AUDIO_CONFIG.get('rms_smoothing_window_size', 1)\n",
    "#     print(f\"Используется значение RMS сглаживания из AUDIO_CONFIG: {best_rms_window}\")\n",
    "\n",
    "# print(\"\\n--- Ячейка 11.1: Калибровка RMS завершена ---\")\n",
    "# print(\"-\" * 50)\n",
    "# # ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 11.2: Блок Калибровки Типа Дельты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================================================================\n",
    "# # Ячейка 11.2: Калибровка Сглаживания Delta (MA) (с Полным Обучением)\n",
    "# # =============================================================================\n",
    "# print(\"--- Ячейка 11.2: Калибровка Сглаживания Delta MA (с Полным Обучением) ---\")\n",
    "\n",
    "# # --- Конфигурация Калибровки ---\n",
    "# BAND_CALIBRATION_CONFIG = {\n",
    "#     \"enabled\": True,\n",
    "#     \"parameter\": 'delta_ma_smoothing_window_size',\n",
    "#     \"values_to_try\": [1, 3], # Окна для проверки\n",
    "#     \"calibration_epochs\": 3, # Используем то же кол-во эпох\n",
    "#     \"metric\": 'Val Levenshtein'\n",
    "# }\n",
    "# print(f\"Калибровка '{BAND_CALIBRATION_CONFIG['parameter']}' включена.\")\n",
    "# print(f\"Значения для проверки: {BAND_CALIBRATION_CONFIG['values_to_try']}\")\n",
    "# print(f\"Количество эпох на каждое значение: {BAND_CALIBRATION_CONFIG['calibration_epochs']}\")\n",
    "# print(f\"Фиксированное окно RMS (из Ячейки 11.1): {AUDIO_CONFIG.get('rms_smoothing_window_size', 'N/A')}\")\n",
    "# print(f\"ПРЕДУПРЕЖДЕНИЕ: Этот процесс также может занять много времени!\")\n",
    "\n",
    "# # --- Проверки готовности ---\n",
    "# # Проверяем базовые компоненты и индексы из прошлой ячейки\n",
    "# missing_calib_vars_delta = [v for v in required_calib_vars if v not in globals() or globals()[v] is None] # Те же переменные, что и в 11.1\n",
    "# indices_exist = 'train_indices_calib' in globals() and 'val_indices_calib' in globals() \\\n",
    "#                 and train_indices_calib is not None and val_indices_calib is not None\n",
    "\n",
    "# if missing_calib_vars_delta:\n",
    "#      print(f\"!!! Ошибка: Отсутствуют компоненты для калибровки Delta: {missing_calib_vars_delta} !!!\")\n",
    "#      BAND_CALIBRATION_CONFIG['enabled'] = False\n",
    "# elif not indices_exist:\n",
    "#      print(f\"!!! Ошибка: Индексы для калибровки (train/val_indices_calib) не найдены. Запустите Ячейку 11.1. !!!\")\n",
    "#      BAND_CALIBRATION_CONFIG['enabled'] = False\n",
    "\n",
    "# # --- Калибровочный цикл для Delta ---\n",
    "# calibration_results_delta = {}\n",
    "# best_delta_window = 1 # По умолчанию 1\n",
    "# best_delta_lev = float('inf')\n",
    "\n",
    "# if BAND_CALIBRATION_CONFIG['enabled']:\n",
    "#     param_to_tune_delta = BAND_CALIBRATION_CONFIG['parameter']\n",
    "#     n_calib_epochs_delta = BAND_CALIBRATION_CONFIG['calibration_epochs']\n",
    "#     # !!! Определяем LR специально для калибровки (тот же, что и для RMS) !!!\n",
    "#     CALIBRATION_LR_DELTA = 5e-4\n",
    "#     print(f\"!!! Используется LR = {CALIBRATION_LR_DELTA:.0e} для калибровочных запусков Delta !!!\")\n",
    "\n",
    "#     for window_size_delta in BAND_CALIBRATION_CONFIG['values_to_try']:\n",
    "#         print(f\"\\n-- Тестирование {param_to_tune_delta} = {window_size_delta} --\")\n",
    "#         start_calib_time_delta = time.time()\n",
    "#         current_best_lev_for_window_d = float('inf')\n",
    "\n",
    "#         # 1. Создаем ВРЕМЕННУЮ конфигурацию аудио (с уже выбранным RMS окном)\n",
    "#         temp_audio_config_delta = AUDIO_CONFIG.copy()\n",
    "#         temp_audio_config_delta[param_to_tune_delta] = window_size_delta\n",
    "\n",
    "#         # 2. Создаем ВРЕМЕННЫЕ Dataset и DataLoader\n",
    "#         temp_model_d = None; temp_optimizer_d = None; temp_scheduler_d = None\n",
    "#         temp_train_loader_d = None; temp_val_loader_d = None\n",
    "#         try:\n",
    "#             # Создаем датасеты\n",
    "#             temp_train_dataset_d = MorseDataset(\n",
    "#                 dataframe=train_df.iloc[train_indices_calib].reset_index(drop=True),\n",
    "#                 audio_dir=EXTRACTED_AUDIO_DIR, char_to_index=char_to_index,\n",
    "#                 audio_config=temp_audio_config_delta, # ВРЕМЕННАЯ КОНФИГУРАЦИЯ\n",
    "#                 model_input_feature_dim=MODEL_CONFIG['input_feature_dim'],\n",
    "#                 train_config=TRAIN_CONFIG, is_train=True\n",
    "#             )\n",
    "#             temp_val_dataset_d = MorseDataset(\n",
    "#                 dataframe=train_df.iloc[val_indices_calib].reset_index(drop=True),\n",
    "#                 audio_dir=EXTRACTED_AUDIO_DIR, char_to_index=char_to_index,\n",
    "#                 audio_config=temp_audio_config_delta, # ВРЕМЕННАЯ КОНФИГУРАЦИЯ\n",
    "#                 model_input_feature_dim=MODEL_CONFIG['input_feature_dim'],\n",
    "#                 train_config=TRAIN_CONFIG, is_train=True\n",
    "#             )\n",
    "#             if len(temp_train_dataset_d) == 0 or len(temp_val_dataset_d) == 0:\n",
    "#                 print(\"!!! Ошибка: Временный калибровочный датасет Delta пуст! Пропуск шага.\")\n",
    "#                 continue\n",
    "\n",
    "#             # Создаем лоадеры\n",
    "#             bs = TRAIN_CONFIG['batch_size']; nw = TRAIN_CONFIG['num_workers']; pm = (device.type == 'cuda')\n",
    "#             temp_train_loader_d = DataLoader(temp_train_dataset_d, batch_size=bs, shuffle=True, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "#             temp_val_loader_d = DataLoader(temp_val_dataset_d, batch_size=bs*2, shuffle=False, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "#             print(f\"  Временные лоадеры Delta созданы: Train={len(temp_train_loader_d)} батчей, Val={len(temp_val_loader_d)} батчей\")\n",
    "\n",
    "#             # 3. Создаем НОВУЮ МОДЕЛЬ с нуля\n",
    "#             temp_model_d = MorseRecognizer(num_classes_ctc=NUM_CLASSES_CTC, **MODEL_CONFIG).to(device)\n",
    "\n",
    "#            # 4. Создаем НОВЫЙ ОПТИМИЗАТОР\n",
    "#             wd_calib = TRAIN_CONFIG['weight_decay']\n",
    "#             if TRAIN_CONFIG['optimizer'].lower() == 'adam':\n",
    "#                  temp_optimizer_d = optim.Adam(temp_model_d.parameters(), lr=CALIBRATION_LR_DELTA, weight_decay=wd_calib)\n",
    "#             else: temp_optimizer_d = optim.AdamW(temp_model_d.parameters(), lr=CALIBRATION_LR_DELTA, weight_decay=wd_calib)\n",
    "\n",
    "#             # 5. Создаем НОВЫЙ ПЛАНИРОВЩИК (!!! используем CALIBRATION_LR_DELTA !!!)\n",
    "#             steps_per_epoch_calib_d = len(temp_train_loader_d)\n",
    "#             if steps_per_epoch_calib_d == 0: raise ValueError(\"Калибровочный train loader Delta пуст!\")\n",
    "#             total_steps_calib_d = n_calib_epochs_delta * steps_per_epoch_calib_d\n",
    "#             final_div_calib = TRAIN_CONFIG.get('final_div_factor', 1e4) # Берем из основного\n",
    "#             temp_scheduler_d = OneCycleLR(\n",
    "#                 temp_optimizer_d,\n",
    "#                 max_lr=CALIBRATION_LR_DELTA, # !!! Явно указываем LR калибровки !!!\n",
    "#                 total_steps=total_steps_calib_d,\n",
    "#                 final_div_factor=final_div_calib\n",
    "#             )\n",
    "#             print(f\"  Новая модель, оптимизатор и планировщик Delta (LR={CALIBRATION_LR_DELTA:.0e}, Total Steps: {total_steps_calib_d}, final_div={final_div_calib:.0f}) созданы.\")\n",
    "\n",
    "\n",
    "#             # 6. Запускаем Цикл Обучения на n_calib_epochs_delta\n",
    "#             print(f\"  Запуск обучения Delta на {n_calib_epochs_delta} эпох...\")\n",
    "#             for epoch_calib_d in range(1, n_calib_epochs_delta + 1):\n",
    "#                 # Тренировка\n",
    "#                 train_loss_c, train_lev_c, _ = train_epoch(\n",
    "#                     model=temp_model_d, dataloader=temp_train_loader_d, criterion=criterion,\n",
    "#                     optimizer=temp_optimizer_d, scheduler=temp_scheduler_d, device=device,\n",
    "#                     epoch_num=epoch_calib_d, total_epochs=n_calib_epochs_delta,\n",
    "#                     index_to_char_map=index_to_char, blank_idx=BLANK_IDX, pad_idx=PAD_IDX,\n",
    "#                     grad_clip_norm=TRAIN_CONFIG['gradient_clip_norm']\n",
    "#                 )\n",
    "#                 # Валидация\n",
    "#                 val_loss_c, val_lev_c, _ = validate_epoch(\n",
    "#                     model=temp_model_d, dataloader=temp_val_loader_d, criterion=criterion, device=device,\n",
    "#                     index_to_char_map=index_to_char, blank_idx=BLANK_IDX, pad_idx=PAD_IDX\n",
    "#                 )\n",
    "#                 print(f\"    Эпоха {epoch_calib_d}/{n_calib_epochs_delta} -> Train Loss: {train_loss_c:.4f}, Val Loss: {val_loss_c:.4f}, Val Lev: {val_lev_c:.4f}\")\n",
    "#                 if np.isfinite(val_lev_c):\n",
    "#                     current_best_lev_for_window_d = min(current_best_lev_for_window_d, val_lev_c)\n",
    "\n",
    "#             # 7. Сохраняем лучший результат для этого окна Delta\n",
    "#             final_lev_for_window_d = current_best_lev_for_window_d\n",
    "#             calibration_results_delta[window_size_delta] = final_lev_for_window_d\n",
    "#             duration_d = time.time() - start_calib_time_delta\n",
    "#             print(f\"  Результат для окна Delta {window_size_delta}: Лучший Val Levenshtein = {final_lev_for_window_d:.4f} (Общее время: {duration_d:.2f} сек)\")\n",
    "\n",
    "#             # 8. Обновляем глобальный лучший результат\n",
    "#             if np.isfinite(final_lev_for_window_d) and final_lev_for_window_d < best_delta_lev:\n",
    "#                 best_delta_lev = final_lev_for_window_d\n",
    "#                 best_delta_window = window_size_delta\n",
    "#                 print(f\"  ✨ Новый лучший глобальный результат для Delta!\")\n",
    "\n",
    "#         except Exception as calib_err_d:\n",
    "#             print(f\"!!! Ошибка при калибровке Delta для window={window_size_delta}: {calib_err_d} !!!\")\n",
    "#             traceback.print_exc(limit=1)\n",
    "#             calibration_results_delta[window_size_delta] = float('inf')\n",
    "#         finally:\n",
    "#             # 9. ОЧИСТКА ПАМЯТИ\n",
    "#             del temp_model_d, temp_optimizer_d, temp_scheduler_d, temp_train_loader_d, temp_val_loader_d\n",
    "#             del temp_train_dataset_d, temp_val_dataset_d\n",
    "#             torch.cuda.empty_cache() if device.type == 'cuda' else None\n",
    "#             print(f\"  Очистка памяти после окна Delta {window_size_delta} завершена.\")\n",
    "\n",
    "# # --- Вывод результатов калибровки Delta ---\n",
    "# if calibration_results_delta:\n",
    "#     print(\"\\n--- Результаты калибровки сглаживания Delta MA ---\")\n",
    "#     print(f\"{'Окно Delta':<10} | {'Лучший Val Lev':<18}\")\n",
    "#     print(\"-\" * 31)\n",
    "#     for window, lev in sorted(calibration_results_delta.items()):\n",
    "#         lev_str = f\"{lev:.4f}\" if np.isfinite(lev) else \"Error/Inf\"\n",
    "#         best_marker = \"<- Лучший\" if window == best_delta_window else \"\"\n",
    "#         print(f\"{window:<10} | {lev_str:<18} {best_marker}\")\n",
    "#     print(\"-\" * 31)\n",
    "#     print(f\"Выбрано оптимальное окно для Delta MA: {best_delta_window} (Lev: {best_delta_lev:.4f})\")\n",
    "#     # !!! ОБНОВЛЯЕМ ОСНОВНУЮ КОНФИГУРАЦИЮ !!!\n",
    "#     print(f\"\\nОбновление AUDIO_CONFIG['{BAND_CALIBRATION_CONFIG['parameter']}'] = {best_delta_window}\")\n",
    "#     AUDIO_CONFIG[BAND_CALIBRATION_CONFIG['parameter']] = best_delta_window\n",
    "\n",
    "#     # !!! ОБНОВЛЕНИЕ СУФФИКСОВ И ПУТЕЙ ПОСЛЕ ВСЕХ КАЛИБРОВОК !!!\n",
    "#     print(\"\\nПересчет суффиксов и финальных путей с учетом калибровки...\")\n",
    "#     rms_w = AUDIO_CONFIG.get('rms_smoothing_window_size', 1)\n",
    "#     delta_w = AUDIO_CONFIG.get('delta_ma_smoothing_window_size', 1)\n",
    "#     rms_smooth_suffix_final = f\"_SmoothRMSMA{rms_w}\" if rms_w > 1 else \"\"\n",
    "#     delta_smooth_suffix_final = f\"_SmoothDeltaMA{delta_w}\" if delta_w > 1 else \"\"\n",
    "#     delta_type_suffix_final = f\"_Delta{AUDIO_CONFIG['delta_type']}\"\n",
    "#     # Собираем финальный суффикс (BASE_FILENAME_SUFFIX_FINAL из Ячейки 2)\n",
    "#     FINAL_SUFFIX = f\"{delta_type_suffix_final}{rms_smooth_suffix_final}{delta_smooth_suffix_final}\"\n",
    "#     # Обновляем глобальные переменные путей\n",
    "#     BEST_MODEL_PATH = Path(f\"{MODEL_SAVE_PATH_TEMPLATE_FINAL}{FINAL_SUFFIX}.pth\")\n",
    "#     PARAMS_PATH = Path(f\"{PARAMS_SAVE_PATH_TEMPLATE_FINAL}{FINAL_SUFFIX}.json\")\n",
    "#     print(f\"Финальный суффикс: {FINAL_SUFFIX}\")\n",
    "#     print(f\"Финальный путь модели: {BEST_MODEL_PATH}\")\n",
    "#     print(f\"Финальный путь параметров: {PARAMS_PATH}\")\n",
    "# else:\n",
    "#     print(\"\\nКалибровка Delta MA не проводилась или не дала результатов.\")\n",
    "#     best_delta_window = AUDIO_CONFIG.get('delta_ma_smoothing_window_size', 1)\n",
    "#     print(f\"Используется значение Delta MA сглаживания из AUDIO_CONFIG: {best_delta_window}\")\n",
    "#     print(\"Финальные пути НЕ обновлены, если калибровка не проводилась.\")\n",
    "\n",
    "# print(\"\\n--- Ячейка 11.2: Калибровка Delta MA завершена ---\")\n",
    "# print(\"-\" * 50)\n",
    "# # ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейка 11.3: Конфигурация Калибровки Частотного Диапазона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейка 11.4: Запуск Калибровки Частотного Диапазона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 12.2: Визуализация Результатов Калибровки Типа Дельты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 12.1: Финальная Конфигурация После Калибровки ---\n",
      "Финальные параметры AUDIO_CONFIG, которые будут использоваться для основного обучения:\n",
      "{\n",
      "  \"sample_rate\": 8000,\n",
      "  \"frame_length_rms\": 384,\n",
      "  \"hop_length_rms\": 96,\n",
      "  \"filter_order\": 5,\n",
      "  \"filter_fmin\": 0,\n",
      "  \"filter_fmax\": 3999,\n",
      "  \"delta_type\": \"standard\",\n",
      "  \"delta_alpha\": 1.0,\n",
      "  \"rms_smoothing_window_size\": 1,\n",
      "  \"delta_ma_smoothing_window_size\": 1\n",
      "}\n",
      "\n",
      "Проверка инициализации MorseDataset с финальной конфигурацией:\n",
      "MorseDataset создан: is_train=False, delta_type='standard', rms_smooth=Отключено, delta_smooth=Отключено, noise_level=Отключен\n",
      "MorseDataset успешно инициализирован с финальной конфигурацией.\n",
      "\n",
      "Финальные пути для сохранения:\n",
      "  Модель: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.pth\n",
      "  Параметры: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\params_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.json\n",
      "\n",
      "--- Ячейка 12.1: Проверка конфигурации завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 12.1: Вывод Финальной Конфигурации (Упрощенная)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 12.1: Финальная Конфигурация После Калибровки ---\")\n",
    "\n",
    "print(\"Финальные параметры AUDIO_CONFIG, которые будут использоваться для основного обучения:\")\n",
    "print(json.dumps(AUDIO_CONFIG, indent=2))\n",
    "\n",
    "print(\"\\nПроверка инициализации MorseDataset с финальной конфигурацией:\")\n",
    "try:\n",
    "    # Попробуем создать экземпляр Dataset с финальными параметрами\n",
    "    final_check_ds = MorseDataset(\n",
    "        dataframe=train_df.head(1), # Берем только одну строку для быстрой проверки\n",
    "        audio_dir=EXTRACTED_AUDIO_DIR,\n",
    "        char_to_index=char_to_index,\n",
    "        audio_config=AUDIO_CONFIG, # ФИНАЛЬНАЯ КОНФИГУРАЦИЯ\n",
    "        model_input_feature_dim=MODEL_CONFIG['input_feature_dim'],\n",
    "        train_config=TRAIN_CONFIG,\n",
    "        is_train=False # Проверяем как для инференса (не нужна колонка message)\n",
    "    )\n",
    "    print(\"MorseDataset успешно инициализирован с финальной конфигурацией.\")\n",
    "    del final_check_ds # Удаляем временный объект\n",
    "except Exception as e:\n",
    "    print(f\"!!! Ошибка при инициализации MorseDataset с финальной конфигурацией: {e} !!!\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\nФинальные пути для сохранения:\")\n",
    "print(f\"  Модель: {BEST_MODEL_PATH}\")\n",
    "print(f\"  Параметры: {PARAMS_PATH}\")\n",
    "\n",
    "print(\"\\n--- Ячейка 12.1: Проверка конфигурации завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 12.3: Визуализация Результатов Калибровки Частотного Диапазона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 12.4: Интерактивная Визуализация Сигналов и Дельт для Разных Фильтров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # =============================================================================\n",
    "# # Ячейка 12.4: Интерактивная Визуализация (ИСПРАВЛЕНА ОШИБКА ValueError)\n",
    "# # =============================================================================\n",
    "# print(\"--- Ячейка 12.4: Интерактивная Визуализация Признаков (Исправлена ошибка) ---\")\n",
    "\n",
    "# # Проверка доступности ipywidgets и данных\n",
    "# try:\n",
    "#     import ipywidgets as widgets; from IPython.display import display, Audio, clear_output\n",
    "#     import matplotlib.pyplot as plt; import librosa; import numpy as np\n",
    "#     import scipy.signal as signal; import pandas as pd; from pathlib import Path\n",
    "#     import traceback; from typing import Union # Добавили Union для совместимости\n",
    "#     IPYWIDGETS_AVAILABLE = True\n",
    "# except ImportError: IPYWIDGETS_AVAILABLE = False\n",
    "\n",
    "# if not IPYWIDGETS_AVAILABLE: print(\"Ошибка: ipywidgets недоступен.\")\n",
    "# elif 'train_df' not in globals() or train_df is None or train_df.empty: print(\"Ошибка: train_df не найден.\")\n",
    "# elif 'AUDIO_CONFIG' not in globals() or not AUDIO_CONFIG: print(\"Ошибка: AUDIO_CONFIG не найден.\")\n",
    "# elif 'EXTRACTED_AUDIO_DIR' not in globals() or not EXTRACTED_AUDIO_DIR.is_dir(): print(f\"Ошибка: Директория аудио ({EXTRACTED_AUDIO_DIR}) не найдена.\")\n",
    "# # Добавим проверки для переменных, нужных временному MorseDataset\n",
    "# elif 'TRAIN_CONFIG' not in globals() or not TRAIN_CONFIG: print(\"Ошибка: TRAIN_CONFIG не найден.\")\n",
    "# elif 'MorseDataset' not in globals(): print(\"Ошибка: Класс MorseDataset не определен (запустите Ячейку 5).\")\n",
    "# else:\n",
    "#     # --- Параметры из Конфига ---\n",
    "#     sr_vis = AUDIO_CONFIG['sample_rate']; frame_len_vis = AUDIO_CONFIG['frame_length_rms']\n",
    "#     hop_len_vis = AUDIO_CONFIG['hop_length_rms']; delta_type_vis = AUDIO_CONFIG.get('delta_type', 'standard')\n",
    "#     delta_alpha_vis = AUDIO_CONFIG.get('delta_alpha', 1.0)\n",
    "#     fmin_vis = AUDIO_CONFIG.get('filter_fmin', 0)\n",
    "#     fmax_vis = AUDIO_CONFIG.get('filter_fmax', 4000)\n",
    "\n",
    "#     # --- Вспомогательная Функция Расчета (ИСПРАВЛЕНО СОЗДАНИЕ MorseDataset) ---\n",
    "#     def calculate_vis_features_raw(\n",
    "#         waveform_np: np.ndarray, sr_vis: int, frame_len: int, hop_len: int,\n",
    "#         delta_type: str, delta_alpha: float\n",
    "#         ):\n",
    "#         \"\"\" Расчет RMS и Дельты БЕЗ сглаживания и нормализации. \"\"\"\n",
    "#         rms_envelope = np.array([]); delta_final = np.array([])\n",
    "#         if not isinstance(waveform_np, np.ndarray) or waveform_np.size == 0:\n",
    "#              return rms_envelope, delta_final\n",
    "#         try:\n",
    "#             # Фильтрация (используем параметры из AUDIO_CONFIG)\n",
    "#             # !!! ИСПРАВЛЕНИЕ: Добавлено is_train=False !!!\n",
    "#             temp_dataset_instance = MorseDataset(\n",
    "#                 pd.DataFrame({'id':['dummy']}), Path('.'), {}, AUDIO_CONFIG, 2, TRAIN_CONFIG, is_train=False\n",
    "#             )\n",
    "#             waveform_filtered = temp_dataset_instance._apply_filter(waveform_np)\n",
    "#             del temp_dataset_instance\n",
    "\n",
    "#             if waveform_filtered.size == 0: return rms_envelope, delta_final\n",
    "\n",
    "#             # 1. Расчет RMS\n",
    "#             rms_envelope = librosa.feature.rms(y=waveform_filtered, frame_length=frame_len, hop_length=hop_len, center=True, pad_mode='reflect')[0]\n",
    "#             if rms_envelope.size < 2: return rms_envelope, delta_final\n",
    "\n",
    "#             # 2. Расчет Дельты\n",
    "#             delta_standard = np.diff(rms_envelope, n=1, prepend=rms_envelope[0])\n",
    "#             delta_final = delta_standard # Default\n",
    "#             if delta_type == 'cubed': delta_final = np.power(delta_alpha * delta_standard, 3)\n",
    "#             elif delta_type == 'quadratic_signed': delta_final = delta_standard * np.abs(delta_standard)\n",
    "\n",
    "#             return rms_envelope, delta_final\n",
    "#         except Exception as e:\n",
    "#              print(f\"Ошибка расчета признаков (vis): {e}\")\n",
    "#              traceback.print_exc(limit=1)\n",
    "#              return rms_envelope, delta_final\n",
    "\n",
    "#     # --- Создание виджетов (Только выбор файла) ---\n",
    "#     file_ids_vis = train_df['id'].unique().tolist();\n",
    "#     if len(file_ids_vis) > 500: file_ids_vis = file_ids_vis[:500]\n",
    "#     file_dropdown_vis = widgets.Dropdown(options=file_ids_vis, description='Аудиофайл:', style={'description_width': 'initial'}, layout=widgets.Layout(width='80%'))\n",
    "#     output_area_vis = widgets.Output()\n",
    "\n",
    "#     # --- Функция обновления ---\n",
    "#     def update_visualization_interactive(change):\n",
    "#         selected_file_id = file_dropdown_vis.value\n",
    "\n",
    "#         with output_area_vis:\n",
    "#             clear_output(wait=True)\n",
    "#             print(f\"Файл: {selected_file_id} (Сглаживание отключено)\")\n",
    "#             audio_path = EXTRACTED_AUDIO_DIR / selected_file_id\n",
    "#             if not audio_path.is_file(): print(f\"Ошибка: Файл {audio_path} не найден!\"); return\n",
    "\n",
    "#             try:\n",
    "#                 # Загрузка и ресэмплинг\n",
    "#                 waveform_orig, sr_orig = librosa.load(audio_path, sr=sr_vis, mono=True)\n",
    "#                 if waveform_orig.size == 0: print(\"Ошибка: Пустой waveform\"); return\n",
    "\n",
    "#                 display(Audio(data=waveform_orig, rate=sr_vis))\n",
    "\n",
    "#                 # Расчет признаков БЕЗ СГЛАЖИВАНИЯ\n",
    "#                 rms_vis, delta_vis = calculate_vis_features_raw(\n",
    "#                     waveform_orig, sr_vis, frame_len_vis, hop_len_vis,\n",
    "#                     delta_type_vis, delta_alpha_vis\n",
    "#                 )\n",
    "\n",
    "#                 # Отрисовка графиков\n",
    "#                 fig, axes = plt.subplots(2, 1, figsize=(14, 6), sharex=True)\n",
    "#                 title_str = f\"Признаки для: {selected_file_id} | Фильтр: {fmin_vis}-{fmax_vis}Hz | Без сглаживания\"\n",
    "#                 fig.suptitle(title_str, fontsize=14)\n",
    "#                 times_vis = librosa.times_like(rms_vis, sr=sr_vis, hop_length=hop_len_vis) if rms_vis.size > 0 else np.array([])\n",
    "#                 # График RMS\n",
    "#                 ax_rms = axes[0]; ax_rms.plot(times_vis, rms_vis, label=f'RMS (Raw)', color='blue', linewidth=1)\n",
    "#                 ax_rms.set_title(\"RMS\"); ax_rms.set_ylabel(\"Амплитуда RMS\"); ax_rms.grid(True, linestyle=':'); ax_rms.legend()\n",
    "#                 if rms_vis.size > 0 : ax_rms.set_ylim(0, np.max(rms_vis) * 1.1 if np.max(rms_vis) > 0 else 1)\n",
    "#                 # График Дельты\n",
    "#                 ax_delta = axes[1]; delta_label = f'Delta ({delta_type_vis}, Raw)'\n",
    "#                 ax_delta.plot(times_vis, delta_vis, label=delta_label, color='red', linewidth=1); ax_delta.axhline(0, color='black', linestyle=':', linewidth=1)\n",
    "#                 ax_delta.set_title(\"Delta\"); ax_delta.set_ylabel(\"Значение Дельты\"); ax_delta.grid(True, linestyle=':'); ax_delta.legend(); ax_delta.set_xlabel(\"Время (с)\")\n",
    "#                 if delta_vis.size > 0: min_d, max_d = np.min(delta_vis), np.max(delta_vis); margin = (max_d - min_d) * 0.1 if (max_d - min_d) > 1e-6 else 0.1; ax_delta.set_ylim(min_d - margin, max_d + margin)\n",
    "#                 plt.tight_layout(rect=[0, 0.03, 1, 0.93]); plt.show()\n",
    "\n",
    "#             except Exception as e: print(f\"Ошибка визуализации {selected_file_id}: {e}\"); traceback.print_exc(limit=1)\n",
    "\n",
    "#     # --- Привязка callback и отображение ---\n",
    "#     file_dropdown_vis.observe(update_visualization_interactive, names='value')\n",
    "\n",
    "#     print(\"Инициализация интерактивных виджетов...\")\n",
    "#     controls_vis = widgets.VBox([\n",
    "#         widgets.HTML(\"<b>Визуализация признаков (RMS и Delta):</b>\"),\n",
    "#         file_dropdown_vis,\n",
    "#     ])\n",
    "#     ui_vis = widgets.VBox([controls_vis, output_area_vis])\n",
    "#     display(ui_vis)\n",
    "#     if not train_df.empty: update_visualization_interactive(None)\n",
    "#     else: print(\"Нет данных для визуализации.\")\n",
    "\n",
    "# print(\"\\n--- Ячейка 12.4: Интерактивная визуализация готова (ошибка исправлена) ---\")\n",
    "# print(\"-\" * 50)\n",
    "# # ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 13: Основной Цикл Обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 13: Запуск Основного Цикла Обучения ---\n",
      "\n",
      "Подготовка Dataset и DataLoaders...\n",
      "MorseDataset создан: is_train=True, delta_type='standard', rms_smooth=Отключено, delta_smooth=Отключено, noise_level=Отключен\n",
      "Полный обучающий датасет создан: 30000 записей.\n",
      "Разделение данных: Train=27000, Validation=3000\n",
      "Созданы Train (3375 батчей) и Val (188 батчей) DataLoaders.\n",
      "\n",
      "Инициализация OneCycleLR: total_steps=50625, max_lr=3.0e-04, final_div_factor=100\n",
      "  Расчетный минимальный LR: 3.00e-06\n",
      "Планировщик OneCycleLR успешно создан.\n",
      "\n",
      "--- Начало основного обучения (15 эпох) ---\n",
      "Модель будет сохранена как: model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.pth\n",
      "\n",
      "--- Эпоха 1/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b865e0e9c6d44d7aa5b7f5a4413bcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 1/15 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee16163bcd547b7b56b95f055bce061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоги Эпохи 1/15 | Время: 420.59 сек | Ср.LR: 2.341e-05\n",
      "  Train Loss: 4.6798 | Train Levenshtein: 9.1089\n",
      "  Val Loss:   3.0670 | Val Levenshtein:   8.3767\n",
      "  Примеры декодирования (Greedy):\n",
      "    1: '' | 'ФААР834ОМП'\n",
      "    2: ' ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    3: '5' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    4: '' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    5: '' | '#6ЧФ8ЮО'\n",
      "  ✨ Val Lev улучшился: inf -> 8.3767. Сохранение модели...\n",
      "  Модель сохранена в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.pth\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Эпоха 2/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe61d9a2d494042b29a7c8fee78a3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 2/15 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb57c8cfdf394e38ad926df5e8527b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоги Эпохи 2/15 | Время: 387.07 сек | Ср.LR: 8.545e-05\n",
      "  Train Loss: 1.0091 | Train Levenshtein: 2.2689\n",
      "  Val Loss:   0.4928 | Val Levenshtein:   1.0880\n",
      "  Примеры декодирования (Greedy):\n",
      "    1: 'ФААР83Ю#МП' | 'ФААР834ОМП'\n",
      "    2: 'ТС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    3: 'ЬЛННЖЗУЯН3ЭХЛ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    4: 'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    5: '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "  ✨ Val Lev улучшился: 8.3767 -> 1.0880. Сохранение модели...\n",
      "  Модель сохранена в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.pth\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Эпоха 3/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26b4ee6a63546a4859326a87f7a3132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 3/15 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3786f6e339749ec9b889cda1ef36beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоги Эпохи 3/15 | Время: 318.51 сек | Ср.LR: 1.805e-04\n",
      "  Train Loss: 0.5165 | Train Levenshtein: 1.1506\n",
      "  Val Loss:   0.4219 | Val Levenshtein:   0.9723\n",
      "  Примеры декодирования (Greedy):\n",
      "    1: 'ФААР83ЮМП' | 'ФААР834ОМП'\n",
      "    2: 'Т8С ЖЩ0ЗЕБМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    3: 'ЬЛННЖЗУЯН3ЭХЛ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    4: 'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    5: '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "  ✨ Val Lev улучшился: 1.0880 -> 0.9723. Сохранение модели...\n",
      "  Модель сохранена в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.pth\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Эпоха 4/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2abe75f27fe4849bea212da04469832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 4/15 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44acf8d32dfe4a9e8ddaba82cc7f1c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоги Эпохи 4/15 | Время: 249.04 сек | Ср.LR: 2.641e-04\n",
      "  Train Loss: 0.4455 | Train Levenshtein: 1.0288\n",
      "  Val Loss:   0.3849 | Val Levenshtein:   0.9047\n",
      "  Примеры декодирования (Greedy):\n",
      "    1: 'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    2: 'ТОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    3: 'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    4: 'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    5: '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "  ✨ Val Lev улучшился: 0.9723 -> 0.9047. Сохранение модели...\n",
      "  Модель сохранена в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.pth\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Эпоха 5/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23bf8a3b0b1430eab9194f4c8bd1eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 5/15 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db92641f7c984a49b57a8093cd51acba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоги Эпохи 5/15 | Время: 258.21 сек | Ср.LR: 2.983e-04\n",
      "  Train Loss: 0.4020 | Train Levenshtein: 0.9552\n",
      "  Val Loss:   0.3642 | Val Levenshtein:   0.8630\n",
      "  Примеры декодирования (Greedy):\n",
      "    1: 'ФААР83ЮОМПЪ' | 'ФААР834ОМП'\n",
      "    2: 'Т0С ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    3: 'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    4: 'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    5: '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "  ✨ Val Lev улучшился: 0.9047 -> 0.8630. Сохранение модели...\n",
      "  Модель сохранена в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.pth\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Эпоха 6/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f448efc3b83411bbbfb4e9d52d61ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 6/15 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение прервано пользователем (KeyboardInterrupt).\n",
      "\n",
      "--- Основное Обучение Завершено ---\n",
      "Общее время обучения: 30.80 мин\n",
      "Лучший достигнутый Val Levenshtein: 0.8630\n",
      "Лучшая модель (state_dict) сохранена в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.pth\n",
      "\n",
      "Сохранение финальных параметров конфигурации...\n",
      "Параметры конфигурации сохранены в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\params_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR3e-04_WD1e-04_Deltastandard.json\n",
      "\n",
      "Построение графиков истории обучения...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 13: Основной Цикл Обучения\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 13: Запуск Основного Цикла Обучения ---\")\n",
    "\n",
    "# --- Проверки готовности ---\n",
    "required_vars = [\n",
    "    'model_created_successfully', 'model', 'criterion', 'optimizer',\n",
    "    'train_df', 'index_to_char', 'char_to_index', 'AUDIO_CONFIG', 'MODEL_CONFIG', 'TRAIN_CONFIG',\n",
    "    'device', 'collate_fn', 'MorseDataset', 'train_epoch', 'validate_epoch',\n",
    "    'BEST_MODEL_PATH', 'PARAMS_PATH', 'EXTRACTED_AUDIO_DIR',\n",
    "    'BLANK_IDX', 'PAD_IDX'\n",
    "]\n",
    "missing_vars = [v for v in required_vars if v not in globals() or globals()[v] is None]\n",
    "if missing_vars:\n",
    "     raise SystemExit(f\"Остановка: Отсутствуют необходимые компоненты для обучения: {missing_vars}\")\n",
    "if not model_created_successfully:\n",
    "     raise SystemExit(\"Остановка: Модель не была успешно создана.\")\n",
    "\n",
    "# --- Подготовка Dataset и DataLoaders ---\n",
    "train_loader, val_loader = None, None\n",
    "main_loaders_ready = False\n",
    "print(\"\\nПодготовка Dataset и DataLoaders...\")\n",
    "try:\n",
    "    # Создаем Dataset с финальной конфигурацией\n",
    "    full_train_dataset = MorseDataset(\n",
    "        dataframe=train_df,\n",
    "        audio_dir=EXTRACTED_AUDIO_DIR,\n",
    "        char_to_index=char_to_index,\n",
    "        audio_config=AUDIO_CONFIG, # Финальная конфигурация\n",
    "        model_input_feature_dim=MODEL_CONFIG['input_feature_dim'],\n",
    "        train_config=TRAIN_CONFIG, # Финальная конфигурация\n",
    "        is_train=True\n",
    "    )\n",
    "    print(f\"Полный обучающий датасет создан: {len(full_train_dataset)} записей.\")\n",
    "    if len(full_train_dataset) == 0: raise ValueError(\"Обучающий датасет пуст!\")\n",
    "\n",
    "    # Разделение на train/validation\n",
    "    dataset_size = len(full_train_dataset)\n",
    "    val_split_ratio = TRAIN_CONFIG['validation_split_ratio']\n",
    "    val_size = int(np.floor(val_split_ratio * dataset_size))\n",
    "    train_size = dataset_size - val_size\n",
    "    if train_size <= 0 or val_size <= 0:\n",
    "        raise ValueError(f\"Некорректное разделение данных: Train={train_size}, Val={val_size}\")\n",
    "    print(f\"Разделение данных: Train={train_size}, Validation={val_size}\")\n",
    "\n",
    "    # Выполняем разделение с фиксированным SEED для воспроизводимости\n",
    "    train_subset, val_subset = random_split(\n",
    "        full_train_dataset,\n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(TRAIN_CONFIG['base_seed'])\n",
    "    )\n",
    "\n",
    "    # Создаем DataLoaders\n",
    "    main_batch_size = TRAIN_CONFIG['batch_size']\n",
    "    main_num_workers = TRAIN_CONFIG['num_workers']\n",
    "    pin_memory_flag = (device.type == 'cuda') # Включаем для ускорения на GPU\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_subset, batch_size=main_batch_size, shuffle=True, # Перемешиваем обучающую выборку\n",
    "        collate_fn=collate_fn, num_workers=main_num_workers, pin_memory=pin_memory_flag\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_subset, batch_size=main_batch_size * 2, shuffle=False, # Валидационную не перемешиваем\n",
    "        collate_fn=collate_fn, num_workers=main_num_workers, pin_memory=pin_memory_flag\n",
    "    )\n",
    "    print(f\"Созданы Train ({len(train_loader)} батчей) и Val ({len(val_loader)} батчей) DataLoaders.\")\n",
    "    main_loaders_ready = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Критическая ошибка при создании Dataset/DataLoaders: {e}\")\n",
    "    traceback.print_exc()\n",
    "    main_loaders_ready = False\n",
    "\n",
    "# --- Инициализация Планировщика OneCycleLR ---\n",
    "scheduler = None\n",
    "if main_loaders_ready and train_loader is not None:\n",
    "    try:\n",
    "        steps_per_epoch = len(train_loader)\n",
    "        if steps_per_epoch == 0: raise ValueError(\"Train loader имеет 0 батчей!\")\n",
    "        total_steps = TRAIN_CONFIG['num_epochs'] * steps_per_epoch\n",
    "        max_lr_scheduler = TRAIN_CONFIG['learning_rate'] # Берем из конфига\n",
    "        final_div = TRAIN_CONFIG.get('final_div_factor', 1e4) # Берем из конфига (или дефолт)\n",
    "\n",
    "        print(f\"\\nИнициализация OneCycleLR: total_steps={total_steps}, max_lr={max_lr_scheduler:.1e}, final_div_factor={final_div:.0f}\")\n",
    "        min_lr_calc = max_lr_scheduler / final_div\n",
    "        print(f\"  Расчетный минимальный LR: {min_lr_calc:.2e}\")\n",
    "\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=max_lr_scheduler,\n",
    "            total_steps=total_steps,\n",
    "            pct_start=0.3,\n",
    "            anneal_strategy='cos',\n",
    "            final_div_factor=final_div # !!! Передаем параметр сюда !!!\n",
    "        )\n",
    "        print(\"Планировщик OneCycleLR успешно создан.\")\n",
    "    except Exception as e: print(f\"!!! Ошибка инициализации OneCycleLR: {e} !!!\"); traceback.print_exc(); scheduler = None; main_loaders_ready = False\n",
    "\n",
    "# --- Основной Цикл Обучения ---\n",
    "if main_loaders_ready and scheduler is not None: # Проверяем и scheduler\n",
    "    print(f\"\\n--- Начало основного обучения ({TRAIN_CONFIG['num_epochs']} эпох) ---\")\n",
    "    print(f\"Модель будет сохранена как: {BEST_MODEL_PATH.name}\")\n",
    "    start_time_total = time.time()\n",
    "    best_val_levenshtein = float('inf'); epochs_without_improvement = 0\n",
    "    # Словарь для хранения истории обучения\n",
    "    training_history = {'train_loss': [], 'train_lev': [], 'val_loss': [], 'val_lev': [], 'lr': []}\n",
    "\n",
    "    try:\n",
    "        for epoch in range(1, TRAIN_CONFIG['num_epochs'] + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            print(f\"\\n--- Эпоха {epoch}/{TRAIN_CONFIG['num_epochs']} ---\")\n",
    "\n",
    "            # --- Тренировка ---\n",
    "            avg_train_loss, avg_train_lev, avg_epoch_lr = train_epoch(\n",
    "                model=model, dataloader=train_loader, criterion=criterion,\n",
    "                optimizer=optimizer, scheduler=scheduler, device=device,\n",
    "                epoch_num=epoch, total_epochs=TRAIN_CONFIG['num_epochs'],\n",
    "                index_to_char_map=index_to_char, blank_idx=BLANK_IDX, pad_idx=PAD_IDX,\n",
    "                grad_clip_norm=TRAIN_CONFIG['gradient_clip_norm']\n",
    "            )\n",
    "\n",
    "            # --- Валидация ---\n",
    "            avg_val_loss, avg_val_lev, val_examples = validate_epoch(\n",
    "                model=model, dataloader=val_loader, criterion=criterion, device=device,\n",
    "                index_to_char_map=index_to_char, blank_idx=BLANK_IDX, pad_idx=PAD_IDX\n",
    "            )\n",
    "\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "\n",
    "            # --- Запись истории ---\n",
    "            training_history['train_loss'].append(avg_train_loss)\n",
    "            training_history['train_lev'].append(avg_train_lev)\n",
    "            training_history['val_loss'].append(avg_val_loss)\n",
    "            training_history['val_lev'].append(avg_val_lev)\n",
    "            training_history['lr'].append(avg_epoch_lr) # Записываем средний LR за эпоху\n",
    "\n",
    "            # --- Вывод результатов эпохи ---\n",
    "            print(f\"\\nИтоги Эпохи {epoch}/{TRAIN_CONFIG['num_epochs']} | Время: {epoch_duration:.2f} сек | Ср.LR: {avg_epoch_lr:.3e}\")\n",
    "            print(f\"  Train Loss: {avg_train_loss:.4f} | Train Levenshtein: {avg_train_lev:.4f}\")\n",
    "            print(f\"  Val Loss:   {avg_val_loss:.4f} | Val Levenshtein:   {avg_val_lev:.4f}\")\n",
    "            print(\"  Примеры декодирования (Greedy):\")\n",
    "            for i, (pred, real) in enumerate(val_examples[:5]): # Выводим первые 5 пар\n",
    "                print(f\"    {i+1}: '{pred[:70]}' | '{real[:70]}'\") # Ограничиваем длину вывода\n",
    "\n",
    "            # --- Сохранение лучшей модели и Early Stopping ---\n",
    "            # Проверяем, что val_lev конечен и меньше текущего лучшего\n",
    "            if np.isfinite(avg_val_lev) and avg_val_lev < best_val_levenshtein:\n",
    "                print(f\"  ✨ Val Lev улучшился: {best_val_levenshtein:.4f} -> {avg_val_lev:.4f}. Сохранение модели...\")\n",
    "                best_val_levenshtein = avg_val_lev\n",
    "                try:\n",
    "                    # Сохраняем только state_dict модели\n",
    "                    torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "                    print(f\"  Модель сохранена в: {BEST_MODEL_PATH}\")\n",
    "                except Exception as save_err:\n",
    "                    print(f\"  !!! Ошибка при сохранении модели: {save_err} !!!\")\n",
    "                epochs_without_improvement = 0 # Сбрасываем счетчик\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "                print(f\"  Val Lev не улучшился ({avg_val_lev:.4f} vs best {best_val_levenshtein:.4f}). Эпох без улучшений: {epochs_without_improvement}/{TRAIN_CONFIG['early_stopping_patience']}\")\n",
    "\n",
    "            # Проверка условия для ранней остановки\n",
    "            if epochs_without_improvement >= TRAIN_CONFIG['early_stopping_patience']:\n",
    "                print(f\"\\n❗️ Ранняя остановка! Нет улучшений Val Levenshtein в течение {TRAIN_CONFIG['early_stopping_patience']} эпох.\")\n",
    "                break # Прерываем цикл обучения\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nОбучение прервано пользователем (KeyboardInterrupt).\")\n",
    "    except RuntimeError as e:\n",
    "        # Обработка OOM отдельно для информативности\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "             print(\"\\n!!! Критическая ошибка: CUDA out of memory! Обучение остановлено. Попробуйте уменьшить batch_size. !!!\")\n",
    "        else:\n",
    "             print(f\"\\n!!! Обучение прервано из-за RuntimeError: {e} !!!\")\n",
    "             traceback.print_exc()\n",
    "    except Exception as train_err:\n",
    "        print(f\"\\n!!! КРИТИЧЕСКАЯ НЕПРЕДВИДЕННАЯ ОШИБКА ОБУЧЕНИЯ: {train_err} !!!\")\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "         # Этот блок выполнится всегда: при нормальном завершении, break, return или ошибке\n",
    "         total_training_time = time.time() - start_time_total\n",
    "         print(f\"\\n--- Основное Обучение Завершено ---\")\n",
    "         print(f\"Общее время обучения: {total_training_time / 60:.2f} мин\")\n",
    "         best_lev_str = f\"{best_val_levenshtein:.4f}\" if np.isfinite(best_val_levenshtein) else \"N/A\"\n",
    "         print(f\"Лучший достигнутый Val Levenshtein: {best_lev_str}\")\n",
    "         if np.isfinite(best_val_levenshtein):\n",
    "             print(f\"Лучшая модель (state_dict) сохранена в: {BEST_MODEL_PATH}\")\n",
    "\n",
    "         # --- Сохранение финальных параметров ---\n",
    "         print(\"\\nСохранение финальных параметров конфигурации...\")\n",
    "         # Собираем все параметры в один словарь для удобства\n",
    "         # Убедимся, что сохраняем словари, а не объекты Path\n",
    "         final_params_to_save = {\n",
    "             'audio_config': AUDIO_CONFIG,\n",
    "             'model_config': MODEL_CONFIG,\n",
    "             'train_config': TRAIN_CONFIG,\n",
    "             'char_map': { # Сохраняем словари и индексы\n",
    "                 'char_to_index': char_to_index,\n",
    "                 'index_to_char': {k:v for k,v in index_to_char.items()}, # Копируем на всякий случай\n",
    "                 'BLANK_IDX': BLANK_IDX,\n",
    "                 'PAD_IDX': PAD_IDX,\n",
    "                 'NUM_CLASSES_CTC': NUM_CLASSES_CTC\n",
    "             },\n",
    "             'best_val_levenshtein': best_val_levenshtein if np.isfinite(best_val_levenshtein) else None\n",
    "         }\n",
    "         try:\n",
    "             with open(PARAMS_PATH, 'w', encoding='utf-8') as f:\n",
    "                 # Используем json.dump для сохранения словаря\n",
    "                 json.dump(final_params_to_save, f, indent=4, ensure_ascii=False)\n",
    "             print(f\"Параметры конфигурации сохранены в: {PARAMS_PATH}\")\n",
    "         except Exception as e:\n",
    "             print(f\"!!! Ошибка при сохранении параметров конфигурации: {e} !!!\")\n",
    "\n",
    "         # --- Построение графиков обучения ---\n",
    "         print(\"\\nПостроение графиков истории обучения...\")\n",
    "         epochs_completed = len(training_history['train_loss'])\n",
    "         if epochs_completed > 0:\n",
    "             epoch_axis = range(1, epochs_completed + 1)\n",
    "             plt.figure(figsize=(18, 5)) # Широкий график\n",
    "\n",
    "             # График Потерь (Loss)\n",
    "             plt.subplot(1, 3, 1)\n",
    "             plt.plot(epoch_axis, training_history['train_loss'], 'o-', label='Train Loss')\n",
    "             plt.plot(epoch_axis, training_history['val_loss'], 'o-', label='Val Loss')\n",
    "             plt.title('Функция Потерь (Loss)'); plt.xlabel('Эпохи'); plt.ylabel('Loss')\n",
    "             plt.legend(); plt.grid(True);\n",
    "             plt.xticks(np.arange(1, epochs_completed + 1, step=max(1, epochs_completed//10)))\n",
    "\n",
    "             # График Метрики (Levenshtein)\n",
    "             plt.subplot(1, 3, 2)\n",
    "             plt.plot(epoch_axis, training_history['train_lev'], 'o-', label='Train Levenshtein')\n",
    "             plt.plot(epoch_axis, training_history['val_lev'], 'o-', label='Val Levenshtein')\n",
    "             # Отмечаем лучший результат на графике\n",
    "             if np.isfinite(best_val_levenshtein):\n",
    "                 best_epoch = np.argmin(training_history['val_lev']) + 1\n",
    "                 plt.axhline(y=best_val_levenshtein, color='r', linestyle='--', label=f'Best ({best_val_levenshtein:.3f} @ ep {best_epoch})')\n",
    "                 plt.scatter(best_epoch, best_val_levenshtein, color='red', s=80, zorder=5, marker='*') # Отмечаем звездочкой\n",
    "             plt.title('Расстояние Левенштейна'); plt.xlabel('Эпохи'); plt.ylabel('Levenshtein')\n",
    "             plt.legend(); plt.grid(True);\n",
    "             plt.xticks(np.arange(1, epochs_completed + 1, step=max(1, epochs_completed//10)))\n",
    "             min_val_lev = min(training_history['val_lev']) if training_history['val_lev'] else 0\n",
    "             plt.ylim(bottom=max(0, min_val_lev - 0.5)) # Устанавливаем разумный нижний предел оси Y\n",
    "\n",
    "             # График Скорости Обучения (Learning Rate)\n",
    "             plt.subplot(1, 3, 3)\n",
    "             plt.plot(epoch_axis, training_history['lr'], 'o-', label='Learning Rate', color='g')\n",
    "             plt.title('Скорость Обучения (LR)'); plt.xlabel('Эпохи'); plt.ylabel('LR')\n",
    "             plt.legend(); plt.grid(True);\n",
    "             plt.yscale('log') # Логарифмическая шкала для LR\n",
    "             plt.xticks(np.arange(1, epochs_completed + 1, step=max(1, epochs_completed//10)))\n",
    "\n",
    "             plt.tight_layout() # Автоматическое расталкивание графиков\n",
    "             plt.show()\n",
    "         else:\n",
    "             print(\"Нет данных для построения графиков (обучение не запускалось или прервалось на 1й эпохе).\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- Основное Обучение Не Запущено (проблемы с подготовкой данных или инициализацией планировщика) ---\")\n",
    "\n",
    "print(\"\\n--- Ячейка 13: Основной цикл обучения завершен ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 14: Генерация Предсказаний (Submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 14: Генерация Предсказаний для Теста (Greedy) ---\n",
      "Модель для инференса: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3996Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_WD1e-04_Deltastandard.pth\n",
      "Параметры для инференса: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\params_Filt0-3996Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_WD1e-04_Deltastandard.json\n",
      "Используется ТОЛЬКО Greedy декодер.\n",
      "\n",
      "Загрузка сохраненных параметров...\n",
      "Параметры успешно загружены.\n",
      "\n",
      "Создание модели для инференса...\n",
      "Архитектура MorseRecognizer инициализирована.\n",
      "Загрузка весов из файла: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3996Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_WD1e-04_Deltastandard.pth...\n",
      "Модель успешно создана и веса загружены.\n",
      "\n",
      "Создание тестового DataLoader...\n",
      "MorseDataset создан: is_train=False, delta_type='standard', rms_smooth=Нет, delta_smooth=Нет, noise_level=Отключен\n",
      "Тестовый DataLoader создан (BS=32).\n",
      "\n",
      "--- Запуск инференса (Greedy) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d392f0006ff4e5c8148c99a86eab4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Предсказание (Greedy):   0%|                                                | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Инференс (Greedy) завершен за 36.95 сек. Предсказаний В СЛОВАРЕ: 5000/5000\n",
      "\n",
      "Формирование файла submission.csv...\n",
      "Файл submission сохранен: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\submission_greedy__Deltastandard.csv\n",
      "\n",
      "Последние 17 строк файла submission:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>34984.opus</td>\n",
       "      <td>ДАМАМТЗОТИ РСЫСАМЦ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>34985.opus</td>\n",
       "      <td>ИЛ ЬСВЕДТКЧВНТИ ЯМДМЫМЮНЯМЦ ЮТИЫМ Ь#ЧМЫН Д#МРГ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>34986.opus</td>\n",
       "      <td>АНХ ВСОЕГЬ Р ВКТДАМИРКШМДНИ ГКНЖТА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>34987.opus</td>\n",
       "      <td>ИЛ ДАСДП ЬСОЕМУНТА ИГВКСОЕП ЬКСХЫСУС ХНУ ЮН ХНУСИ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>34988.opus</td>\n",
       "      <td>ЕТЬТКП ДСЯНКМЫОЦ ИМК</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>34989.opus</td>\n",
       "      <td>КНОЬКМ СОЕНЫМОП ЬСЮНВМ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>34990.opus</td>\n",
       "      <td>ИЛ ЬСОЕНДМ#М ЙЫНУС ЙЫМЧАТУС ЬКТДЛХТ ЫМЖАЛШ ДЛУ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>34991.opus</td>\n",
       "      <td>Л ДАСДП ОСЮВНЫМ НЮЙГРГ ТЫТУКНЩН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>34992.opus</td>\n",
       "      <td>АСТ ИСЧТИ ГЖГПЦ Ю НЙОСЫЗЕПЗ ККАСОЕПЙМИДСЫС</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>34993.opus</td>\n",
       "      <td>ОЫДЛ ЫЛ1ЕТ #КС ЬЙЫНТ ЕСЕРЫ9АМЕ0П</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>34994.opus</td>\n",
       "      <td>АН ЖНОЕС ЬТЫТВНЖМ ГДЫМ3ТААСЬ АН 75 РМЫСЯМРЫСД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>34995.opus</td>\n",
       "      <td>ОДЦЮП ЬСВВТКЧМДНКЕОЦ ДКГЖАГЗ АТЧЕСИМИЛИМ ЬНЫПЯ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>34996.opus</td>\n",
       "      <td>ОРСКС ИЛ ДАСДП ЬСОЕМУАТИ ЕНБАЛ КНРТЕАЛШ ВДМУНЕ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>34997.opus</td>\n",
       "      <td>ИСЧТИ СЕЬК9П ЮН ДНИЬНОМЕТЫПАЪЪ ЖТЫАСР</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>34998.opus</td>\n",
       "      <td>ТОЫМ ДЛ ЬСЧТЫНТЕТ ДТКАГЕПОЦ ВСИСБ НН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>34999.opus</td>\n",
       "      <td>ОДТЕ ОСЫАЯНВНКМЕ ЧМЮАПРНЧВСИГ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>35000.opus</td>\n",
       "      <td>РСАТЯ ЬТКТВНЖМ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            message\n",
       "4983  34984.opus                                 ДАМАМТЗОТИ РСЫСАМЦ\n",
       "4984  34985.opus  ИЛ ЬСВЕДТКЧВНТИ ЯМДМЫМЮНЯМЦ ЮТИЫМ Ь#ЧМЫН Д#МРГ...\n",
       "4985  34986.opus                 АНХ ВСОЕГЬ Р ВКТДАМИРКШМДНИ ГКНЖТА\n",
       "4986  34987.opus  ИЛ ДАСДП ЬСОЕМУНТА ИГВКСОЕП ЬКСХЫСУС ХНУ ЮН ХНУСИ\n",
       "4987  34988.opus                               ЕТЬТКП ДСЯНКМЫОЦ ИМК\n",
       "4988  34989.opus                             КНОЬКМ СОЕНЫМОП ЬСЮНВМ\n",
       "4989  34990.opus  ИЛ ЬСОЕНДМ#М ЙЫНУС ЙЫМЧАТУС ЬКТДЛХТ ЫМЖАЛШ ДЛУ...\n",
       "4990  34991.opus                    Л ДАСДП ОСЮВНЫМ НЮЙГРГ ТЫТУКНЩН\n",
       "4991  34992.opus         АСТ ИСЧТИ ГЖГПЦ Ю НЙОСЫЗЕПЗ ККАСОЕПЙМИДСЫС\n",
       "4992  34993.opus                   ОЫДЛ ЫЛ1ЕТ #КС ЬЙЫНТ ЕСЕРЫ9АМЕ0П\n",
       "4993  34994.opus      АН ЖНОЕС ЬТЫТВНЖМ ГДЫМ3ТААСЬ АН 75 РМЫСЯМРЫСД\n",
       "4994  34995.opus  ОДЦЮП ЬСВВТКЧМДНКЕОЦ ДКГЖАГЗ АТЧЕСИМИЛИМ ЬНЫПЯ...\n",
       "4995  34996.opus  ОРСКС ИЛ ДАСДП ЬСОЕМУАТИ ЕНБАЛ КНРТЕАЛШ ВДМУНЕ...\n",
       "4996  34997.opus              ИСЧТИ СЕЬК9П ЮН ДНИЬНОМЕТЫПАЪЪ ЖТЫАСР\n",
       "4997  34998.opus               ТОЫМ ДЛ ЬСЧТЫНТЕТ ДТКАГЕПОЦ ВСИСБ НН\n",
       "4998  34999.opus                      ОДТЕ ОСЫАЯНВНКМЕ ЧМЮАПРНЧВСИГ\n",
       "4999  35000.opus                                     РСАТЯ ЬТКТВНЖМ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ячейка 14: Работа ноутбука завершена (Greedy) ---\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 14: Генерация Предсказаний (Submission)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 14: Генерация Предсказаний для Теста (Greedy) ---\")\n",
    "\n",
    "# --- Проверки наличия файлов и переменных ---\n",
    "# Убедимся, что все компоненты, необходимые для инференса, доступны\n",
    "required_infer_vars = [\n",
    "    'BEST_MODEL_PATH', 'PARAMS_PATH', 'test_df', 'MorseRecognizer',\n",
    "    'MorseDataset', 'collate_fn', 'device', 'ctc_greedy_decode',\n",
    "    'index_to_char', 'BLANK_IDX', 'PAD_IDX', 'tqdm', 'torch', 'json', 'Path',\n",
    "    'pd', 'DataLoader', 'np', 'EXTRACTED_AUDIO_DIR', 'TRAIN_CONFIG', 'F',\n",
    "    'MODEL_CONFIG', 'OUTPUT_DIR'\n",
    "]\n",
    "missing_infer_vars = [v for v in required_infer_vars if v not in globals() or globals()[v] is None]\n",
    "model_file_exists = 'BEST_MODEL_PATH' in globals() and BEST_MODEL_PATH is not None and isinstance(BEST_MODEL_PATH, Path) and BEST_MODEL_PATH.is_file()\n",
    "params_file_exists = 'PARAMS_PATH' in globals() and PARAMS_PATH is not None and isinstance(PARAMS_PATH, Path) and PARAMS_PATH.is_file()\n",
    "test_df_exists = 'test_df' in globals() and test_df is not None and not test_df.empty\n",
    "\n",
    "can_infer = not missing_infer_vars and model_file_exists and params_file_exists and test_df_exists\n",
    "\n",
    "if can_infer:\n",
    "    print(f\"Загрузка лучшей модели из: {BEST_MODEL_PATH}\")\n",
    "    print(f\"Загрузка параметров из: {PARAMS_PATH}\")\n",
    "    print(\"Декодирование будет выполняться с помощью: Greedy\")\n",
    "\n",
    "    # --- Загрузка параметров конфигурации из файла JSON ---\n",
    "    print(\"\\n1. Загрузка параметров конфигурации...\")\n",
    "    loaded_params_infer = None; params_loaded_successfully = False\n",
    "    try:\n",
    "        with open(PARAMS_PATH, 'r', encoding='utf-8') as f:\n",
    "            loaded_params_infer = json.load(f)\n",
    "        # Извлекаем необходимые словари и значения\n",
    "        loaded_audio_config_inf = loaded_params_infer['audio_config']\n",
    "        loaded_model_config_inf = loaded_params_infer['model_config']\n",
    "        loaded_char_map_inf = loaded_params_infer['char_map']\n",
    "        # Важно восстановить словари и индексы из файла\n",
    "        loaded_char_to_index_inf = loaded_char_map_inf['char_to_index']\n",
    "        # Восстанавливаем index_to_char, преобразуя ключи обратно в int, если нужно\n",
    "        loaded_index_to_char_inf = {int(k) if k.isdigit() else k: v for k,v in loaded_char_map_inf['index_to_char'].items()}\n",
    "        loaded_blank_idx_inf = loaded_char_map_inf['BLANK_IDX']\n",
    "        loaded_pad_idx_inf = loaded_char_map_inf['PAD_IDX']\n",
    "        loaded_num_classes_inf = loaded_char_map_inf['NUM_CLASSES_CTC']\n",
    "        loaded_input_dim_inf = loaded_model_config_inf['input_feature_dim']\n",
    "        print(\"   Параметры успешно загружены.\")\n",
    "        params_loaded_successfully = True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   !!! Ошибка: Файл параметров не найден по пути {PARAMS_PATH} !!!\")\n",
    "    except Exception as e:\n",
    "        print(f\"   !!! Ошибка при загрузке или парсинге файла параметров: {e} !!!\")\n",
    "        traceback.print_exc(limit=1)\n",
    "\n",
    "    # --- Создание модели и загрузка весов ---\n",
    "    inference_model = None; model_loaded_for_inference = False\n",
    "    if params_loaded_successfully:\n",
    "        print(f\"\\n2. Создание модели для инференса...\")\n",
    "        try:\n",
    "            # Создаем модель с загруженными параметрами\n",
    "            temp_model_config_for_init = loaded_model_config_inf.copy()\n",
    "            # input_feature_dim передается отдельно в конструктор\n",
    "            temp_model_config_for_init.pop('input_feature_dim', None)\n",
    "            inference_model = MorseRecognizer(\n",
    "                num_classes_ctc=loaded_num_classes_inf,\n",
    "                input_feature_dim=loaded_input_dim_inf,\n",
    "                **temp_model_config_for_init\n",
    "            ).to(device)\n",
    "\n",
    "            print(f\"   Загрузка весов из файла: {BEST_MODEL_PATH}...\")\n",
    "            # Загружаем state_dict (сохраненные веса)\n",
    "            # Используем weights_only=True для безопасности, если поддерживается\n",
    "            try:\n",
    "                inference_model.load_state_dict(\n",
    "                    torch.load(BEST_MODEL_PATH, map_location=device, weights_only=True)\n",
    "                )\n",
    "            except TypeError: # Обработка для старых версий PyTorch\n",
    "                print(\"   Warning: weights_only=True не поддерживается. Загрузка стандартным способом.\")\n",
    "                inference_model.load_state_dict(\n",
    "                    torch.load(BEST_MODEL_PATH, map_location=device)\n",
    "                )\n",
    "\n",
    "            inference_model.eval() # !!! Перевод модели в режим инференса !!!\n",
    "            print(\"   Модель успешно создана и веса загружены.\")\n",
    "            model_loaded_for_inference = True\n",
    "        except FileNotFoundError:\n",
    "             print(f\"   !!! Ошибка: Файл модели не найден по пути {BEST_MODEL_PATH} !!!\")\n",
    "        except Exception as e:\n",
    "            print(f\"   !!! Ошибка при создании или загрузке весов модели: {e} !!!\")\n",
    "            traceback.print_exc(limit=1)\n",
    "\n",
    "    # --- Создание тестового DataLoader ---\n",
    "    test_loader_infer = None; test_loader_ready = False\n",
    "    if model_loaded_for_inference:\n",
    "        print(\"\\n3. Создание тестового DataLoader...\")\n",
    "        try:\n",
    "             # Используем загруженные конфигурации для создания датасета\n",
    "             # train_config нужен для noise_level (который будет 0)\n",
    "             loaded_train_config_inf = loaded_params_infer.get('train_config', TRAIN_CONFIG)\n",
    "\n",
    "             infer_test_dataset = MorseDataset(\n",
    "                 dataframe=test_df,\n",
    "                 audio_dir=EXTRACTED_AUDIO_DIR,\n",
    "                 char_to_index=loaded_char_to_index_inf,\n",
    "                 audio_config=loaded_audio_config_inf,\n",
    "                 model_input_feature_dim=loaded_input_dim_inf,\n",
    "                 train_config=loaded_train_config_inf, # Передаем для консистентности\n",
    "                 is_train=False # Указываем, что это режим инференса\n",
    "             )\n",
    "             # Увеличиваем batch_size для ускорения инференса\n",
    "             inference_batch_size = TRAIN_CONFIG.get('batch_size', 8) * 4\n",
    "             inf_num_workers = TRAIN_CONFIG.get('num_workers', 0)\n",
    "             test_loader_infer = DataLoader(\n",
    "                 infer_test_dataset,\n",
    "                 batch_size=inference_batch_size,\n",
    "                 shuffle=False, # Тестовую выборку не перемешиваем\n",
    "                 collate_fn=collate_fn,\n",
    "                 num_workers=inf_num_workers,\n",
    "                 pin_memory=(device.type == 'cuda') # Ускорение для GPU\n",
    "             )\n",
    "             print(f\"   Тестовый DataLoader создан (Размер батча={inference_batch_size}).\")\n",
    "             test_loader_ready = True\n",
    "        except Exception as e:\n",
    "            print(f\"   !!! Ошибка при создании тестового DataLoader: {e} !!!\")\n",
    "            traceback.print_exc(limit=1)\n",
    "\n",
    "    # --- Запуск Инференса ---\n",
    "    if test_loader_ready and inference_model is not None:\n",
    "        predictions = {} # Словарь для хранения {file_id: predicted_text}\n",
    "        print(\"\\n4. Запуск инференса (предсказания на тестовых данных)...\")\n",
    "        inference_start_time = time.time()\n",
    "        inference_model.eval(); # Убедимся еще раз, что модель в режиме eval\n",
    "\n",
    "        with torch.no_grad(): # Отключаем расчет градиентов\n",
    "            pbar_infer = tqdm(test_loader_infer, desc=\"Предсказание (Greedy)\", ncols=100, leave=True)\n",
    "            for batch_data in pbar_infer:\n",
    "                if batch_data is None: continue # Пропускаем пустые батчи от collate_fn\n",
    "                features, file_ids, feature_lengths, _ = batch_data\n",
    "                if features is None or file_ids is None or features.shape[0]==0: continue\n",
    "\n",
    "                features = features.to(device, non_blocking=True)\n",
    "\n",
    "                try:\n",
    "                    # Получаем логиты от модели\n",
    "                    logits = inference_model(features) # (Time, B, Classes)\n",
    "                    # Декодируем с помощью Greedy\n",
    "                    decoded_batch = ctc_greedy_decode(\n",
    "                        logits,\n",
    "                        loaded_index_to_char_inf, # Используем загруженный словарь\n",
    "                        loaded_blank_idx_inf      # Используем загруженный индекс BLANK\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nОшибка Forward/Decode в батче инференса: {e}\")\n",
    "                    traceback.print_exc(limit=1)\n",
    "                    # Записываем ошибку для всех ID в этом батче\n",
    "                    for fid in file_ids: predictions[fid] = f\"ERROR_INFER\"\n",
    "                    continue # Переходим к следующему батчу\n",
    "\n",
    "                # Сохраняем предсказания для батча\n",
    "                for file_id, pred_text in zip(file_ids, decoded_batch):\n",
    "                    predictions[file_id] = pred_text\n",
    "\n",
    "        inference_duration = time.time() - inference_start_time\n",
    "        print(f\"\\n   Инференс завершен за {inference_duration:.2f} сек.\")\n",
    "        print(f\"   Предсказаний В СЛОВАРЕ: {len(predictions)} (ожидалось: {len(test_df)})\")\n",
    "        if len(predictions) != len(test_df):\n",
    "             print(\"   !!! Предупреждение: Количество предсказаний не совпадает с размером тестового датасета! Возможны ошибки в обработке части файлов. !!!\")\n",
    "\n",
    "        # --- Формирование и сохранение submission ---\n",
    "        if predictions:\n",
    "            print(\"\\n5. Формирование и сохранение файла submission...\")\n",
    "            # Создаем DataFrame на основе оригинального test_df для сохранения порядка ID\n",
    "            submission_df = pd.DataFrame({'id': test_df['id']})\n",
    "            # Заполняем колонку 'message', используя словарь predictions\n",
    "            # .map() сопоставляет id с ключами словаря predictions\n",
    "            # .fillna(\"\") обрабатывает ID, для которых не нашлось предсказания (не должно быть при len=5000)\n",
    "            submission_df['message'] = submission_df['id'].map(predictions).fillna(\"ERROR_MISSING_PRED\")\n",
    "\n",
    "            # Проверка на пустые строки или ошибки\n",
    "            num_empty = (submission_df['message'] == \"\").sum()\n",
    "            num_errors = submission_df['message'].str.contains(\"ERROR\").sum()\n",
    "            if num_empty > 0: print(f\"  Предупреждение: Найдено {num_empty} пустых предсказаний.\")\n",
    "            if num_errors > 0: print(f\"  Предупреждение: Найдено {num_errors} предсказаний с ошибками.\")\n",
    "\n",
    "            # Формируем имя файла submission, включающее параметры\n",
    "            submission_filename = f\"submission_greedy_{FINAL_SUFFIX}.csv\"\n",
    "            submission_path = OUTPUT_DIR / submission_filename\n",
    "            try:\n",
    "                submission_df.to_csv(submission_path, index=False)\n",
    "                print(f\"   Файл submission успешно сохранен: {submission_path.resolve()}\")\n",
    "\n",
    "                # Вывод ПОСЛЕДНИХ 17 строк для проверки\n",
    "                print(f\"\\n   Последние {min(17, len(submission_df))} строк файла submission:\")\n",
    "                display(submission_df.tail(17)) # Используем .tail()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   !!! Ошибка при сохранении файла submission: {e} !!!\")\n",
    "        else:\n",
    "            print(\"   Предсказания не были сгенерированы, файл submission не создан.\")\n",
    "\n",
    "# Обработка случая, если инференс не мог быть запущен\n",
    "elif not can_infer:\n",
    "    print(\"\\n--- Инференс Не Запущен ---\")\n",
    "    if missing_infer_vars: print(f\"  Причина: Отсутствуют необходимые переменные: {missing_infer_vars}\")\n",
    "    if not model_file_exists: print(f\"  Причина: Файл лучшей модели не найден: {globals().get('BEST_MODEL_PATH', 'Путь не определен')}\")\n",
    "    if not params_file_exists: print(f\"  Причина: Файл параметров не найден: {globals().get('PARAMS_PATH', 'Путь не определен')}\")\n",
    "    if not test_df_exists: print(\"  Причина: Тестовый DataFrame (test_df) не загружен или пуст.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 14: Работа ноутбука завершена ---\")\n",
    "print(\"=\" * 60)\n",
    "# ============================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
