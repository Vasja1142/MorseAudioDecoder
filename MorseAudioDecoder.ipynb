{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 1: Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 1: Импорты и Базовая Настройка ---\n",
      "\n",
      "--- Статус библиотек ---\n",
      "PyTorch Версия: 2.5.1+cu121\n",
      "LibROSA Версия: 0.11.0\n",
      "ipywidgets доступен: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Ячейка 1: Импорты и Базовая Настройка\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 1: Импорты и Базовая Настройка ---\")\n",
    "\n",
    "# --- Базовые библиотеки ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "import zipfile\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import random\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Union # Для аннотаций типов (Python < 3.10)\n",
    "\n",
    "# --- Аудио и Сигналы ---\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy\n",
    "import scipy.signal as signal\n",
    "\n",
    "# --- Визуализация и Интерактивность ---\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, Audio, clear_output\n",
    "    IPYWIDGETS_AVAILABLE = True\n",
    "except ImportError: IPYWIDGETS_AVAILABLE = False\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- PyTorch ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# --- Метрики и Утилиты ---\n",
    "import Levenshtein\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# --- Настройка окружения и предупреждений ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"The verbose parameter is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"You are using `torch.load` with `weights_only=False`\")\n",
    "\n",
    "print(\"\\n--- Статус библиотек ---\")\n",
    "print(f\"PyTorch Версия: {torch.__version__}\")\n",
    "print(f\"LibROSA Версия: {librosa.__version__}\")\n",
    "# ... (остальные версии) ...\n",
    "print(f\"ipywidgets доступен: {IPYWIDGETS_AVAILABLE}\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 2: Конфигурация и Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 2: Конфигурация и Параметры ---\n",
      "Базовая директория: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\n",
      "Директория для аудио: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\morse_dataset\\morse_dataset\n",
      "Директория для вывода: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\n",
      "\n",
      "Аудио параметры (ФИНАЛ): {\n",
      "  \"sample_rate\": 8000,\n",
      "  \"frame_length_rms\": 384,\n",
      "  \"hop_length_rms\": 96,\n",
      "  \"filter_order\": 5,\n",
      "  \"filter_fmin\": 0,\n",
      "  \"filter_fmax\": 3999,\n",
      "  \"delta_type\": \"standard\",\n",
      "  \"delta_alpha\": 1.0,\n",
      "  \"rms_smoothing_window_size\": 1,\n",
      "  \"delta_ma_smoothing_window_size\": 1\n",
      "}\n",
      "\n",
      "Параметры модели: {\n",
      "  \"input_feature_dim\": 2,\n",
      "  \"cnn_out_channels\": [\n",
      "    64,\n",
      "    128,\n",
      "    128\n",
      "  ],\n",
      "  \"cnn_kernel_size\": 9,\n",
      "  \"cnn_stride\": 1,\n",
      "  \"cnn_padding\": \"same\",\n",
      "  \"cnn_pool_kernel\": 2,\n",
      "  \"rnn_hidden_size\": 256,\n",
      "  \"rnn_num_layers\": 2,\n",
      "  \"dropout_rate\": 0.2,\n",
      "  \"activation_fn\": \"GELU\"\n",
      "}\n",
      "\n",
      "Параметры основного обучения (ФИНАЛ): {\n",
      "  \"batch_size\": 8,\n",
      "  \"num_workers\": 0,\n",
      "  \"num_epochs\": 30,\n",
      "  \"learning_rate\": 0.0005,\n",
      "  \"final_div_factor\": 100,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"optimizer\": \"AdamW\",\n",
      "  \"noise_level\": 0.0,\n",
      "  \"early_stopping_patience\": 7,\n",
      "  \"gradient_clip_norm\": 2.0,\n",
      "  \"validation_split_ratio\": 0.1,\n",
      "  \"base_seed\": 42\n",
      "}\n",
      "\n",
      "Финальный путь для модели: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR5e-04_WD1e-04_Deltastandard.pth\n",
      "Финальный путь для параметров: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\params_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR5e-04_WD1e-04_Deltastandard.json\n",
      "\n",
      "Используемое устройство: cuda\n",
      "  GPU: NVIDIA GeForce GTX 1050 Ti\n",
      "Установлен SEED = 42\n",
      "\n",
      "--- Ячейка 2: Конфигурация завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 2: Конфигурация и Параметры (ФИНАЛЬНАЯ ВЕРСИЯ)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 2: Конфигурация и Параметры ---\")\n",
    "\n",
    "SEED = 42 # Фиксируем SEED\n",
    "\n",
    "# --- Пути ---\n",
    "BASE_DIR = Path('./').resolve(); ZIP_PATH = BASE_DIR / 'morse_dataset.zip'\n",
    "AUDIO_DIR_NAME = 'morse_dataset'; EXTRACTED_AUDIO_DIR = BASE_DIR / AUDIO_DIR_NAME / AUDIO_DIR_NAME\n",
    "TRAIN_CSV_PATH = BASE_DIR / 'train.csv'; TEST_CSV_PATH = BASE_DIR / 'test.csv'\n",
    "SAMPLE_SUB_PATH = BASE_DIR / 'sample_submission.csv'\n",
    "OUTPUT_DIR = BASE_DIR / 'output'; OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Базовая директория: {BASE_DIR}\")\n",
    "print(f\"Директория для аудио: {EXTRACTED_AUDIO_DIR}\")\n",
    "print(f\"Директория для вывода: {OUTPUT_DIR}\")\n",
    "\n",
    "# --- Параметры обработки аудио (ФИНАЛЬНЫЕ ПОСЛЕ КАЛИБРОВКИ) ---\n",
    "AUDIO_CONFIG = {\n",
    "    \"sample_rate\": 8000,\n",
    "    \"frame_length_rms\": 384,\n",
    "    \"hop_length_rms\": 96,\n",
    "    \"filter_order\": 5,\n",
    "    \"filter_fmin\": 0,\n",
    "    \"filter_fmax\": 3999, # <-- Остался ФНЧ 0-4кГц\n",
    "    \"delta_type\": 'standard',\n",
    "    \"delta_alpha\": 1.0,\n",
    "    \"rms_smoothing_window_size\": 1,   # <-- ОТКЛЮЧЕНО (Окно 1)\n",
    "    \"delta_ma_smoothing_window_size\": 1, # <-- ОТКЛЮЧЕНО (Окно 1)\n",
    "    # Пока не добавляем Trimming и Robust Norm - это будут отдельные эксперименты\n",
    "}\n",
    "nyquist_freq = AUDIO_CONFIG['sample_rate'] / 2.0\n",
    "if AUDIO_CONFIG['filter_fmax'] >= nyquist_freq:\n",
    "    AUDIO_CONFIG['filter_fmax'] = nyquist_freq * 0.999\n",
    "print(f\"\\nАудио параметры (ФИНАЛ): {json.dumps(AUDIO_CONFIG, indent=2)}\")\n",
    "\n",
    "# --- Параметры Модели (Стандартные) ---\n",
    "MODEL_CONFIG = {\n",
    "    \"input_feature_dim\": 2,\n",
    "    \"cnn_out_channels\": [64, 128, 128],\n",
    "    \"cnn_kernel_size\": 9, \"cnn_stride\": 1, \"cnn_padding\": 'same',\n",
    "    \"cnn_pool_kernel\": 2, \"rnn_hidden_size\": 256, \"rnn_num_layers\": 2,\n",
    "    \"dropout_rate\": 0.2, \"activation_fn\": \"GELU\"\n",
    "}\n",
    "print(f\"\\nПараметры модели: {json.dumps(MODEL_CONFIG, indent=2)}\")\n",
    "\n",
    "# --- Параметры Обучения (ФИНАЛЬНЫЕ) ---\n",
    "TRAIN_CONFIG = {\n",
    "    \"batch_size\": 8,\n",
    "    \"num_workers\": 0,\n",
    "    \"num_epochs\": 30,                   # <-- Увеличим для финального обучения\n",
    "    \"learning_rate\": 5e-4,              # <-- Оптимальный LR\n",
    "    \"final_div_factor\": 100,            # <-- Параметр для OneCycleLR\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"noise_level\": 0.0,                 # <-- Шум выключен\n",
    "    \"early_stopping_patience\": 7,       # <-- Терпение для ранней остановки\n",
    "    \"gradient_clip_norm\": 2.0,\n",
    "    \"validation_split_ratio\": 0.1,\n",
    "    \"base_seed\": SEED\n",
    "}\n",
    "print(f\"\\nПараметры основного обучения (ФИНАЛ): {json.dumps(TRAIN_CONFIG, indent=2)}\")\n",
    "\n",
    "# --- Специальные Токены и Глобальные Переменные ---\n",
    "PAD_TOKEN = '<pad>'; BLANK_TOKEN = '_'; PAD_IDX = -1; BLANK_IDX = -1; NUM_CLASSES_CTC = -1\n",
    "char_to_index = {}; index_to_char = {}\n",
    "\n",
    "# --- Формирование Имен Файлов для Сохранения (ФИНАЛ) ---\n",
    "# Так как сглаживание отключено, суффиксы не нужны\n",
    "rms_smooth_suffix = \"\"\n",
    "delta_smooth_suffix = \"\"\n",
    "delta_type_suffix = f\"_Delta{AUDIO_CONFIG['delta_type']}\"\n",
    "\n",
    "BASE_FILENAME_SUFFIX_FINAL = f\"Filt{int(AUDIO_CONFIG['filter_fmin'])}-{int(AUDIO_CONFIG['filter_fmax'])}Hz_\" \\\n",
    "                             f\"RMS{AUDIO_CONFIG['frame_length_rms']}h{AUDIO_CONFIG['hop_length_rms']}_\" \\\n",
    "                             f\"CNNk{MODEL_CONFIG['cnn_kernel_size']}p{MODEL_CONFIG['cnn_pool_kernel']}_\" \\\n",
    "                             f\"RNN{MODEL_CONFIG['rnn_hidden_size']}x{MODEL_CONFIG['rnn_num_layers']}_\" \\\n",
    "                             f\"Feat{MODEL_CONFIG['input_feature_dim']}_\" \\\n",
    "                             f\"LR{TRAIN_CONFIG['learning_rate']:.0e}_\" \\\n",
    "                             f\"WD{TRAIN_CONFIG['weight_decay']:.0e}\"\n",
    "\n",
    "FINAL_SUFFIX = f\"{delta_type_suffix}{rms_smooth_suffix}{delta_smooth_suffix}\" # Финальный суффикс без сглаживания\n",
    "MODEL_SAVE_PATH_TEMPLATE_FINAL = str(OUTPUT_DIR / f\"model_{BASE_FILENAME_SUFFIX_FINAL}\")\n",
    "PARAMS_SAVE_PATH_TEMPLATE_FINAL = str(OUTPUT_DIR / f\"params_{BASE_FILENAME_SUFFIX_FINAL}\")\n",
    "\n",
    "BEST_MODEL_PATH = Path(f\"{MODEL_SAVE_PATH_TEMPLATE_FINAL}{FINAL_SUFFIX}.pth\")\n",
    "PARAMS_PATH = Path(f\"{PARAMS_SAVE_PATH_TEMPLATE_FINAL}{FINAL_SUFFIX}.json\")\n",
    "\n",
    "print(f\"\\nФинальный путь для модели: {BEST_MODEL_PATH}\")\n",
    "print(f\"Финальный путь для параметров: {PARAMS_PATH}\")\n",
    "\n",
    "# --- Выбор устройства ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nИспользуемое устройство: {device}\")\n",
    "if device.type == 'cuda': print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# --- Установка SEED ---\n",
    "def set_seed(seed_value):\n",
    "    random.seed(seed_value); np.random.seed(seed_value); torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed_value)\n",
    "    print(f\"Установлен SEED = {seed_value}\")\n",
    "set_seed(TRAIN_CONFIG['base_seed'])\n",
    "\n",
    "print(\"\\n--- Ячейка 2: Конфигурация завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 3: Загрузка данных и распаковка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 3: Загрузка метаданных и распаковка аудио ---\n",
      "Папка C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\morse_dataset\\morse_dataset уже существует.\n",
      "\n",
      "Загрузка CSV файлов...\n",
      "  Train: 30000 записей.\n",
      "  Test: 5000 записей.\n",
      "  Sample Sub: 5000 записей.\n",
      "\n",
      "Выборочная проверка аудиофайлов...\n",
      "  Пример файла найден: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\morse_dataset\\morse_dataset\\1.opus\n",
      "\n",
      "--- Ячейка 3: Загрузка данных завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 3: Загрузка Данных и Распаковка\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 3: Загрузка метаданных и распаковка аудио ---\")\n",
    "# --- Проверка и Распаковка Архива ---\n",
    "if not EXTRACTED_AUDIO_DIR.exists():\n",
    "    print(f\"Папка {EXTRACTED_AUDIO_DIR} не найдена.\")\n",
    "    if ZIP_PATH.is_file():\n",
    "        print(f\"Распаковка {ZIP_PATH.name}...\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref: zip_ref.extractall(BASE_DIR)\n",
    "            print(\"Архив распакован.\")\n",
    "            if not EXTRACTED_AUDIO_DIR.is_dir():\n",
    "                 possible_audio_dir = BASE_DIR / ZIP_PATH.stem\n",
    "                 if possible_audio_dir.is_dir(): EXTRACTED_AUDIO_DIR = possible_audio_dir; print(f\"Найдена папка: {EXTRACTED_AUDIO_DIR}\")\n",
    "                 else: raise FileNotFoundError(f\"Не удалось найти папку с аудио после распаковки.\")\n",
    "            else: print(f\"Найдена папка: {EXTRACTED_AUDIO_DIR}\")\n",
    "        except Exception as e: print(f\"Критическая ошибка при распаковке: {e}\"); raise SystemExit(\"Остановка.\")\n",
    "    else: print(f\"Критическая ошибка: Архив {ZIP_PATH} не найден.\"); raise SystemExit(\"Остановка.\")\n",
    "else: print(f\"Папка {EXTRACTED_AUDIO_DIR} уже существует.\")\n",
    "\n",
    "# --- Загрузка CSV ---\n",
    "print(\"\\nЗагрузка CSV файлов...\")\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH); print(f\"  Train: {len(train_df)} записей.\")\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH); print(f\"  Test: {len(test_df)} записей.\")\n",
    "    try: sample_sub_df = pd.read_csv(SAMPLE_SUB_PATH); print(f\"  Sample Sub: {len(sample_sub_df)} записей.\")\n",
    "    except FileNotFoundError: print(f\"  Предупреждение: {SAMPLE_SUB_PATH.name} не найден.\"); sample_sub_df = None\n",
    "except FileNotFoundError as e: print(f\"Критическая ошибка: CSV файл не найден: {e}.\"); raise SystemExit(\"Остановка.\")\n",
    "except Exception as e: print(f\"Критическая ошибка при чтении CSV: {e}\"); raise SystemExit(\"Остановка.\")\n",
    "\n",
    "# --- Проверка наличия аудио ---\n",
    "print(\"\\nВыборочная проверка аудиофайлов...\")\n",
    "if train_df is not None and not train_df.empty and EXTRACTED_AUDIO_DIR.is_dir():\n",
    "    example_path = EXTRACTED_AUDIO_DIR / train_df['id'].iloc[0]\n",
    "    if example_path.is_file(): print(f\"  Пример файла найден: {example_path}\")\n",
    "    else: print(f\"  !!! ПРЕДУПРЕЖДЕНИЕ: Пример файла НЕ найден: {example_path} !!!\")\n",
    "elif not EXTRACTED_AUDIO_DIR.is_dir(): print(f\"  Проверка невозможна: Папка {EXTRACTED_AUDIO_DIR} не существует.\")\n",
    "else: print(\"  Проверка невозможна (train_df пуст?).\")\n",
    "\n",
    "print(\"\\n--- Ячейка 3: Загрузка данных завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 4: Создание словаря символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 4: Создание словаря символов ---\n",
      "Найдено уникальных символов: 44\n",
      "Размер словаря (вкл. BLANK, PAD): 46\n",
      "Индекс BLANK ('_'): 44\n",
      "Индекс PAD ('<pad>'): 45\n",
      "Количество классов для CTC Loss: 45\n",
      "\n",
      "--- Ячейка 4: Создание словаря завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 4: Создание Словаря Символов\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 4: Создание словаря символов ---\")\n",
    "if train_df is None or 'message' not in train_df.columns:\n",
    "    raise SystemExit(\"Остановка: train_df не загружен или нет колонки 'message'.\")\n",
    "try:\n",
    "    all_texts = train_df['message'].fillna('').astype(str)\n",
    "    unique_chars = sorted(list(set(char for text in all_texts for char in text)))\n",
    "    char_to_index = {char: i for i, char in enumerate(unique_chars)}\n",
    "    index_to_char = {i: char for char, i in char_to_index.items()}\n",
    "    BLANK_IDX = len(char_to_index); PAD_IDX = len(char_to_index) + 1\n",
    "    char_to_index[BLANK_TOKEN] = BLANK_IDX; char_to_index[PAD_TOKEN] = PAD_IDX\n",
    "    index_to_char[BLANK_IDX] = BLANK_TOKEN; index_to_char[PAD_IDX] = PAD_TOKEN\n",
    "    NUM_CLASSES_CTC = BLANK_IDX + 1\n",
    "    print(f\"Найдено уникальных символов: {len(unique_chars)}\")\n",
    "    print(f\"Размер словаря (вкл. BLANK, PAD): {len(char_to_index)}\")\n",
    "    print(f\"Индекс BLANK ('{BLANK_TOKEN}'): {BLANK_IDX}\"); print(f\"Индекс PAD ('{PAD_TOKEN}'): {PAD_IDX}\")\n",
    "    print(f\"Количество классов для CTC Loss: {NUM_CLASSES_CTC}\")\n",
    "except Exception as e: print(f\"Критическая ошибка: {e}\"); traceback.print_exc(); raise SystemExit(\"Остановка.\")\n",
    "if not char_to_index or not index_to_char or BLANK_IDX == -1 or PAD_IDX == -1 or NUM_CLASSES_CTC <= 0:\n",
    "    raise SystemExit(\"Остановка: Ошибка инициализации словаря.\")\n",
    "print(\"\\n--- Ячейка 4: Создание словаря завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 5: Класс MorseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 5: Определение класса MorseDataset ---\n",
      "\n",
      "--- Ячейка 5: Определение MorseDataset завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 5: Класс MorseDataset (ФИНАЛЬНАЯ ВЕРСИЯ - без сглаживания)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 5: Определение класса MorseDataset ---\")\n",
    "# Проверка глобальных переменных\n",
    "if 'BLANK_IDX' not in globals() or BLANK_IDX==-1 or 'PAD_IDX' not in globals() or PAD_IDX==-1: raise ValueError(\"BLANK_IDX/PAD_IDX не инициализированы.\")\n",
    "if 'AUDIO_CONFIG' not in globals() or not AUDIO_CONFIG: raise ValueError(\"AUDIO_CONFIG не определена.\")\n",
    "if 'TRAIN_CONFIG' not in globals() or not TRAIN_CONFIG: raise ValueError(\"TRAIN_CONFIG не определена.\")\n",
    "if 'MODEL_CONFIG' not in globals() or not MODEL_CONFIG: raise ValueError(\"MODEL_CONFIG не определена.\")\n",
    "\n",
    "class MorseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет для Морзе. Фильтр -> RMS -> Delta -> Z-score Norm.\n",
    "    Сглаживание ОТКЛЮЧЕНО. Trimming пока НЕ реализован.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe: pd.DataFrame, audio_dir: Path, char_to_index: dict,\n",
    "                 audio_config: dict, model_input_feature_dim: int,\n",
    "                 train_config: dict, is_train: bool = True):\n",
    "        # (Проверки типов...)\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.audio_dir = audio_dir; self.char_to_index = char_to_index; self.is_train = is_train\n",
    "        self.audio_config = audio_config; self.train_config = train_config\n",
    "        self.expected_feature_dim = model_input_feature_dim\n",
    "        # Параметры аудио\n",
    "        self.sample_rate = self.audio_config['sample_rate']; self.frame_length_rms = self.audio_config['frame_length_rms']\n",
    "        self.hop_length_rms = self.audio_config['hop_length_rms']; self.filter_order = self.audio_config['filter_order']\n",
    "        self.filter_fmin = self.audio_config['filter_fmin']; self.filter_fmax = self.audio_config['filter_fmax']\n",
    "        self.delta_type = self.audio_config.get('delta_type', 'standard'); self.delta_alpha = self.audio_config.get('delta_alpha', 1.0)\n",
    "        self.noise_level = self.train_config.get('noise_level', 0) if self.is_train else 0\n",
    "        # Проверки\n",
    "        self.nyquist = self.sample_rate / 2.0\n",
    "        if self.filter_fmax >= self.nyquist: self.filter_fmax = self.nyquist * 0.999\n",
    "        if 'id' not in self.dataframe.columns: raise ValueError(\"Нет колонки 'id'.\")\n",
    "        if self.is_train and 'message' not in self.dataframe.columns: raise ValueError(\"Нет колонки 'message'.\")\n",
    "        print(f\"MorseDataset создан: is_train={self.is_train}, delta_type='{self.delta_type}', \"\n",
    "              f\"Фильтр={self.filter_fmin}-{int(self.filter_fmax)}Hz (Порядок {self.filter_order}), \"\n",
    "              f\"Сглаживание RMS/Delta=ВЫКЛ, Шум={self.noise_level:.1f}\")\n",
    "\n",
    "    def __len__(self): return len(self.dataframe)\n",
    "\n",
    "    def _apply_filter(self, waveform_np: np.ndarray) -> np.ndarray:\n",
    "        # (Код фильтра Баттерворта без изменений, как в предыдущих версиях)\n",
    "        if not isinstance(waveform_np, np.ndarray) or waveform_np.ndim != 1: return waveform_np\n",
    "        f_min = self.filter_fmin; f_max = min(self.filter_fmax, self.nyquist * 0.999)\n",
    "        is_lowcut_needed = f_min > 1e-3; is_highcut_needed = f_max < (self.nyquist * 0.995)\n",
    "        if not is_lowcut_needed and not is_highcut_needed: return waveform_np.astype(np.float32)\n",
    "        try:\n",
    "            if is_lowcut_needed and is_highcut_needed: ftype, freqs = 'bandpass', [f_min, f_max]\n",
    "            elif is_lowcut_needed: ftype, freqs = 'highpass', f_min\n",
    "            else: ftype, freqs = 'lowpass', f_max\n",
    "            if isinstance(freqs, list) and freqs[0] >= freqs[1]: return waveform_np.astype(np.float32)\n",
    "            sos = signal.butter(self.filter_order, freqs, btype=ftype, fs=self.sample_rate, output='sos')\n",
    "            return signal.sosfiltfilt(sos, waveform_np).astype(np.float32)\n",
    "        except ValueError as ve: print(f\"WARNING: Filter ValueError: {ve}.\"); return waveform_np.astype(np.float32)\n",
    "        except Exception as e: print(f\"WARNING: Filter Error: {e}.\"); traceback.print_exc(limit=1); return waveform_np.astype(np.float32)\n",
    "\n",
    "    def _normalize_feature(self, feature_array: np.ndarray) -> np.ndarray:\n",
    "        # Стандартный Z-score\n",
    "        epsilon = 1e-6; mean = np.mean(feature_array); std = np.std(feature_array)\n",
    "        return (feature_array - mean) / (std + epsilon)\n",
    "\n",
    "    def _calculate_features(self, waveform_np: np.ndarray, file_id_for_log: str = \"N/A\") -> Union[torch.Tensor, None]:\n",
    "        \"\"\" Вычисляет признаки. Сглаживание отключено. \"\"\"\n",
    "        empty_tensor = torch.empty((self.expected_feature_dim, 0), dtype=torch.float32)\n",
    "        if not isinstance(waveform_np, np.ndarray) or waveform_np.size == 0: return empty_tensor\n",
    "        try:\n",
    "            # 1. Фильтрация\n",
    "            filtered_waveform = self._apply_filter(waveform_np)\n",
    "            if filtered_waveform.size == 0: return empty_tensor\n",
    "            # 2. Расчет RMS\n",
    "            rms_envelope_raw = librosa.feature.rms(y=filtered_waveform, frame_length=self.frame_length_rms, hop_length=self.hop_length_rms, center=True, pad_mode='reflect')[0]\n",
    "            if rms_envelope_raw.size < 2: return empty_tensor\n",
    "            # 3. Сглаживание RMS - ПРОПУСКАЕТСЯ\n",
    "            rms_envelope_processed = rms_envelope_raw\n",
    "            # 4. Расчет Дельты\n",
    "            delta_standard = np.diff(rms_envelope_processed, n=1, prepend=rms_envelope_processed[0])\n",
    "            delta_raw = delta_standard # (остальные типы дельты пока не используются)\n",
    "            # 5. Сглаживание Дельты - ПРОПУСКАЕТСЯ\n",
    "            delta_processed = delta_raw\n",
    "            # 6. Нормализация (Z-score) и Формирование Выхода\n",
    "            features_to_stack = [self._normalize_feature(rms_envelope_processed), self._normalize_feature(delta_processed)]\n",
    "            features_np = np.vstack(features_to_stack).astype(np.float32)\n",
    "            features_tensor = torch.from_numpy(features_np)\n",
    "            if features_tensor.shape[0] != self.expected_feature_dim:\n",
    "                 print(f\"ERROR ({file_id_for_log}): Wrong feature dim: {features_tensor.shape[0]}\"); return None\n",
    "            return features_tensor\n",
    "        except Exception as e:\n",
    "             print(f\"CRITICAL ERROR in _calculate_features ({file_id_for_log}): {e}\"); traceback.print_exc(limit=1); return None\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # (Код без изменений по сравнению с предыдущими версиями - пока без Trimming)\n",
    "        if not (0 <= index < len(self.dataframe)): return None, (None if self.is_train else f\"InvalidIndex_{index}\")\n",
    "        try: row = self.dataframe.iloc[index]; file_id = row['id']; audio_path = self.audio_dir / file_id\n",
    "        except Exception as e: return None, (None if self.is_train else f\"DataAccessError_{index}_{e}\")\n",
    "        # 1. Загрузка/Ресэмплинг (БЕЗ Trimming)\n",
    "        try:\n",
    "            waveform_np, sr_original = librosa.load(audio_path, sr=self.sample_rate, mono=True)\n",
    "            if waveform_np.size == 0: return None, (file_id if not self.is_train else None)\n",
    "        except FileNotFoundError: print(f\"ERROR ({file_id}): Not found: {audio_path}\"); return None, (file_id if not self.is_train else None)\n",
    "        except Exception as e: print(f\"ERROR ({file_id}): Load error: {e}\"); traceback.print_exc(limit=1); return None, (file_id if not self.is_train else None)\n",
    "        # 2. Зашумление - ПРОПУСКАЕТСЯ (noise_level = 0)\n",
    "        # 3. Вычисление Признаков\n",
    "        features = self._calculate_features(waveform_np, file_id_for_log=file_id)\n",
    "        if features is None or features.shape[1] == 0: return None, (file_id if not self.is_train else None)\n",
    "        # 4. Таргет / ID\n",
    "        if self.is_train:\n",
    "            message_text = str(row.get('message', '')); target_indices = [self.char_to_index.get(c, BLANK_IDX) for c in message_text]\n",
    "            if not target_indices or all(idx == BLANK_IDX for idx in target_indices): return None, None\n",
    "            target_tensor = torch.tensor(target_indices, dtype=torch.long); return features, target_tensor\n",
    "        else: return features, file_id\n",
    "\n",
    "print(\"\\n--- Ячейка 5: Определение MorseDataset завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 6: Функция collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 6: Определение функции collate_fn ---\n",
      "Функция collate_fn определена.\n",
      "\n",
      "--- Ячейка 6: Определение collate_fn завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 6: Функция collate_fn (Сборка Батчей)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 6: Определение функции collate_fn ---\")\n",
    "if 'PAD_IDX' not in globals() or PAD_IDX == -1: raise ValueError(\"PAD_IDX не инициализирован!\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\" Собирает батч, фильтрует None, выполняет паддинг. \"\"\"\n",
    "    original_batch_size = len(batch)\n",
    "    valid_batch = [(f, t) for f, t in batch if f is not None and t is not None and f.shape[1] > 0]\n",
    "    filtered_batch_size = len(valid_batch)\n",
    "    if filtered_batch_size == 0: return None\n",
    "    is_train_batch = isinstance(valid_batch[0][1], torch.Tensor)\n",
    "    features_list = [item[0].permute(1, 0) for item in valid_batch] # (Time, Features)\n",
    "    targets_or_ids_list = [item[1] for item in valid_batch]\n",
    "    # Pad Features: -> (Batch, MaxTime, Features) -> (Batch, Features, MaxTime)\n",
    "    features_padded = pad_sequence(features_list, batch_first=True, padding_value=0.0).permute(0, 2, 1)\n",
    "    feature_lengths = torch.tensor([f[0].shape[1] for f in valid_batch], dtype=torch.long) # Original time lengths\n",
    "    if is_train_batch:\n",
    "        targets_list = targets_or_ids_list\n",
    "        targets_padded = pad_sequence(targets_list, batch_first=True, padding_value=PAD_IDX)\n",
    "        target_lengths = torch.tensor([len(t) for t in targets_list], dtype=torch.long)\n",
    "        return features_padded, targets_padded, feature_lengths, target_lengths\n",
    "    else:\n",
    "        file_ids = targets_or_ids_list\n",
    "        return features_padded, file_ids, feature_lengths, None\n",
    "\n",
    "print(\"Функция collate_fn определена.\")\n",
    "print(\"\\n--- Ячейка 6: Определение collate_fn завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 7: Модель MorseRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 7: Определение модели MorseRecognizer ---\n",
      "\n",
      "Создание экземпляра модели...\n",
      "Архитектура MorseRecognizer инициализирована.\n",
      "Модель 'MorseRecognizer' создана на 'cuda'. Параметры: 2,021,997\n",
      "\n",
      "Проверка forward pass...\n",
      "  Вход: torch.Size([2, 2, 500]), Выход: torch.Size([62, 2, 45])\n",
      "  Размерности выхода корректны.\n",
      "\n",
      "--- Ячейка 7: Определение и проверка модели завершены ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 7: Модель MorseRecognizer (CNN + BiGRU)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 7: Определение модели MorseRecognizer ---\")\n",
    "if 'MODEL_CONFIG' not in globals() or not MODEL_CONFIG: raise ValueError(\"MODEL_CONFIG не определена!\")\n",
    "if 'NUM_CLASSES_CTC' not in globals() or NUM_CLASSES_CTC <= 0: raise ValueError(\"NUM_CLASSES_CTC не инициализирована!\")\n",
    "\n",
    "class MorseRecognizer(nn.Module):\n",
    "    \"\"\" Модель: CNN Extractor + BiGRU + Classifier \"\"\"\n",
    "    def __init__(self, num_classes_ctc: int, input_feature_dim: int, cnn_out_channels: list,\n",
    "                 cnn_kernel_size: int, cnn_stride: int, cnn_padding, cnn_pool_kernel: int,\n",
    "                 rnn_hidden_size: int, rnn_num_layers: int, dropout_rate: float, activation_fn: str = \"GELU\"):\n",
    "        super().__init__()\n",
    "        self.input_feature_dim = input_feature_dim; self._time_reduction_factor = 1.0\n",
    "        # --- CNN ---\n",
    "        cnn_layers = []; in_channels = input_feature_dim\n",
    "        try: ActivationLayer = getattr(nn, activation_fn)\n",
    "        except AttributeError: print(f\"Warning: Активация '{activation_fn}' -> GELU.\"); ActivationLayer = nn.GELU\n",
    "        for i, out_channels in enumerate(cnn_out_channels):\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, cnn_kernel_size, cnn_stride, cnn_padding),\n",
    "                nn.BatchNorm1d(out_channels), ActivationLayer(),\n",
    "                nn.MaxPool1d(cnn_pool_kernel), nn.Dropout(dropout_rate) )\n",
    "            cnn_layers.append(layer); in_channels = out_channels; self._time_reduction_factor *= cnn_pool_kernel\n",
    "        self.cnn_extractor = nn.Sequential(*cnn_layers); self.cnn_output_dim = in_channels\n",
    "        # --- RNN (BiGRU) ---\n",
    "        self.rnn = nn.GRU(self.cnn_output_dim, rnn_hidden_size, rnn_num_layers,\n",
    "                          batch_first=True, bidirectional=True, dropout=dropout_rate if rnn_num_layers > 1 else 0)\n",
    "        # --- Classifier ---\n",
    "        self.classifier = nn.Linear(rnn_hidden_size * 2, num_classes_ctc)\n",
    "        print(\"Архитектура MorseRecognizer инициализирована.\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.shape[1] != self.input_feature_dim: raise ValueError(f\"Wrong input features: {x.shape[1]} vs {self.input_feature_dim}\")\n",
    "        x = self.cnn_extractor(x)  # (B, C_cnn, T_red)\n",
    "        x = x.permute(0, 2, 1)     # (B, T_red, C_cnn)\n",
    "        x_rnn, _ = self.rnn(x)     # (B, T_red, H*2)\n",
    "        logits = self.classifier(x_rnn) # (B, T_red, Classes)\n",
    "        return logits.permute(1, 0, 2)  # (T_red, B, Classes) for CTC\n",
    "\n",
    "    def get_time_reduction_factor(self) -> float: return self._time_reduction_factor\n",
    "\n",
    "# --- Создание и Проверка Модели ---\n",
    "model_created_successfully = False; model = None\n",
    "try:\n",
    "    print(\"\\nСоздание экземпляра модели...\")\n",
    "    model = MorseRecognizer(num_classes_ctc=NUM_CLASSES_CTC, **MODEL_CONFIG).to(device)\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Модель '{type(model).__name__}' создана на '{device}'. Параметры: {total_params:,}\")\n",
    "    # --- Проверка forward pass ---\n",
    "    print(\"\\nПроверка forward pass...\"); model.eval()\n",
    "    dummy_input = torch.randn(2, MODEL_CONFIG['input_feature_dim'], 500).to(device)\n",
    "    with torch.no_grad(): dummy_output = model(dummy_input)\n",
    "    print(f\"  Вход: {dummy_input.shape}, Выход: {dummy_output.shape}\")\n",
    "    expected_time = int(dummy_input.shape[2] / model.get_time_reduction_factor())\n",
    "    if abs(dummy_output.shape[0] - expected_time) > 2: print(f\"  ПРЕДУПРЕЖДЕНИЕ: Неожиданная длина выхода по времени! Ожидалось ~{expected_time}, получено {dummy_output.shape[0]}.\")\n",
    "    assert dummy_output.shape[1] == 2, \"Batch size mismatch!\"\n",
    "    assert dummy_output.shape[2] == NUM_CLASSES_CTC, \"Num classes mismatch!\"\n",
    "    print(\"  Размерности выхода корректны.\"); model_created_successfully = True\n",
    "except Exception as e: print(f\"\\n!!! Ошибка создания/проверки модели: {e} !!!\"); traceback.print_exc(); model = None\n",
    "if not model_created_successfully: raise SystemExit(\"Остановка: Не удалось создать/проверить модель.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 7: Определение и проверка модели завершены ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 8: Loss, Optimizer, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 8: Настройка Loss и Optimizer ---\n",
      "Функция потерь: CTCLoss (blank=44, reduction='mean', zero_infinity=True)\n",
      "\n",
      "Выбор оптимизатора: ADAMW\n",
      "Оптимизатор: AdamW (lr=5.0e-04, weight_decay=1.0e-04)\n",
      "Планировщик: OneCycleLR (будет инициализирован перед циклом обучения)\n",
      "\n",
      "--- Ячейка 8: Настройка Loss и Optimizer завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 8: Функция Потерь (Loss) и Оптимизатор\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 8: Настройка Loss и Optimizer ---\")\n",
    "if not model_created_successfully or model is None: raise SystemExit(\"Остановка: Модель не создана.\")\n",
    "if BLANK_IDX == -1: raise ValueError(\"BLANK_IDX не инициализирован!\")\n",
    "\n",
    "# 1. Loss: CTC Loss\n",
    "criterion = nn.CTCLoss(blank=BLANK_IDX, reduction='mean', zero_infinity=True).to(device)\n",
    "print(f\"Функция потерь: CTCLoss (blank={BLANK_IDX}, reduction='mean', zero_infinity=True)\")\n",
    "\n",
    "# 2. Optimizer\n",
    "optimizer_name = TRAIN_CONFIG.get('optimizer', 'AdamW').lower()\n",
    "lr = TRAIN_CONFIG['learning_rate']; wd = TRAIN_CONFIG['weight_decay']; optimizer = None\n",
    "print(f\"\\nВыбор оптимизатора: {optimizer_name.upper()}\")\n",
    "if optimizer_name == 'adamw': optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "elif optimizer_name == 'adam': optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "else: print(f\"Предупреждение: Неизвестный '{optimizer_name}'. Используется AdamW.\"); optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "print(f\"Оптимизатор: {type(optimizer).__name__} (lr={lr:.1e}, weight_decay={wd:.1e})\")\n",
    "\n",
    "# 3. Scheduler - Инициализируется в Ячейке 13 перед обучением\n",
    "scheduler = None\n",
    "print(\"Планировщик: OneCycleLR (будет инициализирован перед циклом обучения)\")\n",
    "\n",
    "print(\"\\n--- Ячейка 8: Настройка Loss и Optimizer завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 9: Функции Декодирования и Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 9: Определение функций декодирования (Greedy) и метрики ---\n",
      "Функции ctc_greedy_decode и calculate_levenshtein определены.\n",
      "\n",
      "--- Ячейка 9: Определение функций декодирования и метрики завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 9: Функции Декодирования (Greedy) и Метрики (Levenshtein)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 9: Определение функций декодирования (Greedy) и метрики ---\")\n",
    "if 'index_to_char' not in globals() or not index_to_char or BLANK_IDX == -1 or PAD_IDX == -1:\n",
    "     raise ValueError(\"Словарь index_to_char или индексы BLANK/PAD не определены!\")\n",
    "\n",
    "# --- Greedy CTC Decoding ---\n",
    "def ctc_greedy_decode(logits: torch.Tensor, index_to_char_map: dict, blank_idx: int) -> list[str]:\n",
    "    decoded_batch = []\n",
    "    best_path = torch.argmax(logits, dim=2) # (Time, Batch)\n",
    "    best_path_np = best_path.cpu().numpy()\n",
    "    for i in range(best_path_np.shape[1]): # Iterate over batch\n",
    "        sequence_indices = best_path_np[:, i]\n",
    "        collapsed_indices = [idx for j, idx in enumerate(sequence_indices) if j == 0 or idx != sequence_indices[j-1]]\n",
    "        final_indices = [idx for idx in collapsed_indices if idx != blank_idx]\n",
    "        decoded_string = \"\".join([index_to_char_map.get(idx, '?') for idx in final_indices])\n",
    "        decoded_batch.append(decoded_string)\n",
    "    return decoded_batch\n",
    "\n",
    "# --- Levenshtein Distance ---\n",
    "def calculate_levenshtein(predictions: list[str], targets_padded: torch.Tensor,\n",
    "                          target_lengths: torch.Tensor, index_to_char_map: dict,\n",
    "                          pad_idx: int) -> tuple[float, list[tuple[str, str]]]:\n",
    "    total_distance = 0.0; num_valid_pairs = 0; decoded_pairs = []\n",
    "    batch_size = targets_padded.shape[0]\n",
    "    targets_np = targets_padded.cpu().numpy(); target_lengths_np = target_lengths.cpu().numpy()\n",
    "    if len(predictions) != batch_size: print(f\"Warning: Levenshtein size mismatch!\"); return float('inf'), []\n",
    "    for i in range(batch_size):\n",
    "        real_len = target_lengths_np[i]; pred_str = predictions[i]\n",
    "        if real_len <= 0: target_str = \"\"; dist = len(pred_str)\n",
    "        else:\n",
    "            target_indices = targets_np[i, :real_len]\n",
    "            target_str = \"\".join([index_to_char_map.get(idx, '?') for idx in target_indices if idx != pad_idx])\n",
    "            try: dist = Levenshtein.distance(pred_str, target_str)\n",
    "            except Exception as e: print(f\"Levenshtein Error: {e}\"); dist = max(len(pred_str), len(target_str))\n",
    "        total_distance += dist; num_valid_pairs += 1; decoded_pairs.append((pred_str, target_str))\n",
    "    mean_lev = total_distance / num_valid_pairs if num_valid_pairs > 0 else float('inf')\n",
    "    return mean_lev, decoded_pairs\n",
    "\n",
    "print(\"Функции ctc_greedy_decode и calculate_levenshtein определены.\")\n",
    "print(\"\\n--- Ячейка 9: Определение функций декодирования и метрики завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 10: Функции Обучения и Валидации Эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 10: Определение функций обучения и валидации эпохи ---\n",
      "Функции train_epoch и validate_epoch определены.\n",
      "\n",
      "--- Ячейка 10: Определение функций обучения и валидации завершено ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 10: Функции Обучения и Валидации Эпохи\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 10: Определение функций обучения и валидации эпохи ---\")\n",
    "# Проверки... (Проверяем основные функции и переменные)\n",
    "if 'ctc_greedy_decode' not in globals() or 'calculate_levenshtein' not in globals(): raise NameError(\"Функции decode/metric не определены.\")\n",
    "if BLANK_IDX == -1 or PAD_IDX == -1: raise ValueError(\"Индексы BLANK/PAD не определены!\")\n",
    "if 'model' not in globals() or model is None: raise NameError(\"Модель 'model' не определена!\")\n",
    "if 'device' not in globals(): raise NameError(\"Переменная 'device' не определена!\")\n",
    "if 'index_to_char' not in globals() or not index_to_char: raise NameError(\"Словарь 'index_to_char' не определен!\")\n",
    "\n",
    "# --- Train Epoch ---\n",
    "def train_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.CTCLoss,\n",
    "                optimizer: optim.Optimizer, scheduler: optim.lr_scheduler._LRScheduler,\n",
    "                device: torch.device, epoch_num: int, total_epochs: int,\n",
    "                index_to_char_map: dict, blank_idx: int, pad_idx: int,\n",
    "                grad_clip_norm: float) -> tuple[float, float, float]:\n",
    "    model.train(); running_loss = 0.0; total_lev_dist = 0.0; total_lr = 0.0; num_batches = 0; total_samples = 0\n",
    "    try: time_factor = model.get_time_reduction_factor()\n",
    "    except AttributeError: time_factor = 1.0\n",
    "    time_factor = max(time_factor, 1.0)\n",
    "    pbar = tqdm(dataloader, desc=f\"Эпоха {epoch_num}/{total_epochs} [Тренировка]\", leave=False, ncols=1000)\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(pbar):\n",
    "        if batch_data is None: continue\n",
    "        features, targets, feature_lengths, target_lengths = batch_data\n",
    "        if features is None or targets is None: continue\n",
    "        batch_size = features.size(0);\n",
    "        if batch_size == 0: continue\n",
    "        # Move to device\n",
    "        features = features.to(device, non_blocking=True); targets = targets.to(device, non_blocking=True)\n",
    "        feature_lengths_cpu = feature_lengths.cpu(); target_lengths_cpu = target_lengths.cpu()\n",
    "        input_lengths_ctc = torch.floor(feature_lengths_cpu.float() / time_factor + 1e-9).long().clamp(min=1)\n",
    "        # Training step\n",
    "        loss_value = float('inf'); lev_dist_batch = float('inf')\n",
    "        current_lr = optimizer.param_groups[0]['lr']; total_lr += current_lr; num_batches += 1\n",
    "        try:\n",
    "            optimizer.zero_grad(); logits = model(features); output_length = logits.shape[0] # (T, B, C)\n",
    "            if logits.shape[1] != batch_size: continue # Safety check\n",
    "            log_probs = F.log_softmax(logits, dim=2)\n",
    "            input_lengths_ctc_clamped = input_lengths_ctc.clamp(max=output_length)\n",
    "            target_lengths_clamped = target_lengths_cpu.clamp(max=targets.shape[1])\n",
    "            loss = criterion(log_probs, targets, input_lengths_ctc_clamped, target_lengths_clamped)\n",
    "            if not torch.isfinite(loss): print(f\"Warning: NaN/Inf loss in batch {batch_idx}. Skip step.\"); optimizer.zero_grad(); continue\n",
    "            loss_value = loss.item()\n",
    "            loss.backward()\n",
    "            if grad_clip_norm > 0: torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_norm)\n",
    "            optimizer.step()\n",
    "            if scheduler: scheduler.step() # OneCycleLR step per batch\n",
    "            # Calc Levenshtein (no grad)\n",
    "            with torch.no_grad():\n",
    "                decoded_preds = ctc_greedy_decode(logits, index_to_char_map, blank_idx)\n",
    "                lev_dist_batch, _ = calculate_levenshtein(decoded_preds, targets.cpu(), target_lengths_cpu, index_to_char_map, pad_idx)\n",
    "        except RuntimeError as e:\n",
    "             if \"CUDA out of memory\" in str(e): print(\"\\n!!! CUDA OOM Error !!!\"); raise e\n",
    "             else: print(f\"\\nRuntimeError batch {batch_idx}: {e}\"); traceback.print_exc(); loss_value=30.0; lev_dist_batch=float('inf')\n",
    "        except Exception as e: print(f\"\\nTrain Error batch {batch_idx}: {e}\"); traceback.print_exc(); loss_value=30.0; lev_dist_batch=float('inf')\n",
    "        # Update stats\n",
    "        if np.isfinite(loss_value): running_loss += loss_value * batch_size\n",
    "        else: running_loss += 30.0 * batch_size\n",
    "        lev_to_add = lev_dist_batch if np.isfinite(lev_dist_batch) else (features.shape[2] / 10.0)\n",
    "        total_lev_dist += lev_to_add * batch_size; total_samples += batch_size\n",
    "        pbar.set_postfix(loss=f'{loss_value:.4f}', lev=f'{lev_dist_batch:.4f}', lr=f'{current_lr:.2e}')\n",
    "    pbar.close()\n",
    "    avg_loss = running_loss / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lev = total_lev_dist / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lr = total_lr / num_batches if num_batches > 0 else 0.0\n",
    "    return avg_loss, avg_lev, avg_lr\n",
    "\n",
    "# --- Validate Epoch ---\n",
    "def validate_epoch(model: nn.Module, dataloader: DataLoader, criterion: nn.CTCLoss,\n",
    "                   device: torch.device, index_to_char_map: dict,\n",
    "                   blank_idx: int, pad_idx: int) -> tuple[float, float, list[tuple[str, str]]]:\n",
    "    model.eval(); running_loss = 0.0; total_lev_dist = 0.0; total_samples = 0; all_decoded_pairs = []\n",
    "    try: time_factor = model.get_time_reduction_factor()\n",
    "    except AttributeError: time_factor = 1.0\n",
    "    time_factor = max(time_factor, 1.0)\n",
    "    pbar = tqdm(dataloader, desc=\"   [Валидация]\", leave=False, ncols=1000)\n",
    "    with torch.no_grad():\n",
    "        for batch_data in pbar:\n",
    "            if batch_data is None: continue\n",
    "            features, targets, feature_lengths, target_lengths = batch_data\n",
    "            if features is None or targets is None: continue\n",
    "            batch_size = features.size(0);\n",
    "            if batch_size == 0: continue\n",
    "            features = features.to(device, non_blocking=True); targets = targets.to(device, non_blocking=True)\n",
    "            feature_lengths_cpu = feature_lengths.cpu(); target_lengths_cpu = target_lengths.cpu()\n",
    "            input_lengths_ctc = torch.floor(feature_lengths_cpu.float() / time_factor + 1e-9).long().clamp(min=1)\n",
    "            loss_value = float('inf'); lev_dist_batch = float('inf'); decoded_pairs_batch = []\n",
    "            try:\n",
    "                logits = model(features); output_length = logits.shape[0]\n",
    "                if logits.shape[1] != batch_size: continue\n",
    "                log_probs = F.log_softmax(logits, dim=2)\n",
    "                input_lengths_ctc_clamped = input_lengths_ctc.clamp(max=output_length)\n",
    "                target_lengths_clamped = target_lengths_cpu.clamp(max=targets.shape[1])\n",
    "                loss = criterion(log_probs, targets, input_lengths_ctc_clamped, target_lengths_clamped)\n",
    "                if torch.isfinite(loss): loss_value = loss.item()\n",
    "                decoded_preds = ctc_greedy_decode(logits, index_to_char_map, blank_idx)\n",
    "                lev_dist_batch, decoded_pairs_batch = calculate_levenshtein(\n",
    "                    decoded_preds, targets.cpu(), target_lengths_cpu, index_to_char_map, pad_idx )\n",
    "            except Exception as e: print(f\"\\nVal Error: {e}\"); traceback.print_exc(limit=1); loss_value=inf; lev_dist_batch=inf; decoded_pairs_batch = [(\"ERROR\",\"\")]*batch_size\n",
    "            # Update stats\n",
    "            if np.isfinite(loss_value): running_loss += loss_value * batch_size\n",
    "            lev_to_add = lev_dist_batch if np.isfinite(lev_dist_batch) else (features.shape[2] / 10.0)\n",
    "            total_lev_dist += lev_to_add * batch_size; total_samples += batch_size\n",
    "            if len(all_decoded_pairs) < 15: all_decoded_pairs.extend(decoded_pairs_batch)\n",
    "            pbar.set_postfix(loss=f'{loss_value:.4f}', lev=f'{lev_dist_batch:.4f}')\n",
    "    pbar.close()\n",
    "    avg_loss = running_loss / total_samples if total_samples > 0 else float('inf')\n",
    "    avg_lev = total_lev_dist / total_samples if total_samples > 0 else float('inf')\n",
    "    return avg_loss, avg_lev, all_decoded_pairs\n",
    "\n",
    "print(\"Функции train_epoch и validate_epoch определены.\")\n",
    "print(\"\\n--- Ячейка 10: Определение функций обучения и валидации завершено ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1: Вывод Финальной Конфигурации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 12.1: Финальная Конфигурация Перед Обучением ---\n",
      "AUDIO_CONFIG:\n",
      "{\n",
      "  \"sample_rate\": 8000,\n",
      "  \"frame_length_rms\": 384,\n",
      "  \"hop_length_rms\": 96,\n",
      "  \"filter_order\": 5,\n",
      "  \"filter_fmin\": 0,\n",
      "  \"filter_fmax\": 3999,\n",
      "  \"delta_type\": \"standard\",\n",
      "  \"delta_alpha\": 1.0,\n",
      "  \"rms_smoothing_window_size\": 1,\n",
      "  \"delta_ma_smoothing_window_size\": 1\n",
      "}\n",
      "\n",
      "MODEL_CONFIG:\n",
      "{\n",
      "  \"input_feature_dim\": 2,\n",
      "  \"cnn_out_channels\": [\n",
      "    64,\n",
      "    128,\n",
      "    128\n",
      "  ],\n",
      "  \"cnn_kernel_size\": 9,\n",
      "  \"cnn_stride\": 1,\n",
      "  \"cnn_padding\": \"same\",\n",
      "  \"cnn_pool_kernel\": 2,\n",
      "  \"rnn_hidden_size\": 256,\n",
      "  \"rnn_num_layers\": 2,\n",
      "  \"dropout_rate\": 0.2,\n",
      "  \"activation_fn\": \"GELU\"\n",
      "}\n",
      "\n",
      "TRAIN_CONFIG:\n",
      "{\n",
      "  \"batch_size\": 8,\n",
      "  \"num_workers\": 0,\n",
      "  \"num_epochs\": 30,\n",
      "  \"learning_rate\": 0.0005,\n",
      "  \"final_div_factor\": 100,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"optimizer\": \"AdamW\",\n",
      "  \"noise_level\": 0.0,\n",
      "  \"early_stopping_patience\": 7,\n",
      "  \"gradient_clip_norm\": 2.0,\n",
      "  \"validation_split_ratio\": 0.1,\n",
      "  \"base_seed\": 42\n",
      "}\n",
      "\n",
      "Пути для сохранения:\n",
      "  Модель: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR5e-04_WD1e-04_Deltastandard.pth\n",
      "  Параметры: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\params_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR5e-04_WD1e-04_Deltastandard.json\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 12.1: Финальная Конфигурация Перед Обучением ---\")\n",
    "print(\"AUDIO_CONFIG:\")\n",
    "print(json.dumps(AUDIO_CONFIG, indent=2))\n",
    "print(\"\\nMODEL_CONFIG:\")\n",
    "print(json.dumps(MODEL_CONFIG, indent=2))\n",
    "print(\"\\nTRAIN_CONFIG:\")\n",
    "print(json.dumps(TRAIN_CONFIG, indent=2))\n",
    "print(\"\\nПути для сохранения:\")\n",
    "print(f\"  Модель: {BEST_MODEL_PATH}\")\n",
    "print(f\"  Параметры: {PARAMS_PATH}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 12.4: Интерактивная Визуализация Сигналов и Дельт для Разных Фильтров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 12.4: Визуализация Признаков (Опционально) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b0f0b1083f461ca80b33575cd93f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<b>Визуализация признаков (RMS/Delta):</b>'), Dropdown(description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ячейка 12: Завершена ---\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 12.4: Интерактивная Визуализация Признаков (Опционально)\n",
    "print(\"\\n--- 12.4: Визуализация Признаков (Опционально) ---\")\n",
    "if IPYWIDGETS_AVAILABLE and 'train_df' in globals() and train_df is not None and not train_df.empty \\\n",
    "   and 'AUDIO_CONFIG' in globals() and 'EXTRACTED_AUDIO_DIR' in globals() and EXTRACTED_AUDIO_DIR.is_dir() \\\n",
    "   and 'MorseDataset' in globals() and 'TRAIN_CONFIG' in globals():\n",
    "    # (Код визуализации из Ячейки 12.4 предыдущих версий - без изменений)\n",
    "    # (Важно: он использует MorseDataset._apply_filter и _calculate_features\n",
    "    #  с текущими AUDIO_CONFIG, т.е. покажет признаки БЕЗ сглаживания)\n",
    "    # --- Параметры ---\n",
    "    sr_vis=AUDIO_CONFIG['sample_rate']; frame_len_vis=AUDIO_CONFIG['frame_length_rms']; hop_len_vis=AUDIO_CONFIG['hop_length_rms']\n",
    "    delta_type_vis=AUDIO_CONFIG.get('delta_type', 'standard'); delta_alpha_vis=AUDIO_CONFIG.get('delta_alpha', 1.0)\n",
    "    fmin_vis=AUDIO_CONFIG.get('filter_fmin', 0); fmax_vis=AUDIO_CONFIG.get('filter_fmax', 4000)\n",
    "    # --- Функция расчета (без сглаж. и норм.) ---\n",
    "    def calculate_vis_features_raw_vis(waveform_np, sr, frame, hop, delta_t, delta_a):\n",
    "        rms_env = np.array([]); delta_fin = np.array([])\n",
    "        if not isinstance(waveform_np, np.ndarray) or waveform_np.size==0: return rms_env, delta_fin\n",
    "        try:\n",
    "            temp_ds = MorseDataset(pd.DataFrame({'id':['d']}), Path('.'), {}, AUDIO_CONFIG, 2, TRAIN_CONFIG, is_train=False)\n",
    "            wf_filt = temp_ds._apply_filter(waveform_np); del temp_ds\n",
    "            if wf_filt.size==0: return rms_env, delta_fin\n",
    "            rms_env = librosa.feature.rms(y=wf_filt, frame_length=frame, hop_length=hop, center=True, pad_mode='reflect')[0]\n",
    "            if rms_env.size<2: return rms_env, delta_fin\n",
    "            delta_std = np.diff(rms_env, n=1, prepend=rms_env[0]); delta_fin = delta_std\n",
    "            #if delta_t=='cubed': delta_fin = np.power(delta_a*delta_std,3) # Add other types if needed\n",
    "            return rms_env, delta_fin\n",
    "        except Exception as e: print(f\"Vis Error: {e}\"); return rms_env, delta_fin\n",
    "    # --- Виджеты ---\n",
    "    file_ids_vis = train_df['id'].unique().tolist(); file_ids_vis=file_ids_vis[:500]\n",
    "    file_dd_vis = widgets.Dropdown(options=file_ids_vis, description='Файл:', style={'description_width': 'initial'}, layout=widgets.Layout(width='80%'))\n",
    "    output_vis = widgets.Output()\n",
    "    # --- Функция обновления ---\n",
    "    def update_vis(change):\n",
    "        fid = file_dd_vis.value\n",
    "        with output_vis:\n",
    "            clear_output(wait=True); print(f\"Файл: {fid} (Без сглаживания)\")\n",
    "            path = EXTRACTED_AUDIO_DIR / fid;\n",
    "            if not path.is_file(): print(f\"Не найден: {path}\"); return\n",
    "            try:\n",
    "                wf, _ = librosa.load(path, sr=sr_vis, mono=True);\n",
    "                if wf.size==0: print(\"Пустой waveform\"); return\n",
    "                display(Audio(data=wf, rate=sr_vis))\n",
    "                rms_v, delta_v = calculate_vis_features_raw_vis(wf, sr_vis, frame_len_vis, hop_len_vis, delta_type_vis, delta_alpha_vis)\n",
    "                fig,ax = plt.subplots(2,1,figsize=(14,6),sharex=True)\n",
    "                fig.suptitle(f\"Признаки: {fid} | Фильтр: {fmin_vis}-{fmax_vis}Hz | Без сглаживания\",fontsize=14)\n",
    "                times_v = librosa.times_like(rms_v, sr=sr_vis, hop_length=hop_len_vis) if rms_v.size>0 else np.array([])\n",
    "                ax[0].plot(times_v, rms_v, label='RMS (Raw)', c='b', lw=1); ax[0].set_title(\"RMS\"); ax[0].legend(); ax[0].grid(True, ls=':');\n",
    "                if rms_v.size>0: ax[0].set_ylim(0, np.max(rms_v)*1.1 if np.max(rms_v)>0 else 1)\n",
    "                ax[1].plot(times_v, delta_v, label=f'Delta ({delta_type_vis}, Raw)', c='r', lw=1); ax[1].axhline(0, c='k', ls=':', lw=1)\n",
    "                ax[1].set_title(\"Delta\"); ax[1].legend(); ax[1].grid(True, ls=':'); ax[1].set_xlabel(\"Время (с)\")\n",
    "                if delta_v.size>0: mn,mx=np.min(delta_v),np.max(delta_v); marg=(mx-mn)*0.1 if (mx-mn)>1e-6 else 0.1; ax[1].set_ylim(mn-marg,mx+marg)\n",
    "                plt.tight_layout(rect=[0,0.03,1,0.93]); plt.show()\n",
    "            except Exception as e: print(f\"Vis Error {fid}: {e}\"); traceback.print_exc(limit=1)\n",
    "    # --- Отображение ---\n",
    "    file_dd_vis.observe(update_vis, names='value')\n",
    "    controls_vis = widgets.VBox([widgets.HTML(\"<b>Визуализация признаков (RMS/Delta):</b>\"), file_dd_vis])\n",
    "    ui_vis = widgets.VBox([controls_vis, output_vis])\n",
    "    display(ui_vis)\n",
    "    if not train_df.empty: update_vis(None)\n",
    "else: print(\"Визуализация пропущена (ipywidgets не найден / данные отсутствуют).\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Ячейка 12: Завершена ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 13: Основной Цикл Обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 13: Запуск Основного Цикла Обучения (с MLflow) ---\n",
      "MLflow Версия: 2.21.3\n",
      "\n",
      "Подготовка Dataset и DataLoaders...\n",
      "MorseDataset создан: is_train=True, delta_type='standard', Фильтр=0-3999Hz (Порядок 5), Сглаживание RMS/Delta=ВЫКЛ, Шум=0.0\n",
      "Разделение: Train=27000, Validation=3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/08 19:53:36 INFO mlflow.tracking.fluent: Experiment with name 'Morse Recognition Training' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Созданы Train (3375 батчей) и Val (188 батчей) DataLoaders.\n",
      "\n",
      "Инициализация OneCycleLR: total_steps=101250, max_lr=5.0e-04, final_div_factor=100\n",
      "Планировщик OneCycleLR создан.\n",
      "\n",
      "Настройка MLflow...\n",
      "MLflow готов. Логи будут сохраняться локально в папку './mlruns'.\n",
      "Запустите 'mlflow ui' в терминале в папке проекта для просмотра.\n",
      "\n",
      "--- Начало основного обучения (30 эпох) ---\n",
      "MLflow Run ID: b2361fafef324f3e8a9bf0d876709a81\n",
      "Модель будет сохранена как: model_Filt0-3999Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_LR5e-04_WD1e-04_Deltastandard.pth\n",
      "Логирование параметров в MLflow...\n",
      "\n",
      "--- Эпоха 1/30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f3854a678d415a8a8194017c9250ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 1/30 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a75680f0c2e4117b34a68df21c64437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоги Эпохи 1/30 | Время: 398.22 сек | Ср.LR: 2.484e-05\n",
      "  Train Loss: 4.2863 | Train Levenshtein: 8.9695\n",
      "  Val Loss:   2.3132 | Val Levenshtein:   6.0903\n",
      "  Примеры декодирования (Greedy):\n",
      "    1: 'РА32' | 'ФААР834ОМП'\n",
      "    2: '7 4Б' | 'Т0С ЖЩ0О БМЫ'\n",
      "    3: 'ЬНЖУ3ЭХ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    4: 'ИИЭ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    5: '6Ф2' | '#6ЧФ8ЮО'\n",
      "  ✨ Val Lev улучшился: inf -> 6.0903. Сохранение локальной модели...\n",
      "  Временная модель сохранена в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\temp_best_model_mlflow_b2361fafef324f3e8a9bf0d876709a81.pth\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Эпоха 2/30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f6e16336b44ac5a01d395d7dfdc820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 2/30 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f9dd7981f64dd1a0388aa187b958d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоги Эпохи 2/30 | Время: 389.24 сек | Ср.LR: 5.320e-05\n",
      "  Train Loss: 1.0124 | Train Levenshtein: 2.2108\n",
      "  Val Loss:   0.5421 | Val Levenshtein:   1.1460\n",
      "  Примеры декодирования (Greedy):\n",
      "    1: 'ФААР83Ю0МП' | 'ФААР834ОМП'\n",
      "    2: 'ТОС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    3: 'ЬЛННЖЗУЯН3ЭХЛ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    4: 'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    5: '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "  ✨ Val Lev улучшился: 6.0903 -> 1.1460. Сохранение локальной модели...\n",
      "  Временная модель сохранена в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\temp_best_model_mlflow_b2361fafef324f3e8a9bf0d876709a81.pth\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Эпоха 3/30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1159f9bf5b474055bd1e2d6ddbc43726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 3/30 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f25345f98c14f49aa53970c2e5bb9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоги Эпохи 3/30 | Время: 275.70 сек | Ср.LR: 1.065e-04\n",
      "  Train Loss: 0.5585 | Train Levenshtein: 1.2293\n",
      "  Val Loss:   0.4495 | Val Levenshtein:   1.0150\n",
      "  Примеры декодирования (Greedy):\n",
      "    1: 'ФААР83ЮО0МП' | 'ФААР834ОМП'\n",
      "    2: 'ТШС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    3: 'ЬЛННЖЗУЯНИ3ЭХЛ' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    4: 'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    5: '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "  ✨ Val Lev улучшился: 1.1460 -> 1.0150. Сохранение локальной модели...\n",
      "  Временная модель сохранена в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\temp_best_model_mlflow_b2361fafef324f3e8a9bf0d876709a81.pth\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Эпоха 4/30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b606c08ab7456d89341c2576226a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 4/30 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c187b3bfda417eb9c48e67ebd7dd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоги Эпохи 4/30 | Время: 417.93 сек | Ср.LR: 1.783e-04\n",
      "  Train Loss: 0.4731 | Train Levenshtein: 1.0864\n",
      "  Val Loss:   0.4003 | Val Levenshtein:   0.9170\n",
      "  Примеры декодирования (Greedy):\n",
      "    1: 'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    2: 'ТШС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    3: 'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    4: 'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    5: '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "  ✨ Val Lev улучшился: 1.0150 -> 0.9170. Сохранение локальной модели...\n",
      "  Временная модель сохранена в: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\temp_best_model_mlflow_b2361fafef324f3e8a9bf0d876709a81.pth\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Эпоха 5/30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8e129b98e64b2eba074ef208ea8a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 5/30 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cc008388534a0aa591bb849e1474f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "   [Валидация]:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоги Эпохи 5/30 | Время: 262.36 сек | Ср.LR: 2.600e-04\n",
      "  Train Loss: 0.4283 | Train Levenshtein: 1.0033\n",
      "  Val Loss:   0.3883 | Val Levenshtein:   0.9213\n",
      "  Примеры декодирования (Greedy):\n",
      "    1: 'ФААР83ЮОМП' | 'ФААР834ОМП'\n",
      "    2: 'ТЧС ЖЩ0З БМЫ' | 'Т0С ЖЩ0О БМЫ'\n",
      "    3: 'ЬЛННЖЗУЯН3ЭХ7' | 'ЬЛННЖЗУЯН3ЭХ7'\n",
      "    4: 'АИИ9Ъ9ОЭЯЕ' | 'АИИ9Ъ9ОЭЯЕ'\n",
      "    5: '#6ЧФ8ЮО' | '#6ЧФ8ЮО'\n",
      "  Val Lev не улучшился (0.9213 vs best 0.9170). Эпох без улучшений: 1/7\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Эпоха 6/30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a937fa5025437093f8d7498e59b0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 6/30 [Тренировка]:   0%|                                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 13: Основной Цикл Обучения (с MLflow)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 13: Запуск Основного Цикла Обучения (с MLflow) ---\")\n",
    "\n",
    "# --- Добавляем импорты MLflow ---\n",
    "import mlflow\n",
    "import mlflow.pytorch # Для интеграции с PyTorch (опционально для автологирования, но полезно для log_model)\n",
    "print(f\"MLflow Версия: {mlflow.__version__}\")\n",
    "\n",
    "# --- Проверки готовности ---\n",
    "required_vars = [ # Проверяем все, включая mlflow\n",
    "    'model_created_successfully', 'model', 'criterion', 'optimizer', 'mlflow', # Заменили wandb на mlflow\n",
    "    'train_df', 'index_to_char', 'char_to_index', 'AUDIO_CONFIG', 'MODEL_CONFIG', 'TRAIN_CONFIG',\n",
    "    'device', 'collate_fn', 'MorseDataset', 'train_epoch', 'validate_epoch',\n",
    "    'BEST_MODEL_PATH', 'PARAMS_PATH', 'EXTRACTED_AUDIO_DIR', 'BLANK_IDX', 'PAD_IDX'\n",
    "]\n",
    "missing_vars = [v for v in required_vars if v not in globals() or globals()[v] is None]\n",
    "if missing_vars: raise SystemExit(f\"Остановка: Отсутствуют компоненты для обучения: {missing_vars}\")\n",
    "if not model_created_successfully: raise SystemExit(\"Остановка: Модель не создана.\")\n",
    "\n",
    "# --- Подготовка Dataset и DataLoaders ---\n",
    "train_loader, val_loader = None, None; main_loaders_ready = False\n",
    "print(\"\\nПодготовка Dataset и DataLoaders...\")\n",
    "try:\n",
    "    # (Код создания Dataset и DataLoader без изменений)\n",
    "    full_train_dataset = MorseDataset(\n",
    "        dataframe=train_df, audio_dir=EXTRACTED_AUDIO_DIR, char_to_index=char_to_index,\n",
    "        audio_config=AUDIO_CONFIG, model_input_feature_dim=MODEL_CONFIG['input_feature_dim'],\n",
    "        train_config=TRAIN_CONFIG, is_train=True )\n",
    "    if len(full_train_dataset) == 0: raise ValueError(\"Обучающий датасет пуст!\")\n",
    "    dataset_size = len(full_train_dataset); val_split_ratio = TRAIN_CONFIG['validation_split_ratio']\n",
    "    val_size = int(np.floor(val_split_ratio * dataset_size)); train_size = dataset_size - val_size\n",
    "    if train_size <= 0 or val_size <= 0: raise ValueError(f\"Некорректное разделение: Train={train_size}, Val={val_size}\")\n",
    "    print(f\"Разделение: Train={train_size}, Validation={val_size}\")\n",
    "    train_subset, val_subset = random_split(full_train_dataset, [train_size, val_size],\n",
    "                                            generator=torch.Generator().manual_seed(TRAIN_CONFIG['base_seed']))\n",
    "    bs = TRAIN_CONFIG['batch_size']; nw = TRAIN_CONFIG['num_workers']; pm = (device.type == 'cuda')\n",
    "    train_loader = DataLoader(train_subset, batch_size=bs, shuffle=True, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "    val_loader = DataLoader(val_subset, batch_size=bs*2, shuffle=False, collate_fn=collate_fn, num_workers=nw, pin_memory=pm)\n",
    "    print(f\"Созданы Train ({len(train_loader)} батчей) и Val ({len(val_loader)} батчей) DataLoaders.\")\n",
    "    main_loaders_ready = True\n",
    "except Exception as e: print(f\"Критическая ошибка DataLoader: {e}\"); traceback.print_exc(); main_loaders_ready = False\n",
    "\n",
    "# --- Инициализация Планировщика OneCycleLR ---\n",
    "scheduler = None\n",
    "if main_loaders_ready and train_loader is not None:\n",
    "    try:\n",
    "        # (Код инициализации OneCycleLR без изменений)\n",
    "        steps_per_epoch = len(train_loader);\n",
    "        if steps_per_epoch == 0: raise ValueError(\"Train loader имеет 0 батчей!\")\n",
    "        total_steps = TRAIN_CONFIG['num_epochs'] * steps_per_epoch\n",
    "        max_lr = TRAIN_CONFIG['learning_rate']; final_div = TRAIN_CONFIG.get('final_div_factor', 1e4)\n",
    "        print(f\"\\nИнициализация OneCycleLR: total_steps={total_steps}, max_lr={max_lr:.1e}, final_div_factor={final_div}\")\n",
    "        scheduler = OneCycleLR(optimizer, max_lr=max_lr, total_steps=total_steps,\n",
    "                               pct_start=0.3, anneal_strategy='cos', div_factor=25.0, final_div_factor=final_div)\n",
    "        print(\"Планировщик OneCycleLR создан.\")\n",
    "    except Exception as e: print(f\"!!! Ошибка OneCycleLR: {e} !!!\"); traceback.print_exc(); scheduler = None; main_loaders_ready = False\n",
    "\n",
    "# --- Настройка и Запуск MLflow ---\n",
    "mlflow_enabled = False # Флаг для проверки успешности запуска\n",
    "if main_loaders_ready and scheduler is not None:\n",
    "    print(\"\\nНастройка MLflow...\")\n",
    "    try:\n",
    "        # Задаем имя эксперимента (если его нет, он будет создан)\n",
    "        mlflow.set_experiment(\"Morse Recognition Training\")\n",
    "        mlflow_enabled = True\n",
    "        print(f\"MLflow готов. Логи будут сохраняться локально в папку './mlruns'.\")\n",
    "        print(\"Запустите 'mlflow ui' в терминале в папке проекта для просмотра.\")\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Ошибка настройки MLflow: {e}. Обучение продолжится без логирования в MLflow.\")\n",
    "\n",
    "# --- Основной Цикл Обучения ---\n",
    "if main_loaders_ready and scheduler is not None:\n",
    "    # --- Начинаем MLflow Run ---\n",
    "    with mlflow.start_run(run_name=f\"train_{FINAL_SUFFIX}\"): # Используем 'with', чтобы run завершился автоматически\n",
    "        print(f\"\\n--- Начало основного обучения ({TRAIN_CONFIG['num_epochs']} эпох) ---\")\n",
    "        print(f\"MLflow Run ID: {mlflow.active_run().info.run_id}\")\n",
    "        print(f\"Модель будет сохранена как: {BEST_MODEL_PATH.name}\")\n",
    "\n",
    "        # Логирование параметров в MLflow\n",
    "        if mlflow_enabled:\n",
    "            print(\"Логирование параметров в MLflow...\")\n",
    "            mlflow.log_param(\"seed\", SEED)\n",
    "            mlflow.log_params(TRAIN_CONFIG)\n",
    "            # Логируем словари аудио и модели \"как есть\"\n",
    "            # MLflow UI может отображать их как JSON/YAML\n",
    "            mlflow.log_dict(AUDIO_CONFIG, \"audio_config.json\")\n",
    "            mlflow.log_dict(MODEL_CONFIG, \"model_config.json\")\n",
    "            # Можно также логировать отдельные вложенные параметры, если нужно их сравнивать напрямую\n",
    "            # mlflow.log_param(\"cnn_kernel_size\", MODEL_CONFIG[\"cnn_kernel_size\"])\n",
    "\n",
    "        start_time_total = time.time()\n",
    "        best_val_levenshtein = float('inf'); epochs_without_improvement = 0\n",
    "        best_model_local_path = None; best_epoch_num = None # Переменные для лучшей модели/эпохи\n",
    "        # Словарь для локальных графиков (если нужен)\n",
    "        training_history = {'train_loss': [], 'train_lev': [], 'val_loss': [], 'val_lev': [], 'lr': []}\n",
    "\n",
    "        try:\n",
    "            for epoch in range(1, TRAIN_CONFIG['num_epochs'] + 1):\n",
    "                epoch_start_time = time.time()\n",
    "                print(f\"\\n--- Эпоха {epoch}/{TRAIN_CONFIG['num_epochs']} ---\")\n",
    "                # --- Тренировка ---\n",
    "                avg_train_loss, avg_train_lev, avg_epoch_lr = train_epoch(\n",
    "                    model=model, dataloader=train_loader, criterion=criterion, optimizer=optimizer,\n",
    "                    scheduler=scheduler, device=device, epoch_num=epoch, total_epochs=TRAIN_CONFIG['num_epochs'],\n",
    "                    index_to_char_map=index_to_char, blank_idx=BLANK_IDX, pad_idx=PAD_IDX,\n",
    "                    grad_clip_norm=TRAIN_CONFIG['gradient_clip_norm'] )\n",
    "                # --- Валидация ---\n",
    "                avg_val_loss, avg_val_lev, val_examples = validate_epoch(\n",
    "                    model=model, dataloader=val_loader, criterion=criterion, device=device,\n",
    "                    index_to_char_map=index_to_char, blank_idx=BLANK_IDX, pad_idx=PAD_IDX )\n",
    "                epoch_duration = time.time() - epoch_start_time\n",
    "\n",
    "                # Запись в локальную историю для графиков matplotlib\n",
    "                training_history['train_loss'].append(avg_train_loss)\n",
    "                training_history['train_lev'].append(avg_train_lev)\n",
    "                training_history['val_loss'].append(avg_val_loss)\n",
    "                training_history['val_lev'].append(avg_val_lev)\n",
    "                training_history['lr'].append(avg_epoch_lr)\n",
    "\n",
    "                # --- Логирование метрик в MLflow (если включен) ---\n",
    "                if mlflow_enabled:\n",
    "                    mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
    "                    mlflow.log_metric(\"train_levenshtein\", avg_train_lev, step=epoch)\n",
    "                    mlflow.log_metric(\"val_loss\", avg_val_loss, step=epoch)\n",
    "                    mlflow.log_metric(\"val_levenshtein\", avg_val_lev, step=epoch)\n",
    "                    mlflow.log_metric(\"learning_rate\", avg_epoch_lr, step=epoch)\n",
    "\n",
    "                # --- Вывод результатов эпохи ---\n",
    "                print(f\"\\nИтоги Эпохи {epoch}/{TRAIN_CONFIG['num_epochs']} | Время: {epoch_duration:.2f} сек | Ср.LR: {avg_epoch_lr:.3e}\")\n",
    "                print(f\"  Train Loss: {avg_train_loss:.4f} | Train Levenshtein: {avg_train_lev:.4f}\")\n",
    "                print(f\"  Val Loss:   {avg_val_loss:.4f} | Val Levenshtein:   {avg_val_lev:.4f}\")\n",
    "                print(\"  Примеры декодирования (Greedy):\")\n",
    "                for i, (pred, real) in enumerate(val_examples[:5]): print(f\"    {i+1}: '{pred[:70]}' | '{real[:70]}'\")\n",
    "\n",
    "                # --- Сохранение лучшей модели ЛОКАЛЬНО и Early Stopping ---\n",
    "                if np.isfinite(avg_val_lev) and avg_val_lev < best_val_levenshtein:\n",
    "                    print(f\"  ✨ Val Lev улучшился: {best_val_levenshtein:.4f} -> {avg_val_lev:.4f}. Сохранение локальной модели...\")\n",
    "                    best_val_levenshtein = avg_val_lev; best_epoch_num = epoch\n",
    "                    best_model_local_path = OUTPUT_DIR / f\"temp_best_model_mlflow_{mlflow.active_run().info.run_id if mlflow_enabled else 'local'}.pth\"\n",
    "                    try:\n",
    "                        torch.save(model.state_dict(), best_model_local_path)\n",
    "                        print(f\"  Временная модель сохранена в: {best_model_local_path}\")\n",
    "                    except Exception as save_err: print(f\"  !!! Ошибка сохранения временной модели: {save_err} !!!\")\n",
    "                    epochs_without_improvement = 0\n",
    "                else:\n",
    "                    epochs_without_improvement += 1\n",
    "                    print(f\"  Val Lev не улучшился ({avg_val_lev:.4f} vs best {best_val_levenshtein:.4f}). Эпох без улучшений: {epochs_without_improvement}/{TRAIN_CONFIG['early_stopping_patience']}\")\n",
    "                if epochs_without_improvement >= TRAIN_CONFIG['early_stopping_patience']:\n",
    "                    print(f\"\\n❗️ Ранняя остановка!\"); break\n",
    "                print(\"-\" * 60)\n",
    "\n",
    "        except KeyboardInterrupt: print(\"\\nОбучение прервано пользователем.\")\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA out of memory\" in str(e): print(\"\\n!!! Критическая ошибка: CUDA OOM !!!\")\n",
    "            else: print(f\"\\n!!! Runtime Error: {e} !!!\"); traceback.print_exc()\n",
    "        except Exception as train_err: print(f\"\\n!!! НЕПРЕДВИДЕННАЯ ОШИБКА ОБУЧЕНИЯ: {train_err} !!!\"); traceback.print_exc()\n",
    "        finally:\n",
    "            total_training_time = time.time() - start_time_total\n",
    "            print(f\"\\n--- Основное Обучение Завершено ---\")\n",
    "            print(f\"Общее время: {total_training_time / 60:.2f} мин\")\n",
    "            best_lev_str = f\"{best_val_levenshtein:.4f}\" if np.isfinite(best_val_levenshtein) else \"N/A\"\n",
    "            best_epoch_str = str(best_epoch_num) if best_epoch_num is not None else \"?\"\n",
    "            print(f\"Лучший Val Levenshtein: {best_lev_str} (на эпохе {best_epoch_str})\")\n",
    "\n",
    "            # --- Логирование финальных метрик и артефактов в MLflow ---\n",
    "            if mlflow_enabled:\n",
    "                print(\"\\nЛогирование артефактов и финальных метрик в MLflow...\")\n",
    "                try:\n",
    "                    # Логируем лучшую метрику\n",
    "                    if np.isfinite(best_val_levenshtein):\n",
    "                         mlflow.log_metric(\"best_val_levenshtein\", best_val_levenshtein)\n",
    "                         if best_epoch_num is not None:\n",
    "                              mlflow.log_metric(\"best_epoch\", best_epoch_num)\n",
    "\n",
    "                    # Логируем лучшую модель как артефакт\n",
    "                    if best_model_local_path and best_model_local_path.exists() and np.isfinite(best_val_levenshtein):\n",
    "                         # Вариант 1: Логирование как простой файл .pth\n",
    "                         mlflow.log_artifact(str(best_model_local_path), artifact_path=\"model\")\n",
    "                         print(f\"  Артефакт модели '{best_model_local_path.name}' залогирован (как .pth файл).\")\n",
    "                         # Вариант 2: Логирование в формате mlflow.pytorch (создаст папку)\n",
    "                         # mlflow.pytorch.log_model(model, \"pytorch_model\", registered_model_name=\"MorseRecognizerModel\") # Загружает текущее состояние модели!\n",
    "                         # print(f\"  Модель залогирована в формате mlflow.pytorch.\")\n",
    "                    elif np.isfinite(best_val_levenshtein):\n",
    "                         print(f\"  Артефакт модели не логирован (файл {best_model_local_path} не найден?).\")\n",
    "\n",
    "                    # Сохраняем и логируем финальные параметры\n",
    "                    final_params_to_save = {\n",
    "                        'audio_config': AUDIO_CONFIG, 'model_config': MODEL_CONFIG, 'train_config': TRAIN_CONFIG,\n",
    "                        'char_map': { 'char_to_index': char_to_index, 'index_to_char': {k:v for k,v in index_to_char.items()},\n",
    "                                      'BLANK_IDX': BLANK_IDX, 'PAD_IDX': PAD_IDX, 'NUM_CLASSES_CTC': NUM_CLASSES_CTC },\n",
    "                        'best_val_levenshtein': best_val_levenshtein if np.isfinite(best_val_levenshtein) else None,\n",
    "                        'best_epoch': best_epoch_num\n",
    "                    }\n",
    "                    params_temp_path = OUTPUT_DIR / f\"params_{mlflow.active_run().info.run_id}.json\"\n",
    "                    with open(params_temp_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(final_params_to_save, f, indent=4, ensure_ascii=False)\n",
    "                    mlflow.log_artifact(str(params_temp_path), artifact_path=\"config\")\n",
    "                    print(f\"  Артефакт конфигурации '{params_temp_path.name}' залогирован.\")\n",
    "                    # Сохраняем копию с финальным именем локально\n",
    "                    try:\n",
    "                        PARAMS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "                        params_temp_path.rename(PARAMS_PATH) # Переименовываем временный файл в финальный\n",
    "                        print(f\"  Локальный файл параметров сохранен/переименован в: {PARAMS_PATH}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  Ошибка переименования файла параметров: {e}. Финальный конфиг остался в: {params_temp_path}\")\n",
    "                        # Не удаляем временный файл, если не удалось переименовать\n",
    "                        # Можно скопировать, если rename не работает на разных дисках/разделах\n",
    "                        # import shutil\n",
    "                        # shutil.copy2(params_temp_path, PARAMS_PATH)\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                     print(f\"!!! Ошибка логирования артефактов/метрик в MLflow: {e} !!!\")\n",
    "            else:\n",
    "                # Если MLflow не включен, просто сохраняем параметры локально\n",
    "                 print(\"\\nСохранение финальных параметров конфигурации (локально)...\")\n",
    "                 final_params_to_save = {\n",
    "                     'audio_config': AUDIO_CONFIG, 'model_config': MODEL_CONFIG, 'train_config': TRAIN_CONFIG,\n",
    "                     'char_map': { 'char_to_index': char_to_index, 'index_to_char': {k:v for k,v in index_to_char.items()},\n",
    "                                   'BLANK_IDX': BLANK_IDX, 'PAD_IDX': PAD_IDX, 'NUM_CLASSES_CTC': NUM_CLASSES_CTC },\n",
    "                     'best_val_levenshtein': best_val_levenshtein if np.isfinite(best_val_levenshtein) else None,\n",
    "                     'best_epoch': best_epoch_num\n",
    "                 }\n",
    "                 try:\n",
    "                      PARAMS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "                      with open(PARAMS_PATH, 'w', encoding='utf-8') as f:\n",
    "                          json.dump(final_params_to_save, f, indent=4, ensure_ascii=False)\n",
    "                      print(f\"Параметры сохранены локально в: {PARAMS_PATH}\")\n",
    "                 except Exception as e: print(f\"!!! Ошибка сохранения параметров: {e} !!!\")\n",
    "\n",
    "\n",
    "            # --- Переименование лучшей локальной модели в финальный путь ---\n",
    "            # Делаем это после логирования в MLflow, на всякий случай\n",
    "            if best_model_local_path and best_model_local_path.exists() and np.isfinite(best_val_levenshtein):\n",
    "                 try:\n",
    "                     BEST_MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "                     # Проверяем, не совпадает ли временный путь с финальным (маловероятно, но все же)\n",
    "                     if best_model_local_path.resolve() != BEST_MODEL_PATH.resolve():\n",
    "                          best_model_local_path.rename(BEST_MODEL_PATH)\n",
    "                          print(f\"Лучшая локальная модель перемещена в: {BEST_MODEL_PATH}\")\n",
    "                     else:\n",
    "                          print(f\"Лучшая модель уже находится по финальному пути: {BEST_MODEL_PATH}\")\n",
    "                 except Exception as e:\n",
    "                     print(f\"!!! Ошибка перемещения лучшей модели из {best_model_local_path} в {BEST_MODEL_PATH}: {e} !!!\")\n",
    "                     print(f\"    Лучшая модель осталась в: {best_model_local_path}\")\n",
    "            elif np.isfinite(best_val_levenshtein):\n",
    "                 print(f\"!!! Предупреждение: Файл лучшей модели {best_model_local_path} не найден для финального перемещения.\")\n",
    "            else:\n",
    "                 print(\"!!! Лучшая модель не была сохранена (нет конечного результата Levenshtein).\")\n",
    "\n",
    "\n",
    "            # --- Построение графиков обучения (Локально) ---\n",
    "            print(\"\\nПостроение локальных графиков истории обучения...\")\n",
    "            if training_history and training_history.get('train_loss'):\n",
    "                 epochs_completed = len(training_history['train_loss'])\n",
    "                 if epochs_completed > 0:\n",
    "                     # (Код matplotlib без изменений)\n",
    "                     epoch_axis = range(1, epochs_completed + 1)\n",
    "                     plt.figure(figsize=(18, 5)); plt.subplot(1, 3, 1)\n",
    "                     plt.plot(epoch_axis, training_history['train_loss'], 'o-', label='Train Loss'); plt.plot(epoch_axis, training_history['val_loss'], 'o-', label='Val Loss')\n",
    "                     plt.title('Loss'); plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.legend(); plt.grid(True); plt.xticks(np.arange(1,epochs_completed+1, step=max(1,epochs_completed//10)))\n",
    "                     plt.subplot(1, 3, 2); plt.plot(epoch_axis, training_history['train_lev'], 'o-', label='Train Lev'); plt.plot(epoch_axis, training_history['val_lev'], 'o-', label='Val Lev')\n",
    "                     if np.isfinite(best_val_levenshtein):\n",
    "                         best_ep_idx = np.argmin(training_history['val_lev']); best_ep = best_ep_idx + 1\n",
    "                         plt.axhline(y=best_val_levenshtein, color='r', linestyle='--', label=f'Best ({best_val_levenshtein:.3f} @ ep {best_ep})')\n",
    "                         plt.scatter(best_ep, best_val_levenshtein, c='r', s=80, zorder=5, marker='*')\n",
    "                     plt.title('Levenshtein'); plt.xlabel('Epochs'); plt.ylabel('Levenshtein'); plt.legend(); plt.grid(True); plt.xticks(np.arange(1,epochs_completed+1, step=max(1,epochs_completed//10))); min_val_lev = min(training_history.get('val_lev', [0])); plt.ylim(bottom=max(0, min_val_lev - 0.5))\n",
    "                     plt.subplot(1, 3, 3); plt.plot(epoch_axis, training_history['lr'], 'o-', label='Learning Rate', color='g'); plt.title('Learning Rate'); plt.xlabel('Epochs'); plt.ylabel('LR'); plt.legend(); plt.grid(True); plt.yscale('log'); plt.xticks(np.arange(1,epochs_completed+1, step=max(1,epochs_completed//10)))\n",
    "                     plt.tight_layout(); plt.show()\n",
    "                 else: print(\"Нет данных для локальных графиков.\")\n",
    "            else: print(\"Локальные графики не строятся (нет истории).\")\n",
    "\n",
    "        # Run завершается автоматически при выходе из блока 'with'\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- Основное Обучение Не Запущено (проблемы с подготовкой данных / планировщиком / MLflow) ---\")\n",
    "\n",
    "print(\"\\n--- Ячейка 13: Основной цикл обучения завершен ---\")\n",
    "print(\"-\" * 50)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ячейка 14: Генерация Предсказаний (Submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ячейка 14: Генерация Предсказаний для Теста (Greedy) ---\n",
      "Модель для инференса: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3996Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_WD1e-04_Deltastandard.pth\n",
      "Параметры для инференса: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\params_Filt0-3996Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_WD1e-04_Deltastandard.json\n",
      "Используется ТОЛЬКО Greedy декодер.\n",
      "\n",
      "Загрузка сохраненных параметров...\n",
      "Параметры успешно загружены.\n",
      "\n",
      "Создание модели для инференса...\n",
      "Архитектура MorseRecognizer инициализирована.\n",
      "Загрузка весов из файла: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\model_Filt0-3996Hz_RMS384h96_CNNk9p2_RNN256x2_Feat2_WD1e-04_Deltastandard.pth...\n",
      "Модель успешно создана и веса загружены.\n",
      "\n",
      "Создание тестового DataLoader...\n",
      "MorseDataset создан: is_train=False, delta_type='standard', rms_smooth=Нет, delta_smooth=Нет, noise_level=Отключен\n",
      "Тестовый DataLoader создан (BS=32).\n",
      "\n",
      "--- Запуск инференса (Greedy) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d392f0006ff4e5c8148c99a86eab4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Предсказание (Greedy):   0%|                                                | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Инференс (Greedy) завершен за 36.95 сек. Предсказаний В СЛОВАРЕ: 5000/5000\n",
      "\n",
      "Формирование файла submission.csv...\n",
      "Файл submission сохранен: C:\\Users\\vasja\\OneDrive\\Рабочий стол\\MorseAudioDecoder\\output\\submission_greedy__Deltastandard.csv\n",
      "\n",
      "Последние 17 строк файла submission:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>34984.opus</td>\n",
       "      <td>ДАМАМТЗОТИ РСЫСАМЦ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>34985.opus</td>\n",
       "      <td>ИЛ ЬСВЕДТКЧВНТИ ЯМДМЫМЮНЯМЦ ЮТИЫМ Ь#ЧМЫН Д#МРГ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>34986.opus</td>\n",
       "      <td>АНХ ВСОЕГЬ Р ВКТДАМИРКШМДНИ ГКНЖТА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>34987.opus</td>\n",
       "      <td>ИЛ ДАСДП ЬСОЕМУНТА ИГВКСОЕП ЬКСХЫСУС ХНУ ЮН ХНУСИ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>34988.opus</td>\n",
       "      <td>ЕТЬТКП ДСЯНКМЫОЦ ИМК</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>34989.opus</td>\n",
       "      <td>КНОЬКМ СОЕНЫМОП ЬСЮНВМ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>34990.opus</td>\n",
       "      <td>ИЛ ЬСОЕНДМ#М ЙЫНУС ЙЫМЧАТУС ЬКТДЛХТ ЫМЖАЛШ ДЛУ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>34991.opus</td>\n",
       "      <td>Л ДАСДП ОСЮВНЫМ НЮЙГРГ ТЫТУКНЩН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>34992.opus</td>\n",
       "      <td>АСТ ИСЧТИ ГЖГПЦ Ю НЙОСЫЗЕПЗ ККАСОЕПЙМИДСЫС</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>34993.opus</td>\n",
       "      <td>ОЫДЛ ЫЛ1ЕТ #КС ЬЙЫНТ ЕСЕРЫ9АМЕ0П</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>34994.opus</td>\n",
       "      <td>АН ЖНОЕС ЬТЫТВНЖМ ГДЫМ3ТААСЬ АН 75 РМЫСЯМРЫСД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>34995.opus</td>\n",
       "      <td>ОДЦЮП ЬСВВТКЧМДНКЕОЦ ДКГЖАГЗ АТЧЕСИМИЛИМ ЬНЫПЯ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>34996.opus</td>\n",
       "      <td>ОРСКС ИЛ ДАСДП ЬСОЕМУАТИ ЕНБАЛ КНРТЕАЛШ ВДМУНЕ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>34997.opus</td>\n",
       "      <td>ИСЧТИ СЕЬК9П ЮН ДНИЬНОМЕТЫПАЪЪ ЖТЫАСР</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>34998.opus</td>\n",
       "      <td>ТОЫМ ДЛ ЬСЧТЫНТЕТ ДТКАГЕПОЦ ВСИСБ НН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>34999.opus</td>\n",
       "      <td>ОДТЕ ОСЫАЯНВНКМЕ ЧМЮАПРНЧВСИГ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>35000.opus</td>\n",
       "      <td>РСАТЯ ЬТКТВНЖМ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            message\n",
       "4983  34984.opus                                 ДАМАМТЗОТИ РСЫСАМЦ\n",
       "4984  34985.opus  ИЛ ЬСВЕДТКЧВНТИ ЯМДМЫМЮНЯМЦ ЮТИЫМ Ь#ЧМЫН Д#МРГ...\n",
       "4985  34986.opus                 АНХ ВСОЕГЬ Р ВКТДАМИРКШМДНИ ГКНЖТА\n",
       "4986  34987.opus  ИЛ ДАСДП ЬСОЕМУНТА ИГВКСОЕП ЬКСХЫСУС ХНУ ЮН ХНУСИ\n",
       "4987  34988.opus                               ЕТЬТКП ДСЯНКМЫОЦ ИМК\n",
       "4988  34989.opus                             КНОЬКМ СОЕНЫМОП ЬСЮНВМ\n",
       "4989  34990.opus  ИЛ ЬСОЕНДМ#М ЙЫНУС ЙЫМЧАТУС ЬКТДЛХТ ЫМЖАЛШ ДЛУ...\n",
       "4990  34991.opus                    Л ДАСДП ОСЮВНЫМ НЮЙГРГ ТЫТУКНЩН\n",
       "4991  34992.opus         АСТ ИСЧТИ ГЖГПЦ Ю НЙОСЫЗЕПЗ ККАСОЕПЙМИДСЫС\n",
       "4992  34993.opus                   ОЫДЛ ЫЛ1ЕТ #КС ЬЙЫНТ ЕСЕРЫ9АМЕ0П\n",
       "4993  34994.opus      АН ЖНОЕС ЬТЫТВНЖМ ГДЫМ3ТААСЬ АН 75 РМЫСЯМРЫСД\n",
       "4994  34995.opus  ОДЦЮП ЬСВВТКЧМДНКЕОЦ ДКГЖАГЗ АТЧЕСИМИЛИМ ЬНЫПЯ...\n",
       "4995  34996.opus  ОРСКС ИЛ ДАСДП ЬСОЕМУАТИ ЕНБАЛ КНРТЕАЛШ ВДМУНЕ...\n",
       "4996  34997.opus              ИСЧТИ СЕЬК9П ЮН ДНИЬНОМЕТЫПАЪЪ ЖТЫАСР\n",
       "4997  34998.opus               ТОЫМ ДЛ ЬСЧТЫНТЕТ ДТКАГЕПОЦ ВСИСБ НН\n",
       "4998  34999.opus                      ОДТЕ ОСЫАЯНВНКМЕ ЧМЮАПРНЧВСИГ\n",
       "4999  35000.opus                                     РСАТЯ ЬТКТВНЖМ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ячейка 14: Работа ноутбука завершена (Greedy) ---\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Ячейка 14: Генерация Предсказаний (Submission)\n",
    "# =============================================================================\n",
    "print(\"--- Ячейка 14: Генерация Предсказаний для Теста (Greedy) ---\")\n",
    "\n",
    "# --- Проверки наличия файлов и переменных ---\n",
    "# Убедимся, что модель и параметры существуют локально\n",
    "model_file_exists = 'BEST_MODEL_PATH' in globals() and BEST_MODEL_PATH is not None and BEST_MODEL_PATH.is_file()\n",
    "params_file_exists = 'PARAMS_PATH' in globals() and PARAMS_PATH is not None and PARAMS_PATH.is_file()\n",
    "test_df_exists = 'test_df' in globals() and test_df is not None and not test_df.empty\n",
    "# Доп. переменные для инференса\n",
    "required_infer_vars = [ 'MorseRecognizer', 'MorseDataset', 'collate_fn', 'device', 'ctc_greedy_decode',\n",
    "                        'index_to_char', 'BLANK_IDX', 'PAD_IDX', 'tqdm', 'torch', 'json', 'Path',\n",
    "                        'pd', 'DataLoader', 'np', 'EXTRACTED_AUDIO_DIR', 'TRAIN_CONFIG', 'F', 'MODEL_CONFIG', 'OUTPUT_DIR']\n",
    "missing_infer_vars = [v for v in required_infer_vars if v not in globals() or globals()[v] is None]\n",
    "\n",
    "can_infer = not missing_infer_vars and model_file_exists and params_file_exists and test_df_exists\n",
    "\n",
    "if can_infer:\n",
    "    print(f\"Загрузка модели из ЛОКАЛЬНОГО файла: {BEST_MODEL_PATH}\")\n",
    "    print(f\"Загрузка параметров из ЛОКАЛЬНОГО файла: {PARAMS_PATH}\")\n",
    "\n",
    "    # --- Загрузка параметров конфигурации из ЛОКАЛЬНОГО файла JSON ---\n",
    "    print(\"\\n1. Загрузка параметров конфигурации...\")\n",
    "    loaded_params_infer = None; params_loaded = False\n",
    "    try:\n",
    "        with open(PARAMS_PATH, 'r', encoding='utf-8') as f: loaded_params_infer = json.load(f)\n",
    "        loaded_audio_config_inf = loaded_params_infer['audio_config']; loaded_model_config_inf = loaded_params_infer['model_config']\n",
    "        loaded_char_map_inf = loaded_params_infer['char_map']; loaded_char_to_index_inf = loaded_char_map_inf['char_to_index']\n",
    "        loaded_index_to_char_inf = {int(k) if k.isdigit() else k: v for k,v in loaded_char_map_inf['index_to_char'].items()}\n",
    "        loaded_blank_idx_inf = loaded_char_map_inf['BLANK_IDX']; loaded_pad_idx_inf = loaded_char_map_inf['PAD_IDX']\n",
    "        loaded_num_classes_inf = loaded_char_map_inf['NUM_CLASSES_CTC']; loaded_input_dim_inf = loaded_model_config_inf['input_feature_dim']\n",
    "        print(\"   Параметры успешно загружены.\"); params_loaded = True\n",
    "    except Exception as e: print(f\"   !!! Ошибка загрузки/парсинга параметров: {e} !!!\"); traceback.print_exc(limit=1)\n",
    "\n",
    "    # --- Создание модели и загрузка весов из ЛОКАЛЬНОГО файла ---\n",
    "    inference_model = None; model_loaded = False\n",
    "    if params_loaded:\n",
    "        print(f\"\\n2. Создание модели для инференса...\");\n",
    "        try:\n",
    "            temp_model_config = loaded_model_config_inf.copy(); temp_model_config.pop('input_feature_dim', None)\n",
    "            inference_model = MorseRecognizer(num_classes_ctc=loaded_num_classes_inf, input_feature_dim=loaded_input_dim_inf, **temp_model_config).to(device)\n",
    "            print(f\"   Загрузка весов из: {BEST_MODEL_PATH}...\");\n",
    "            # Используем weights_only=True для безопасности\n",
    "            try: inference_model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device, weights_only=True))\n",
    "            except TypeError: print(\"   Warning: weights_only=True не поддерживается.\"); inference_model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
    "            inference_model.eval(); print(\"   Модель создана и веса загружены.\"); model_loaded = True\n",
    "        except Exception as e: print(f\"   !!! Ошибка создания/загрузки модели: {e} !!!\"); traceback.print_exc(limit=1)\n",
    "\n",
    "    # --- Создание тестового DataLoader ---\n",
    "    test_loader_infer = None; test_loader_ready = False\n",
    "    if model_loaded:\n",
    "        print(\"\\n3. Создание тестового DataLoader...\")\n",
    "        try:\n",
    "             loaded_train_config_inf = loaded_params_infer.get('train_config', TRAIN_CONFIG) # Берем из файла, если есть\n",
    "             infer_test_dataset = MorseDataset(\n",
    "                 dataframe=test_df, audio_dir=EXTRACTED_AUDIO_DIR, char_to_index=loaded_char_to_index_inf,\n",
    "                 audio_config=loaded_audio_config_inf, model_input_feature_dim=loaded_input_dim_inf,\n",
    "                 train_config=loaded_train_config_inf, is_train=False )\n",
    "             inf_bs = TRAIN_CONFIG.get('batch_size', 8) * 4; inf_nw = TRAIN_CONFIG.get('num_workers', 0)\n",
    "             test_loader_infer = DataLoader( infer_test_dataset, batch_size=inf_bs, shuffle=False,\n",
    "                 collate_fn=collate_fn, num_workers=inf_nw, pin_memory=(device.type == 'cuda') )\n",
    "             print(f\"   Тестовый DataLoader создан (Batch Size={inf_bs}).\"); test_loader_ready = True\n",
    "        except Exception as e: print(f\"   !!! Ошибка создания тестового DataLoader: {e} !!!\"); traceback.print_exc(limit=1)\n",
    "\n",
    "    # --- Запуск Инференса ---\n",
    "    if test_loader_ready and inference_model is not None:\n",
    "        predictions = {}; print(\"\\n4. Запуск инференса...\"); inference_start_time = time.time()\n",
    "        inference_model.eval();\n",
    "        with torch.no_grad():\n",
    "            pbar_infer = tqdm(test_loader_infer, desc=\"Предсказание (Greedy)\", ncols=1000, leave=True)\n",
    "            for batch_data in pbar_infer:\n",
    "                if batch_data is None: continue\n",
    "                features, file_ids, _, _ = batch_data # Длины не нужны для инференса\n",
    "                if features is None or file_ids is None or features.shape[0]==0: continue\n",
    "                features = features.to(device, non_blocking=True)\n",
    "                try:\n",
    "                    logits = inference_model(features) # (T, B, C)\n",
    "                    decoded_batch = ctc_greedy_decode(logits, loaded_index_to_char_inf, loaded_blank_idx_inf)\n",
    "                except Exception as e: print(f\"\\nОшибка Forward/Decode: {e}\"); decoded_batch = [\"ERROR_INFER\"] * len(file_ids)\n",
    "                for file_id, pred_text in zip(file_ids, decoded_batch): predictions[file_id] = pred_text\n",
    "        inference_duration = time.time() - inference_start_time\n",
    "        print(f\"\\n   Инференс завершен за {inference_duration:.2f} сек.\")\n",
    "        print(f\"   Предсказаний в словаре: {len(predictions)} (ожидалось: {len(test_df)})\")\n",
    "        if len(predictions) != len(test_df): print(\"   !!! ПРЕДУПРЕЖДЕНИЕ: Кол-во предсказаний не совпадает с test_df! Возможны пропуски.\")\n",
    "\n",
    "        # --- Формирование и сохранение submission ---\n",
    "        if predictions:\n",
    "            print(\"\\n5. Формирование и сохранение файла submission...\")\n",
    "            submission_df = pd.DataFrame({'id': test_df['id']})\n",
    "            submission_df['message'] = submission_df['id'].map(predictions).fillna(\"ERROR_MISSING_PRED\")\n",
    "            num_empty = (submission_df['message'] == \"\").sum(); num_errors = submission_df['message'].str.contains(\"ERROR\").sum()\n",
    "            if num_empty > 0: print(f\"  Предупреждение: Найдено {num_empty} пустых предсказаний.\")\n",
    "            if num_errors > 0: print(f\"  Предупреждение: Найдено {num_errors} предсказаний с ошибками.\")\n",
    "            # Используем финальный суффикс\n",
    "            submission_filename = f\"submission_greedy_{FINAL_SUFFIX}.csv\"\n",
    "            submission_path = OUTPUT_DIR / submission_filename\n",
    "            try:\n",
    "                submission_df.to_csv(submission_path, index=False)\n",
    "                print(f\"   Файл submission сохранен: {submission_path.resolve()}\")\n",
    "                print(f\"\\n   Последние 17 строк файла submission:\")\n",
    "                display(submission_df.tail(17))\n",
    "            except Exception as e: print(f\"   !!! Ошибка сохранения submission: {e} !!!\")\n",
    "        else: print(\"   Предсказания не сгенерированы, файл submission не создан.\")\n",
    "\n",
    "elif not can_infer:\n",
    "    print(\"\\n--- Инференс Не Запущен ---\")\n",
    "    if missing_infer_vars: print(f\"  Причина: Отсутствуют переменные: {missing_infer_vars}\")\n",
    "    if not model_file_exists: print(f\"  Причина: Файл модели не найден: {globals().get('BEST_MODEL_PATH', 'Путь не определен')}\")\n",
    "    if not params_file_exists: print(f\"  Причина: Файл параметров не найден: {globals().get('PARAMS_PATH', 'Путь не определен')}\")\n",
    "    if not test_df_exists: print(\"  Причина: test_df не загружен/пуст.\")\n",
    "\n",
    "print(\"\\n--- Ячейка 14: Работа ноутбука завершена ---\")\n",
    "print(\"=\" * 60)\n",
    "# ============================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
